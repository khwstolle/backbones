{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting backbones \n",
    "\n",
    "This notebook investigates how backbones can be exported using `torch.export`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khwstolle/.conda/envs/multictx/lib/python3.12/site-packages/timm/optim/optim_factory.py:7: FutureWarning: Importing from timm.optim.optim_factory is deprecated, please import via timm.optim\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.optim\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (stem): Sequential(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation): InplaceReLU(inplace=True)\n",
      "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ext1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Sequential(\n",
      "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "  )\n",
      "  (ext2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Sequential(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "  )\n",
      "  (ext3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Sequential(\n",
      "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "  )\n",
      "  (ext4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Sequential(\n",
      "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): InplaceReLU(inplace=True)\n",
      "      (residual): Identity()\n",
      "    )\n",
      "  )\n",
      "  (head): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53763/2619692258.py:9: UserWarning: Unexpected keys: ['head.proj.bias', 'head.proj.weight'].\n",
      "  bb.load_weights(\n"
     ]
    }
   ],
   "source": [
    "import torch.export\n",
    "import torch.nn\n",
    "import torch.fx\n",
    "\n",
    "import backbones as bb\n",
    "import unipercept as up\n",
    "\n",
    "rn50 = up.config.lazy.instantiate(bb.resnet.configs.RESNET_50)\n",
    "bb.load_weights(\n",
    "    \"../weights/resnet/50/imagenet-classification.safetensors\", rn50, device=\"cpu\"\n",
    ")\n",
    "\n",
    "print(rn50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, p_stem_conv_weight: \"f32[64, 3, 7, 7]\", p_stem_norm_weight: \"f32[64]\", p_stem_norm_bias: \"f32[64]\", p_getattr_l__self___ext1___0___residual_conv_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___residual_norm_weight: \"f32[256]\", p_getattr_l__self___ext1___0___residual_norm_bias: \"f32[256]\", p_getattr_l__self___ext1___0___conv1_weight: \"f32[64, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___0___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___0___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___1___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___1___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___1___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___1___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___1___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___2___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___2___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___2___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___2___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___2___norm3_bias: \"f32[256]\", p_getattr_l__self___ext2___0___residual_conv_weight: \"f32[512, 256, 1, 1]\", p_getattr_l__self___ext2___0___residual_norm_weight: \"f32[512]\", p_getattr_l__self___ext2___0___residual_norm_bias: \"f32[512]\", p_getattr_l__self___ext2___0___conv1_weight: \"f32[128, 256, 1, 1]\", p_getattr_l__self___ext2___0___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___0___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___0___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___0___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___1___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___1___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___1___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___1___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___1___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___2___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___2___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___2___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___2___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___2___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___3___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___3___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___3___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___3___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___3___norm3_bias: \"f32[512]\", p_getattr_l__self___ext3___0___residual_conv_weight: \"f32[1024, 512, 1, 1]\", p_getattr_l__self___ext3___0___residual_norm_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___residual_norm_bias: \"f32[1024]\", p_getattr_l__self___ext3___0___conv1_weight: \"f32[256, 512, 1, 1]\", p_getattr_l__self___ext3___0___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___0___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___0___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___1___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___1___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___1___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___1___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___1___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___2___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___2___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___2___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___2___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___2___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___3___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___3___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___3___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___3___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___3___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___4___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___4___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___4___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___4___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___4___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___5___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___5___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___5___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___5___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___5___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext4___0___residual_conv_weight: \"f32[2048, 1024, 1, 1]\", p_getattr_l__self___ext4___0___residual_norm_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___residual_norm_bias: \"f32[2048]\", p_getattr_l__self___ext4___0___conv1_weight: \"f32[512, 1024, 1, 1]\", p_getattr_l__self___ext4___0___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___0___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___0___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___1___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___1___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___1___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___1___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___1___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___2___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___2___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___2___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___2___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___2___norm3_bias: \"f32[2048]\", b_stem_norm_running_mean: \"f32[64]\", b_stem_norm_running_var: \"f32[64]\", b_stem_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___residual_norm_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___residual_norm_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___residual_norm_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___residual_norm_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_num_batches_tracked: \"i64[]\", x: \"f32[s0, 3, 2*s3, 2*s4]\"):\n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:285 in _forward_resnet, code: x = layer(x)\n",
      "            conv2d: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.conv2d.default(x, p_stem_conv_weight, None, [2, 2], [3, 3]);  x = p_stem_conv_weight = None\n",
      "            add_: \"i64[]\" = torch.ops.aten.add_.Tensor(b_stem_norm_num_batches_tracked, 1);  b_stem_norm_num_batches_tracked = add_ = None\n",
      "            batch_norm: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.batch_norm.default(conv2d, p_stem_norm_weight, p_stem_norm_bias, b_stem_norm_running_mean, b_stem_norm_running_var, True, 0.1, 1e-05, True);  conv2d = p_stem_norm_weight = p_stem_norm_bias = b_stem_norm_running_mean = b_stem_norm_running_var = None\n",
      "            relu_: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.relu_.default(batch_norm);  batch_norm = None\n",
      "            max_pool2d: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.max_pool2d.default(relu_, [3, 3], [2, 2], [1, 1]);  relu_ = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___residual_conv_weight);  p_getattr_l__self___ext1___0___residual_conv_weight = None\n",
      "            add__1: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked = add__1 = None\n",
      "            batch_norm_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_1, p_getattr_l__self___ext1___0___residual_norm_weight, p_getattr_l__self___ext1___0___residual_norm_bias, b_getattr_l__self___ext1___0___residual_norm_running_mean, b_getattr_l__self___ext1___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_1 = p_getattr_l__self___ext1___0___residual_norm_weight = p_getattr_l__self___ext1___0___residual_norm_bias = b_getattr_l__self___ext1___0___residual_norm_running_mean = b_getattr_l__self___ext1___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___conv1_weight);  max_pool2d = p_getattr_l__self___ext1___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__2: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm1_num_batches_tracked = add__2 = None\n",
      "            batch_norm_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_2, p_getattr_l__self___ext1___0___norm1_weight, p_getattr_l__self___ext1___0___norm1_bias, b_getattr_l__self___ext1___0___norm1_running_mean, b_getattr_l__self___ext1___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_2 = p_getattr_l__self___ext1___0___norm1_weight = p_getattr_l__self___ext1___0___norm1_bias = b_getattr_l__self___ext1___0___norm1_running_mean = b_getattr_l__self___ext1___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__1: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_2);  batch_norm_2 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__1, p_getattr_l__self___ext1___0___conv2_weight, None, [1, 1], [1, 1]);  relu__1 = p_getattr_l__self___ext1___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__3: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm2_num_batches_tracked = add__3 = None\n",
      "            batch_norm_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_3, p_getattr_l__self___ext1___0___norm2_weight, p_getattr_l__self___ext1___0___norm2_bias, b_getattr_l__self___ext1___0___norm2_running_mean, b_getattr_l__self___ext1___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_3 = p_getattr_l__self___ext1___0___norm2_weight = p_getattr_l__self___ext1___0___norm2_bias = b_getattr_l__self___ext1___0___norm2_running_mean = b_getattr_l__self___ext1___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_3);  batch_norm_3 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__2, p_getattr_l__self___ext1___0___conv3_weight);  relu__2 = p_getattr_l__self___ext1___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__4: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm3_num_batches_tracked = add__4 = None\n",
      "            batch_norm_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_4, p_getattr_l__self___ext1___0___norm3_weight, p_getattr_l__self___ext1___0___norm3_bias, b_getattr_l__self___ext1___0___norm3_running_mean, b_getattr_l__self___ext1___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_4 = p_getattr_l__self___ext1___0___norm3_weight = p_getattr_l__self___ext1___0___norm3_bias = b_getattr_l__self___ext1___0___norm3_running_mean = b_getattr_l__self___ext1___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_4, batch_norm_1);  batch_norm_4 = batch_norm_1 = None\n",
      "            relu__3: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add);  add = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__3, p_getattr_l__self___ext1___1___conv1_weight);  p_getattr_l__self___ext1___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__5: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm1_num_batches_tracked = add__5 = None\n",
      "            batch_norm_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_5, p_getattr_l__self___ext1___1___norm1_weight, p_getattr_l__self___ext1___1___norm1_bias, b_getattr_l__self___ext1___1___norm1_running_mean, b_getattr_l__self___ext1___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_5 = p_getattr_l__self___ext1___1___norm1_weight = p_getattr_l__self___ext1___1___norm1_bias = b_getattr_l__self___ext1___1___norm1_running_mean = b_getattr_l__self___ext1___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__4: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_5);  batch_norm_5 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__4, p_getattr_l__self___ext1___1___conv2_weight, None, [1, 1], [1, 1]);  relu__4 = p_getattr_l__self___ext1___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__6: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm2_num_batches_tracked = add__6 = None\n",
      "            batch_norm_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_6, p_getattr_l__self___ext1___1___norm2_weight, p_getattr_l__self___ext1___1___norm2_bias, b_getattr_l__self___ext1___1___norm2_running_mean, b_getattr_l__self___ext1___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_6 = p_getattr_l__self___ext1___1___norm2_weight = p_getattr_l__self___ext1___1___norm2_bias = b_getattr_l__self___ext1___1___norm2_running_mean = b_getattr_l__self___ext1___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_6);  batch_norm_6 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__5, p_getattr_l__self___ext1___1___conv3_weight);  relu__5 = p_getattr_l__self___ext1___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__7: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm3_num_batches_tracked = add__7 = None\n",
      "            batch_norm_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_7, p_getattr_l__self___ext1___1___norm3_weight, p_getattr_l__self___ext1___1___norm3_bias, b_getattr_l__self___ext1___1___norm3_running_mean, b_getattr_l__self___ext1___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_7 = p_getattr_l__self___ext1___1___norm3_weight = p_getattr_l__self___ext1___1___norm3_bias = b_getattr_l__self___ext1___1___norm3_running_mean = b_getattr_l__self___ext1___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_7, relu__3);  batch_norm_7 = relu__3 = None\n",
      "            relu__6: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_1);  add_1 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__6, p_getattr_l__self___ext1___2___conv1_weight);  p_getattr_l__self___ext1___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__8: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm1_num_batches_tracked = add__8 = None\n",
      "            batch_norm_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_8, p_getattr_l__self___ext1___2___norm1_weight, p_getattr_l__self___ext1___2___norm1_bias, b_getattr_l__self___ext1___2___norm1_running_mean, b_getattr_l__self___ext1___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_8 = p_getattr_l__self___ext1___2___norm1_weight = p_getattr_l__self___ext1___2___norm1_bias = b_getattr_l__self___ext1___2___norm1_running_mean = b_getattr_l__self___ext1___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__7: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_8);  batch_norm_8 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__7, p_getattr_l__self___ext1___2___conv2_weight, None, [1, 1], [1, 1]);  relu__7 = p_getattr_l__self___ext1___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__9: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm2_num_batches_tracked = add__9 = None\n",
      "            batch_norm_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_9, p_getattr_l__self___ext1___2___norm2_weight, p_getattr_l__self___ext1___2___norm2_bias, b_getattr_l__self___ext1___2___norm2_running_mean, b_getattr_l__self___ext1___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_9 = p_getattr_l__self___ext1___2___norm2_weight = p_getattr_l__self___ext1___2___norm2_bias = b_getattr_l__self___ext1___2___norm2_running_mean = b_getattr_l__self___ext1___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_9);  batch_norm_9 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__8, p_getattr_l__self___ext1___2___conv3_weight);  relu__8 = p_getattr_l__self___ext1___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__10: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm3_num_batches_tracked = add__10 = None\n",
      "            batch_norm_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_10, p_getattr_l__self___ext1___2___norm3_weight, p_getattr_l__self___ext1___2___norm3_bias, b_getattr_l__self___ext1___2___norm3_running_mean, b_getattr_l__self___ext1___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_10 = p_getattr_l__self___ext1___2___norm3_weight = p_getattr_l__self___ext1___2___norm3_bias = b_getattr_l__self___ext1___2___norm3_running_mean = b_getattr_l__self___ext1___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_2: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_10, relu__6);  batch_norm_10 = relu__6 = None\n",
      "            relu__9: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_2);  add_2 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext2___0___residual_conv_weight = None\n",
      "            add__11: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked = add__11 = None\n",
      "            batch_norm_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_11, p_getattr_l__self___ext2___0___residual_norm_weight, p_getattr_l__self___ext2___0___residual_norm_bias, b_getattr_l__self___ext2___0___residual_norm_running_mean, b_getattr_l__self___ext2___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_11 = p_getattr_l__self___ext2___0___residual_norm_weight = p_getattr_l__self___ext2___0___residual_norm_bias = b_getattr_l__self___ext2___0___residual_norm_running_mean = b_getattr_l__self___ext2___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___conv1_weight);  relu__9 = p_getattr_l__self___ext2___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__12: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm1_num_batches_tracked = add__12 = None\n",
      "            batch_norm_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_12, p_getattr_l__self___ext2___0___norm1_weight, p_getattr_l__self___ext2___0___norm1_bias, b_getattr_l__self___ext2___0___norm1_running_mean, b_getattr_l__self___ext2___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_12 = p_getattr_l__self___ext2___0___norm1_weight = p_getattr_l__self___ext2___0___norm1_bias = b_getattr_l__self___ext2___0___norm1_running_mean = b_getattr_l__self___ext2___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__10: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_12);  batch_norm_12 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__10, p_getattr_l__self___ext2___0___conv2_weight, None, [2, 2], [1, 1]);  relu__10 = p_getattr_l__self___ext2___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__13: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm2_num_batches_tracked = add__13 = None\n",
      "            batch_norm_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_13, p_getattr_l__self___ext2___0___norm2_weight, p_getattr_l__self___ext2___0___norm2_bias, b_getattr_l__self___ext2___0___norm2_running_mean, b_getattr_l__self___ext2___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_13 = p_getattr_l__self___ext2___0___norm2_weight = p_getattr_l__self___ext2___0___norm2_bias = b_getattr_l__self___ext2___0___norm2_running_mean = b_getattr_l__self___ext2___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__11: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_13);  batch_norm_13 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__11, p_getattr_l__self___ext2___0___conv3_weight);  relu__11 = p_getattr_l__self___ext2___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__14: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm3_num_batches_tracked = add__14 = None\n",
      "            batch_norm_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_14, p_getattr_l__self___ext2___0___norm3_weight, p_getattr_l__self___ext2___0___norm3_bias, b_getattr_l__self___ext2___0___norm3_running_mean, b_getattr_l__self___ext2___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_14 = p_getattr_l__self___ext2___0___norm3_weight = p_getattr_l__self___ext2___0___norm3_bias = b_getattr_l__self___ext2___0___norm3_running_mean = b_getattr_l__self___ext2___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_3: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_14, batch_norm_11);  batch_norm_14 = batch_norm_11 = None\n",
      "            relu__12: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_3);  add_3 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__12, p_getattr_l__self___ext2___1___conv1_weight);  p_getattr_l__self___ext2___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__15: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm1_num_batches_tracked = add__15 = None\n",
      "            batch_norm_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_15, p_getattr_l__self___ext2___1___norm1_weight, p_getattr_l__self___ext2___1___norm1_bias, b_getattr_l__self___ext2___1___norm1_running_mean, b_getattr_l__self___ext2___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_15 = p_getattr_l__self___ext2___1___norm1_weight = p_getattr_l__self___ext2___1___norm1_bias = b_getattr_l__self___ext2___1___norm1_running_mean = b_getattr_l__self___ext2___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_15);  batch_norm_15 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__13, p_getattr_l__self___ext2___1___conv2_weight, None, [1, 1], [1, 1]);  relu__13 = p_getattr_l__self___ext2___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__16: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm2_num_batches_tracked = add__16 = None\n",
      "            batch_norm_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_16, p_getattr_l__self___ext2___1___norm2_weight, p_getattr_l__self___ext2___1___norm2_bias, b_getattr_l__self___ext2___1___norm2_running_mean, b_getattr_l__self___ext2___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_16 = p_getattr_l__self___ext2___1___norm2_weight = p_getattr_l__self___ext2___1___norm2_bias = b_getattr_l__self___ext2___1___norm2_running_mean = b_getattr_l__self___ext2___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__14: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_16);  batch_norm_16 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__14, p_getattr_l__self___ext2___1___conv3_weight);  relu__14 = p_getattr_l__self___ext2___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__17: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm3_num_batches_tracked = add__17 = None\n",
      "            batch_norm_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_17, p_getattr_l__self___ext2___1___norm3_weight, p_getattr_l__self___ext2___1___norm3_bias, b_getattr_l__self___ext2___1___norm3_running_mean, b_getattr_l__self___ext2___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_17 = p_getattr_l__self___ext2___1___norm3_weight = p_getattr_l__self___ext2___1___norm3_bias = b_getattr_l__self___ext2___1___norm3_running_mean = b_getattr_l__self___ext2___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_4: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_17, relu__12);  batch_norm_17 = relu__12 = None\n",
      "            relu__15: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_4);  add_4 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__15, p_getattr_l__self___ext2___2___conv1_weight);  p_getattr_l__self___ext2___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__18: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm1_num_batches_tracked = add__18 = None\n",
      "            batch_norm_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_18, p_getattr_l__self___ext2___2___norm1_weight, p_getattr_l__self___ext2___2___norm1_bias, b_getattr_l__self___ext2___2___norm1_running_mean, b_getattr_l__self___ext2___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_18 = p_getattr_l__self___ext2___2___norm1_weight = p_getattr_l__self___ext2___2___norm1_bias = b_getattr_l__self___ext2___2___norm1_running_mean = b_getattr_l__self___ext2___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_18);  batch_norm_18 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__16, p_getattr_l__self___ext2___2___conv2_weight, None, [1, 1], [1, 1]);  relu__16 = p_getattr_l__self___ext2___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__19: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm2_num_batches_tracked = add__19 = None\n",
      "            batch_norm_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_19, p_getattr_l__self___ext2___2___norm2_weight, p_getattr_l__self___ext2___2___norm2_bias, b_getattr_l__self___ext2___2___norm2_running_mean, b_getattr_l__self___ext2___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_19 = p_getattr_l__self___ext2___2___norm2_weight = p_getattr_l__self___ext2___2___norm2_bias = b_getattr_l__self___ext2___2___norm2_running_mean = b_getattr_l__self___ext2___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__17: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_19);  batch_norm_19 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__17, p_getattr_l__self___ext2___2___conv3_weight);  relu__17 = p_getattr_l__self___ext2___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__20: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm3_num_batches_tracked = add__20 = None\n",
      "            batch_norm_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_20, p_getattr_l__self___ext2___2___norm3_weight, p_getattr_l__self___ext2___2___norm3_bias, b_getattr_l__self___ext2___2___norm3_running_mean, b_getattr_l__self___ext2___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_20 = p_getattr_l__self___ext2___2___norm3_weight = p_getattr_l__self___ext2___2___norm3_bias = b_getattr_l__self___ext2___2___norm3_running_mean = b_getattr_l__self___ext2___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_5: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_20, relu__15);  batch_norm_20 = relu__15 = None\n",
      "            relu__18: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_5);  add_5 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__18, p_getattr_l__self___ext2___3___conv1_weight);  p_getattr_l__self___ext2___3___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__21: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm1_num_batches_tracked = add__21 = None\n",
      "            batch_norm_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_21, p_getattr_l__self___ext2___3___norm1_weight, p_getattr_l__self___ext2___3___norm1_bias, b_getattr_l__self___ext2___3___norm1_running_mean, b_getattr_l__self___ext2___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_21 = p_getattr_l__self___ext2___3___norm1_weight = p_getattr_l__self___ext2___3___norm1_bias = b_getattr_l__self___ext2___3___norm1_running_mean = b_getattr_l__self___ext2___3___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_21);  batch_norm_21 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__19, p_getattr_l__self___ext2___3___conv2_weight, None, [1, 1], [1, 1]);  relu__19 = p_getattr_l__self___ext2___3___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__22: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm2_num_batches_tracked = add__22 = None\n",
      "            batch_norm_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_22, p_getattr_l__self___ext2___3___norm2_weight, p_getattr_l__self___ext2___3___norm2_bias, b_getattr_l__self___ext2___3___norm2_running_mean, b_getattr_l__self___ext2___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_22 = p_getattr_l__self___ext2___3___norm2_weight = p_getattr_l__self___ext2___3___norm2_bias = b_getattr_l__self___ext2___3___norm2_running_mean = b_getattr_l__self___ext2___3___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__20: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_22);  batch_norm_22 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__20, p_getattr_l__self___ext2___3___conv3_weight);  relu__20 = p_getattr_l__self___ext2___3___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__23: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm3_num_batches_tracked = add__23 = None\n",
      "            batch_norm_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_23, p_getattr_l__self___ext2___3___norm3_weight, p_getattr_l__self___ext2___3___norm3_bias, b_getattr_l__self___ext2___3___norm3_running_mean, b_getattr_l__self___ext2___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_23 = p_getattr_l__self___ext2___3___norm3_weight = p_getattr_l__self___ext2___3___norm3_bias = b_getattr_l__self___ext2___3___norm3_running_mean = b_getattr_l__self___ext2___3___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_6: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_23, relu__18);  batch_norm_23 = relu__18 = None\n",
      "            relu__21: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_6);  add_6 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext3___0___residual_conv_weight = None\n",
      "            add__24: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked = add__24 = None\n",
      "            batch_norm_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_24, p_getattr_l__self___ext3___0___residual_norm_weight, p_getattr_l__self___ext3___0___residual_norm_bias, b_getattr_l__self___ext3___0___residual_norm_running_mean, b_getattr_l__self___ext3___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_24 = p_getattr_l__self___ext3___0___residual_norm_weight = p_getattr_l__self___ext3___0___residual_norm_bias = b_getattr_l__self___ext3___0___residual_norm_running_mean = b_getattr_l__self___ext3___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___conv1_weight);  relu__21 = p_getattr_l__self___ext3___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__25: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm1_num_batches_tracked = add__25 = None\n",
      "            batch_norm_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_25, p_getattr_l__self___ext3___0___norm1_weight, p_getattr_l__self___ext3___0___norm1_bias, b_getattr_l__self___ext3___0___norm1_running_mean, b_getattr_l__self___ext3___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_25 = p_getattr_l__self___ext3___0___norm1_weight = p_getattr_l__self___ext3___0___norm1_bias = b_getattr_l__self___ext3___0___norm1_running_mean = b_getattr_l__self___ext3___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__22: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_25);  batch_norm_25 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__22, p_getattr_l__self___ext3___0___conv2_weight, None, [2, 2], [1, 1]);  relu__22 = p_getattr_l__self___ext3___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__26: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm2_num_batches_tracked = add__26 = None\n",
      "            batch_norm_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_26, p_getattr_l__self___ext3___0___norm2_weight, p_getattr_l__self___ext3___0___norm2_bias, b_getattr_l__self___ext3___0___norm2_running_mean, b_getattr_l__self___ext3___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_26 = p_getattr_l__self___ext3___0___norm2_weight = p_getattr_l__self___ext3___0___norm2_bias = b_getattr_l__self___ext3___0___norm2_running_mean = b_getattr_l__self___ext3___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__23: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_26);  batch_norm_26 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__23, p_getattr_l__self___ext3___0___conv3_weight);  relu__23 = p_getattr_l__self___ext3___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__27: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm3_num_batches_tracked = add__27 = None\n",
      "            batch_norm_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_27, p_getattr_l__self___ext3___0___norm3_weight, p_getattr_l__self___ext3___0___norm3_bias, b_getattr_l__self___ext3___0___norm3_running_mean, b_getattr_l__self___ext3___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_27 = p_getattr_l__self___ext3___0___norm3_weight = p_getattr_l__self___ext3___0___norm3_bias = b_getattr_l__self___ext3___0___norm3_running_mean = b_getattr_l__self___ext3___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_7: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_27, batch_norm_24);  batch_norm_27 = batch_norm_24 = None\n",
      "            relu__24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_7);  add_7 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__24, p_getattr_l__self___ext3___1___conv1_weight);  p_getattr_l__self___ext3___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__28: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm1_num_batches_tracked = add__28 = None\n",
      "            batch_norm_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_28, p_getattr_l__self___ext3___1___norm1_weight, p_getattr_l__self___ext3___1___norm1_bias, b_getattr_l__self___ext3___1___norm1_running_mean, b_getattr_l__self___ext3___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_28 = p_getattr_l__self___ext3___1___norm1_weight = p_getattr_l__self___ext3___1___norm1_bias = b_getattr_l__self___ext3___1___norm1_running_mean = b_getattr_l__self___ext3___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__25: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_28);  batch_norm_28 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__25, p_getattr_l__self___ext3___1___conv2_weight, None, [1, 1], [1, 1]);  relu__25 = p_getattr_l__self___ext3___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__29: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm2_num_batches_tracked = add__29 = None\n",
      "            batch_norm_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_29, p_getattr_l__self___ext3___1___norm2_weight, p_getattr_l__self___ext3___1___norm2_bias, b_getattr_l__self___ext3___1___norm2_running_mean, b_getattr_l__self___ext3___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_29 = p_getattr_l__self___ext3___1___norm2_weight = p_getattr_l__self___ext3___1___norm2_bias = b_getattr_l__self___ext3___1___norm2_running_mean = b_getattr_l__self___ext3___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_29);  batch_norm_29 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__26, p_getattr_l__self___ext3___1___conv3_weight);  relu__26 = p_getattr_l__self___ext3___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__30: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm3_num_batches_tracked = add__30 = None\n",
      "            batch_norm_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_30, p_getattr_l__self___ext3___1___norm3_weight, p_getattr_l__self___ext3___1___norm3_bias, b_getattr_l__self___ext3___1___norm3_running_mean, b_getattr_l__self___ext3___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_30 = p_getattr_l__self___ext3___1___norm3_weight = p_getattr_l__self___ext3___1___norm3_bias = b_getattr_l__self___ext3___1___norm3_running_mean = b_getattr_l__self___ext3___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_8: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_30, relu__24);  batch_norm_30 = relu__24 = None\n",
      "            relu__27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_8);  add_8 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__27, p_getattr_l__self___ext3___2___conv1_weight);  p_getattr_l__self___ext3___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__31: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm1_num_batches_tracked = add__31 = None\n",
      "            batch_norm_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_31, p_getattr_l__self___ext3___2___norm1_weight, p_getattr_l__self___ext3___2___norm1_bias, b_getattr_l__self___ext3___2___norm1_running_mean, b_getattr_l__self___ext3___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_31 = p_getattr_l__self___ext3___2___norm1_weight = p_getattr_l__self___ext3___2___norm1_bias = b_getattr_l__self___ext3___2___norm1_running_mean = b_getattr_l__self___ext3___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_31);  batch_norm_31 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__28, p_getattr_l__self___ext3___2___conv2_weight, None, [1, 1], [1, 1]);  relu__28 = p_getattr_l__self___ext3___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__32: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm2_num_batches_tracked = add__32 = None\n",
      "            batch_norm_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_32, p_getattr_l__self___ext3___2___norm2_weight, p_getattr_l__self___ext3___2___norm2_bias, b_getattr_l__self___ext3___2___norm2_running_mean, b_getattr_l__self___ext3___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_32 = p_getattr_l__self___ext3___2___norm2_weight = p_getattr_l__self___ext3___2___norm2_bias = b_getattr_l__self___ext3___2___norm2_running_mean = b_getattr_l__self___ext3___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_32);  batch_norm_32 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__29, p_getattr_l__self___ext3___2___conv3_weight);  relu__29 = p_getattr_l__self___ext3___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__33: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm3_num_batches_tracked = add__33 = None\n",
      "            batch_norm_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_33, p_getattr_l__self___ext3___2___norm3_weight, p_getattr_l__self___ext3___2___norm3_bias, b_getattr_l__self___ext3___2___norm3_running_mean, b_getattr_l__self___ext3___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_33 = p_getattr_l__self___ext3___2___norm3_weight = p_getattr_l__self___ext3___2___norm3_bias = b_getattr_l__self___ext3___2___norm3_running_mean = b_getattr_l__self___ext3___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_9: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_33, relu__27);  batch_norm_33 = relu__27 = None\n",
      "            relu__30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_9);  add_9 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__30, p_getattr_l__self___ext3___3___conv1_weight);  p_getattr_l__self___ext3___3___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__34: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm1_num_batches_tracked = add__34 = None\n",
      "            batch_norm_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_34, p_getattr_l__self___ext3___3___norm1_weight, p_getattr_l__self___ext3___3___norm1_bias, b_getattr_l__self___ext3___3___norm1_running_mean, b_getattr_l__self___ext3___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_34 = p_getattr_l__self___ext3___3___norm1_weight = p_getattr_l__self___ext3___3___norm1_bias = b_getattr_l__self___ext3___3___norm1_running_mean = b_getattr_l__self___ext3___3___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_34);  batch_norm_34 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__31, p_getattr_l__self___ext3___3___conv2_weight, None, [1, 1], [1, 1]);  relu__31 = p_getattr_l__self___ext3___3___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__35: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm2_num_batches_tracked = add__35 = None\n",
      "            batch_norm_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_35, p_getattr_l__self___ext3___3___norm2_weight, p_getattr_l__self___ext3___3___norm2_bias, b_getattr_l__self___ext3___3___norm2_running_mean, b_getattr_l__self___ext3___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_35 = p_getattr_l__self___ext3___3___norm2_weight = p_getattr_l__self___ext3___3___norm2_bias = b_getattr_l__self___ext3___3___norm2_running_mean = b_getattr_l__self___ext3___3___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_35);  batch_norm_35 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__32, p_getattr_l__self___ext3___3___conv3_weight);  relu__32 = p_getattr_l__self___ext3___3___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__36: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm3_num_batches_tracked = add__36 = None\n",
      "            batch_norm_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_36, p_getattr_l__self___ext3___3___norm3_weight, p_getattr_l__self___ext3___3___norm3_bias, b_getattr_l__self___ext3___3___norm3_running_mean, b_getattr_l__self___ext3___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_36 = p_getattr_l__self___ext3___3___norm3_weight = p_getattr_l__self___ext3___3___norm3_bias = b_getattr_l__self___ext3___3___norm3_running_mean = b_getattr_l__self___ext3___3___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_10: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_36, relu__30);  batch_norm_36 = relu__30 = None\n",
      "            relu__33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_10);  add_10 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__33, p_getattr_l__self___ext3___4___conv1_weight);  p_getattr_l__self___ext3___4___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__37: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm1_num_batches_tracked = add__37 = None\n",
      "            batch_norm_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_37, p_getattr_l__self___ext3___4___norm1_weight, p_getattr_l__self___ext3___4___norm1_bias, b_getattr_l__self___ext3___4___norm1_running_mean, b_getattr_l__self___ext3___4___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_37 = p_getattr_l__self___ext3___4___norm1_weight = p_getattr_l__self___ext3___4___norm1_bias = b_getattr_l__self___ext3___4___norm1_running_mean = b_getattr_l__self___ext3___4___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_37);  batch_norm_37 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__34, p_getattr_l__self___ext3___4___conv2_weight, None, [1, 1], [1, 1]);  relu__34 = p_getattr_l__self___ext3___4___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__38: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm2_num_batches_tracked = add__38 = None\n",
      "            batch_norm_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_38, p_getattr_l__self___ext3___4___norm2_weight, p_getattr_l__self___ext3___4___norm2_bias, b_getattr_l__self___ext3___4___norm2_running_mean, b_getattr_l__self___ext3___4___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_38 = p_getattr_l__self___ext3___4___norm2_weight = p_getattr_l__self___ext3___4___norm2_bias = b_getattr_l__self___ext3___4___norm2_running_mean = b_getattr_l__self___ext3___4___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_38);  batch_norm_38 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__35, p_getattr_l__self___ext3___4___conv3_weight);  relu__35 = p_getattr_l__self___ext3___4___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__39: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm3_num_batches_tracked = add__39 = None\n",
      "            batch_norm_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_39, p_getattr_l__self___ext3___4___norm3_weight, p_getattr_l__self___ext3___4___norm3_bias, b_getattr_l__self___ext3___4___norm3_running_mean, b_getattr_l__self___ext3___4___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_39 = p_getattr_l__self___ext3___4___norm3_weight = p_getattr_l__self___ext3___4___norm3_bias = b_getattr_l__self___ext3___4___norm3_running_mean = b_getattr_l__self___ext3___4___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_11: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_39, relu__33);  batch_norm_39 = relu__33 = None\n",
      "            relu__36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_11);  add_11 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__36, p_getattr_l__self___ext3___5___conv1_weight);  p_getattr_l__self___ext3___5___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__40: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm1_num_batches_tracked = add__40 = None\n",
      "            batch_norm_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_40, p_getattr_l__self___ext3___5___norm1_weight, p_getattr_l__self___ext3___5___norm1_bias, b_getattr_l__self___ext3___5___norm1_running_mean, b_getattr_l__self___ext3___5___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_40 = p_getattr_l__self___ext3___5___norm1_weight = p_getattr_l__self___ext3___5___norm1_bias = b_getattr_l__self___ext3___5___norm1_running_mean = b_getattr_l__self___ext3___5___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_40);  batch_norm_40 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__37, p_getattr_l__self___ext3___5___conv2_weight, None, [1, 1], [1, 1]);  relu__37 = p_getattr_l__self___ext3___5___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__41: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm2_num_batches_tracked = add__41 = None\n",
      "            batch_norm_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_41, p_getattr_l__self___ext3___5___norm2_weight, p_getattr_l__self___ext3___5___norm2_bias, b_getattr_l__self___ext3___5___norm2_running_mean, b_getattr_l__self___ext3___5___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_41 = p_getattr_l__self___ext3___5___norm2_weight = p_getattr_l__self___ext3___5___norm2_bias = b_getattr_l__self___ext3___5___norm2_running_mean = b_getattr_l__self___ext3___5___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_41);  batch_norm_41 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__38, p_getattr_l__self___ext3___5___conv3_weight);  relu__38 = p_getattr_l__self___ext3___5___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__42: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm3_num_batches_tracked = add__42 = None\n",
      "            batch_norm_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_42, p_getattr_l__self___ext3___5___norm3_weight, p_getattr_l__self___ext3___5___norm3_bias, b_getattr_l__self___ext3___5___norm3_running_mean, b_getattr_l__self___ext3___5___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_42 = p_getattr_l__self___ext3___5___norm3_weight = p_getattr_l__self___ext3___5___norm3_bias = b_getattr_l__self___ext3___5___norm3_running_mean = b_getattr_l__self___ext3___5___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_12: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_42, relu__36);  batch_norm_42 = relu__36 = None\n",
      "            relu__39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_12);  add_12 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext4___0___residual_conv_weight = None\n",
      "            add__43: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked = add__43 = None\n",
      "            batch_norm_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_43, p_getattr_l__self___ext4___0___residual_norm_weight, p_getattr_l__self___ext4___0___residual_norm_bias, b_getattr_l__self___ext4___0___residual_norm_running_mean, b_getattr_l__self___ext4___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_43 = p_getattr_l__self___ext4___0___residual_norm_weight = p_getattr_l__self___ext4___0___residual_norm_bias = b_getattr_l__self___ext4___0___residual_norm_running_mean = b_getattr_l__self___ext4___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___conv1_weight);  relu__39 = p_getattr_l__self___ext4___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__44: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm1_num_batches_tracked = add__44 = None\n",
      "            batch_norm_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_44, p_getattr_l__self___ext4___0___norm1_weight, p_getattr_l__self___ext4___0___norm1_bias, b_getattr_l__self___ext4___0___norm1_running_mean, b_getattr_l__self___ext4___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_44 = p_getattr_l__self___ext4___0___norm1_weight = p_getattr_l__self___ext4___0___norm1_bias = b_getattr_l__self___ext4___0___norm1_running_mean = b_getattr_l__self___ext4___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__40: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_44);  batch_norm_44 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__40, p_getattr_l__self___ext4___0___conv2_weight, None, [2, 2], [1, 1]);  relu__40 = p_getattr_l__self___ext4___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__45: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm2_num_batches_tracked = add__45 = None\n",
      "            batch_norm_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_45, p_getattr_l__self___ext4___0___norm2_weight, p_getattr_l__self___ext4___0___norm2_bias, b_getattr_l__self___ext4___0___norm2_running_mean, b_getattr_l__self___ext4___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_45 = p_getattr_l__self___ext4___0___norm2_weight = p_getattr_l__self___ext4___0___norm2_bias = b_getattr_l__self___ext4___0___norm2_running_mean = b_getattr_l__self___ext4___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__41: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_45);  batch_norm_45 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__41, p_getattr_l__self___ext4___0___conv3_weight);  relu__41 = p_getattr_l__self___ext4___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__46: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm3_num_batches_tracked = add__46 = None\n",
      "            batch_norm_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_46, p_getattr_l__self___ext4___0___norm3_weight, p_getattr_l__self___ext4___0___norm3_bias, b_getattr_l__self___ext4___0___norm3_running_mean, b_getattr_l__self___ext4___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_46 = p_getattr_l__self___ext4___0___norm3_weight = p_getattr_l__self___ext4___0___norm3_bias = b_getattr_l__self___ext4___0___norm3_running_mean = b_getattr_l__self___ext4___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_13: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_46, batch_norm_43);  batch_norm_46 = batch_norm_43 = None\n",
      "            relu__42: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_13);  add_13 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__42, p_getattr_l__self___ext4___1___conv1_weight);  p_getattr_l__self___ext4___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__47: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm1_num_batches_tracked = add__47 = None\n",
      "            batch_norm_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_47, p_getattr_l__self___ext4___1___norm1_weight, p_getattr_l__self___ext4___1___norm1_bias, b_getattr_l__self___ext4___1___norm1_running_mean, b_getattr_l__self___ext4___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_47 = p_getattr_l__self___ext4___1___norm1_weight = p_getattr_l__self___ext4___1___norm1_bias = b_getattr_l__self___ext4___1___norm1_running_mean = b_getattr_l__self___ext4___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__43: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_47);  batch_norm_47 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__43, p_getattr_l__self___ext4___1___conv2_weight, None, [1, 1], [1, 1]);  relu__43 = p_getattr_l__self___ext4___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__48: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm2_num_batches_tracked = add__48 = None\n",
      "            batch_norm_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_48, p_getattr_l__self___ext4___1___norm2_weight, p_getattr_l__self___ext4___1___norm2_bias, b_getattr_l__self___ext4___1___norm2_running_mean, b_getattr_l__self___ext4___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_48 = p_getattr_l__self___ext4___1___norm2_weight = p_getattr_l__self___ext4___1___norm2_bias = b_getattr_l__self___ext4___1___norm2_running_mean = b_getattr_l__self___ext4___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__44: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_48);  batch_norm_48 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__44, p_getattr_l__self___ext4___1___conv3_weight);  relu__44 = p_getattr_l__self___ext4___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__49: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm3_num_batches_tracked = add__49 = None\n",
      "            batch_norm_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_49, p_getattr_l__self___ext4___1___norm3_weight, p_getattr_l__self___ext4___1___norm3_bias, b_getattr_l__self___ext4___1___norm3_running_mean, b_getattr_l__self___ext4___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_49 = p_getattr_l__self___ext4___1___norm3_weight = p_getattr_l__self___ext4___1___norm3_bias = b_getattr_l__self___ext4___1___norm3_running_mean = b_getattr_l__self___ext4___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_14: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_49, relu__42);  batch_norm_49 = relu__42 = None\n",
      "            relu__45: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_14);  add_14 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__45, p_getattr_l__self___ext4___2___conv1_weight);  p_getattr_l__self___ext4___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__50: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm1_num_batches_tracked = add__50 = None\n",
      "            batch_norm_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_50, p_getattr_l__self___ext4___2___norm1_weight, p_getattr_l__self___ext4___2___norm1_bias, b_getattr_l__self___ext4___2___norm1_running_mean, b_getattr_l__self___ext4___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_50 = p_getattr_l__self___ext4___2___norm1_weight = p_getattr_l__self___ext4___2___norm1_bias = b_getattr_l__self___ext4___2___norm1_running_mean = b_getattr_l__self___ext4___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__46: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_50);  batch_norm_50 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__46, p_getattr_l__self___ext4___2___conv2_weight, None, [1, 1], [1, 1]);  relu__46 = p_getattr_l__self___ext4___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__51: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm2_num_batches_tracked = add__51 = None\n",
      "            batch_norm_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_51, p_getattr_l__self___ext4___2___norm2_weight, p_getattr_l__self___ext4___2___norm2_bias, b_getattr_l__self___ext4___2___norm2_running_mean, b_getattr_l__self___ext4___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_51 = p_getattr_l__self___ext4___2___norm2_weight = p_getattr_l__self___ext4___2___norm2_bias = b_getattr_l__self___ext4___2___norm2_running_mean = b_getattr_l__self___ext4___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_51);  batch_norm_51 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__47, p_getattr_l__self___ext4___2___conv3_weight);  relu__47 = p_getattr_l__self___ext4___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__52: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm3_num_batches_tracked = add__52 = None\n",
      "            batch_norm_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_52, p_getattr_l__self___ext4___2___norm3_weight, p_getattr_l__self___ext4___2___norm3_bias, b_getattr_l__self___ext4___2___norm3_running_mean, b_getattr_l__self___ext4___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_52 = p_getattr_l__self___ext4___2___norm3_weight = p_getattr_l__self___ext4___2___norm3_bias = b_getattr_l__self___ext4___2___norm3_running_mean = b_getattr_l__self___ext4___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_15: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_52, relu__45);  batch_norm_52 = relu__45 = None\n",
      "            relu__48: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_15);  add_15 = None\n",
      "            return (relu__48,)\n",
      "            \n",
      "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_stem_conv_weight'), target='stem.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_stem_norm_weight'), target='stem.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_stem_norm_bias'), target='stem.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___residual_conv_weight'), target='ext1.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___residual_norm_weight'), target='ext1.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___residual_norm_bias'), target='ext1.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___conv1_weight'), target='ext1.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm1_weight'), target='ext1.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm1_bias'), target='ext1.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___conv2_weight'), target='ext1.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm2_weight'), target='ext1.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm2_bias'), target='ext1.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___conv3_weight'), target='ext1.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm3_weight'), target='ext1.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm3_bias'), target='ext1.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___conv1_weight'), target='ext1.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm1_weight'), target='ext1.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm1_bias'), target='ext1.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___conv2_weight'), target='ext1.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm2_weight'), target='ext1.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm2_bias'), target='ext1.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___conv3_weight'), target='ext1.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm3_weight'), target='ext1.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm3_bias'), target='ext1.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___conv1_weight'), target='ext1.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm1_weight'), target='ext1.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm1_bias'), target='ext1.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___conv2_weight'), target='ext1.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm2_weight'), target='ext1.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm2_bias'), target='ext1.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___conv3_weight'), target='ext1.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm3_weight'), target='ext1.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm3_bias'), target='ext1.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___residual_conv_weight'), target='ext2.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___residual_norm_weight'), target='ext2.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___residual_norm_bias'), target='ext2.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___conv1_weight'), target='ext2.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm1_weight'), target='ext2.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm1_bias'), target='ext2.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___conv2_weight'), target='ext2.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm2_weight'), target='ext2.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm2_bias'), target='ext2.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___conv3_weight'), target='ext2.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm3_weight'), target='ext2.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm3_bias'), target='ext2.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___conv1_weight'), target='ext2.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm1_weight'), target='ext2.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm1_bias'), target='ext2.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___conv2_weight'), target='ext2.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm2_weight'), target='ext2.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm2_bias'), target='ext2.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___conv3_weight'), target='ext2.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm3_weight'), target='ext2.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm3_bias'), target='ext2.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___conv1_weight'), target='ext2.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm1_weight'), target='ext2.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm1_bias'), target='ext2.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___conv2_weight'), target='ext2.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm2_weight'), target='ext2.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm2_bias'), target='ext2.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___conv3_weight'), target='ext2.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm3_weight'), target='ext2.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm3_bias'), target='ext2.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___conv1_weight'), target='ext2.3.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm1_weight'), target='ext2.3.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm1_bias'), target='ext2.3.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___conv2_weight'), target='ext2.3.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm2_weight'), target='ext2.3.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm2_bias'), target='ext2.3.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___conv3_weight'), target='ext2.3.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm3_weight'), target='ext2.3.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm3_bias'), target='ext2.3.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___residual_conv_weight'), target='ext3.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___residual_norm_weight'), target='ext3.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___residual_norm_bias'), target='ext3.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___conv1_weight'), target='ext3.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm1_weight'), target='ext3.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm1_bias'), target='ext3.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___conv2_weight'), target='ext3.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm2_weight'), target='ext3.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm2_bias'), target='ext3.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___conv3_weight'), target='ext3.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm3_weight'), target='ext3.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm3_bias'), target='ext3.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___conv1_weight'), target='ext3.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm1_weight'), target='ext3.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm1_bias'), target='ext3.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___conv2_weight'), target='ext3.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm2_weight'), target='ext3.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm2_bias'), target='ext3.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___conv3_weight'), target='ext3.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm3_weight'), target='ext3.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm3_bias'), target='ext3.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___conv1_weight'), target='ext3.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm1_weight'), target='ext3.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm1_bias'), target='ext3.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___conv2_weight'), target='ext3.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm2_weight'), target='ext3.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm2_bias'), target='ext3.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___conv3_weight'), target='ext3.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm3_weight'), target='ext3.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm3_bias'), target='ext3.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___conv1_weight'), target='ext3.3.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm1_weight'), target='ext3.3.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm1_bias'), target='ext3.3.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___conv2_weight'), target='ext3.3.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm2_weight'), target='ext3.3.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm2_bias'), target='ext3.3.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___conv3_weight'), target='ext3.3.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm3_weight'), target='ext3.3.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm3_bias'), target='ext3.3.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___conv1_weight'), target='ext3.4.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm1_weight'), target='ext3.4.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm1_bias'), target='ext3.4.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___conv2_weight'), target='ext3.4.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm2_weight'), target='ext3.4.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm2_bias'), target='ext3.4.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___conv3_weight'), target='ext3.4.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm3_weight'), target='ext3.4.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm3_bias'), target='ext3.4.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___conv1_weight'), target='ext3.5.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm1_weight'), target='ext3.5.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm1_bias'), target='ext3.5.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___conv2_weight'), target='ext3.5.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm2_weight'), target='ext3.5.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm2_bias'), target='ext3.5.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___conv3_weight'), target='ext3.5.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm3_weight'), target='ext3.5.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm3_bias'), target='ext3.5.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___residual_conv_weight'), target='ext4.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___residual_norm_weight'), target='ext4.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___residual_norm_bias'), target='ext4.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___conv1_weight'), target='ext4.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm1_weight'), target='ext4.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm1_bias'), target='ext4.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___conv2_weight'), target='ext4.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm2_weight'), target='ext4.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm2_bias'), target='ext4.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___conv3_weight'), target='ext4.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm3_weight'), target='ext4.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm3_bias'), target='ext4.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___conv1_weight'), target='ext4.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm1_weight'), target='ext4.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm1_bias'), target='ext4.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___conv2_weight'), target='ext4.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm2_weight'), target='ext4.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm2_bias'), target='ext4.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___conv3_weight'), target='ext4.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm3_weight'), target='ext4.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm3_bias'), target='ext4.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___conv1_weight'), target='ext4.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm1_weight'), target='ext4.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm1_bias'), target='ext4.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___conv2_weight'), target='ext4.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm2_weight'), target='ext4.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm2_bias'), target='ext4.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___conv3_weight'), target='ext4.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm3_weight'), target='ext4.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm3_bias'), target='ext4.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_stem_norm_running_mean'), target='stem.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_stem_norm_running_var'), target='stem.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_stem_norm_num_batches_tracked'), target='stem.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___residual_norm_running_mean'), target='ext1.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___residual_norm_running_var'), target='ext1.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked'), target='ext1.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm1_running_mean'), target='ext1.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm1_running_var'), target='ext1.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm1_num_batches_tracked'), target='ext1.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm2_running_mean'), target='ext1.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm2_running_var'), target='ext1.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm2_num_batches_tracked'), target='ext1.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm3_running_mean'), target='ext1.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm3_running_var'), target='ext1.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm3_num_batches_tracked'), target='ext1.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm1_running_mean'), target='ext1.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm1_running_var'), target='ext1.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm1_num_batches_tracked'), target='ext1.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm2_running_mean'), target='ext1.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm2_running_var'), target='ext1.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm2_num_batches_tracked'), target='ext1.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm3_running_mean'), target='ext1.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm3_running_var'), target='ext1.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm3_num_batches_tracked'), target='ext1.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm1_running_mean'), target='ext1.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm1_running_var'), target='ext1.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm1_num_batches_tracked'), target='ext1.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm2_running_mean'), target='ext1.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm2_running_var'), target='ext1.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm2_num_batches_tracked'), target='ext1.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm3_running_mean'), target='ext1.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm3_running_var'), target='ext1.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm3_num_batches_tracked'), target='ext1.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___residual_norm_running_mean'), target='ext2.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___residual_norm_running_var'), target='ext2.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked'), target='ext2.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm1_running_mean'), target='ext2.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm1_running_var'), target='ext2.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm1_num_batches_tracked'), target='ext2.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm2_running_mean'), target='ext2.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm2_running_var'), target='ext2.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm2_num_batches_tracked'), target='ext2.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm3_running_mean'), target='ext2.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm3_running_var'), target='ext2.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm3_num_batches_tracked'), target='ext2.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm1_running_mean'), target='ext2.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm1_running_var'), target='ext2.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm1_num_batches_tracked'), target='ext2.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm2_running_mean'), target='ext2.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm2_running_var'), target='ext2.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm2_num_batches_tracked'), target='ext2.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm3_running_mean'), target='ext2.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm3_running_var'), target='ext2.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm3_num_batches_tracked'), target='ext2.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm1_running_mean'), target='ext2.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm1_running_var'), target='ext2.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm1_num_batches_tracked'), target='ext2.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm2_running_mean'), target='ext2.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm2_running_var'), target='ext2.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm2_num_batches_tracked'), target='ext2.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm3_running_mean'), target='ext2.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm3_running_var'), target='ext2.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm3_num_batches_tracked'), target='ext2.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm1_running_mean'), target='ext2.3.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm1_running_var'), target='ext2.3.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm1_num_batches_tracked'), target='ext2.3.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm2_running_mean'), target='ext2.3.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm2_running_var'), target='ext2.3.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm2_num_batches_tracked'), target='ext2.3.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm3_running_mean'), target='ext2.3.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm3_running_var'), target='ext2.3.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm3_num_batches_tracked'), target='ext2.3.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___residual_norm_running_mean'), target='ext3.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___residual_norm_running_var'), target='ext3.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked'), target='ext3.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm1_running_mean'), target='ext3.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm1_running_var'), target='ext3.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm1_num_batches_tracked'), target='ext3.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm2_running_mean'), target='ext3.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm2_running_var'), target='ext3.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm2_num_batches_tracked'), target='ext3.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm3_running_mean'), target='ext3.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm3_running_var'), target='ext3.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm3_num_batches_tracked'), target='ext3.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm1_running_mean'), target='ext3.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm1_running_var'), target='ext3.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm1_num_batches_tracked'), target='ext3.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm2_running_mean'), target='ext3.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm2_running_var'), target='ext3.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm2_num_batches_tracked'), target='ext3.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm3_running_mean'), target='ext3.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm3_running_var'), target='ext3.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm3_num_batches_tracked'), target='ext3.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm1_running_mean'), target='ext3.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm1_running_var'), target='ext3.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm1_num_batches_tracked'), target='ext3.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm2_running_mean'), target='ext3.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm2_running_var'), target='ext3.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm2_num_batches_tracked'), target='ext3.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm3_running_mean'), target='ext3.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm3_running_var'), target='ext3.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm3_num_batches_tracked'), target='ext3.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm1_running_mean'), target='ext3.3.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm1_running_var'), target='ext3.3.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm1_num_batches_tracked'), target='ext3.3.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm2_running_mean'), target='ext3.3.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm2_running_var'), target='ext3.3.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm2_num_batches_tracked'), target='ext3.3.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm3_running_mean'), target='ext3.3.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm3_running_var'), target='ext3.3.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm3_num_batches_tracked'), target='ext3.3.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm1_running_mean'), target='ext3.4.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm1_running_var'), target='ext3.4.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm1_num_batches_tracked'), target='ext3.4.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm2_running_mean'), target='ext3.4.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm2_running_var'), target='ext3.4.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm2_num_batches_tracked'), target='ext3.4.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm3_running_mean'), target='ext3.4.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm3_running_var'), target='ext3.4.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm3_num_batches_tracked'), target='ext3.4.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm1_running_mean'), target='ext3.5.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm1_running_var'), target='ext3.5.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm1_num_batches_tracked'), target='ext3.5.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm2_running_mean'), target='ext3.5.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm2_running_var'), target='ext3.5.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm2_num_batches_tracked'), target='ext3.5.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm3_running_mean'), target='ext3.5.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm3_running_var'), target='ext3.5.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm3_num_batches_tracked'), target='ext3.5.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___residual_norm_running_mean'), target='ext4.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___residual_norm_running_var'), target='ext4.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked'), target='ext4.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm1_running_mean'), target='ext4.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm1_running_var'), target='ext4.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm1_num_batches_tracked'), target='ext4.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm2_running_mean'), target='ext4.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm2_running_var'), target='ext4.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm2_num_batches_tracked'), target='ext4.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm3_running_mean'), target='ext4.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm3_running_var'), target='ext4.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm3_num_batches_tracked'), target='ext4.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm1_running_mean'), target='ext4.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm1_running_var'), target='ext4.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm1_num_batches_tracked'), target='ext4.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm2_running_mean'), target='ext4.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm2_running_var'), target='ext4.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm2_num_batches_tracked'), target='ext4.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm3_running_mean'), target='ext4.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm3_running_var'), target='ext4.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm3_num_batches_tracked'), target='ext4.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm1_running_mean'), target='ext4.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm1_running_var'), target='ext4.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm1_num_batches_tracked'), target='ext4.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm2_running_mean'), target='ext4.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm2_running_var'), target='ext4.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm2_num_batches_tracked'), target='ext4.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm3_running_mean'), target='ext4.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm3_running_var'), target='ext4.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm3_num_batches_tracked'), target='ext4.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='relu__48'), target=None)])\n",
      "Range constraints: {s0: VR[1, int_oo], 2*s3: VR[256, 1024], 2*s4: VR[256, 1024], s3: VR[128, 512], s4: VR[128, 512]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.export.dynamic_shapes import Dim\n",
    "\n",
    "inputs = (torch.randn(2, 3, 512, 1024),)\n",
    "\n",
    "sb = Dim(\"batch\", min=1)\n",
    "sh = Dim(\"height\", min=128, max=512)\n",
    "sw = Dim(\"width\", min=128, max=512)\n",
    "# sw = 2 * sh\n",
    "\n",
    "\n",
    "rn50_train = torch.export.export_for_training(\n",
    "    rn50,\n",
    "    inputs,\n",
    "    dynamic_shapes=[(sb, Dim.STATIC, 2 * sh, 2 * sw)],  # type: ignore[attr-defined]\n",
    ")\n",
    "print(rn50_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.export.save(rn50_train, \"resnet50.pt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, p_stem_conv_weight: \"f32[64, 3, 7, 7]\", p_stem_norm_weight: \"f32[64]\", p_stem_norm_bias: \"f32[64]\", p_getattr_l__self___ext1___0___residual_conv_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___residual_norm_weight: \"f32[256]\", p_getattr_l__self___ext1___0___residual_norm_bias: \"f32[256]\", p_getattr_l__self___ext1___0___conv1_weight: \"f32[64, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___0___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___0___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___1___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___1___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___1___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___1___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___1___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___2___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___2___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___2___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___2___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___2___norm3_bias: \"f32[256]\", p_getattr_l__self___ext2___0___residual_conv_weight: \"f32[512, 256, 1, 1]\", p_getattr_l__self___ext2___0___residual_norm_weight: \"f32[512]\", p_getattr_l__self___ext2___0___residual_norm_bias: \"f32[512]\", p_getattr_l__self___ext2___0___conv1_weight: \"f32[128, 256, 1, 1]\", p_getattr_l__self___ext2___0___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___0___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___0___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___0___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___1___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___1___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___1___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___1___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___1___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___2___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___2___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___2___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___2___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___2___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___3___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___3___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___3___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___3___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___3___norm3_bias: \"f32[512]\", p_getattr_l__self___ext3___0___residual_conv_weight: \"f32[1024, 512, 1, 1]\", p_getattr_l__self___ext3___0___residual_norm_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___residual_norm_bias: \"f32[1024]\", p_getattr_l__self___ext3___0___conv1_weight: \"f32[256, 512, 1, 1]\", p_getattr_l__self___ext3___0___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___0___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___0___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___1___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___1___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___1___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___1___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___1___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___2___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___2___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___2___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___2___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___2___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___3___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___3___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___3___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___3___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___3___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___4___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___4___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___4___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___4___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___4___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___5___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___5___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___5___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___5___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___5___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext4___0___residual_conv_weight: \"f32[2048, 1024, 1, 1]\", p_getattr_l__self___ext4___0___residual_norm_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___residual_norm_bias: \"f32[2048]\", p_getattr_l__self___ext4___0___conv1_weight: \"f32[512, 1024, 1, 1]\", p_getattr_l__self___ext4___0___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___0___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___0___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___1___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___1___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___1___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___1___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___1___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___2___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___2___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___2___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___2___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___2___norm3_bias: \"f32[2048]\", b_stem_norm_running_mean: \"f32[64]\", b_stem_norm_running_var: \"f32[64]\", b_stem_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___residual_norm_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___residual_norm_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___residual_norm_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___residual_norm_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_num_batches_tracked: \"i64[]\", x: \"f32[s0, 3, 2*s3, 2*s4]\"):\n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:285 in _forward_resnet, code: x = layer(x)\n",
      "            conv2d: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.conv2d.default(x, p_stem_conv_weight, bias = None, stride = [2, 2], padding = [3, 3]);  x = p_stem_conv_weight = None\n",
      "            add_: \"i64[]\" = torch.ops.aten.add_.Tensor(b_stem_norm_num_batches_tracked, 1);  b_stem_norm_num_batches_tracked = add_ = None\n",
      "            batch_norm: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.batch_norm.default(conv2d, p_stem_norm_weight, p_stem_norm_bias, b_stem_norm_running_mean, b_stem_norm_running_var, True, 0.1, 1e-05, True);  conv2d = p_stem_norm_weight = p_stem_norm_bias = b_stem_norm_running_mean = b_stem_norm_running_var = None\n",
      "            relu_: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.relu_.default(batch_norm);  batch_norm = None\n",
      "            max_pool2d: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.max_pool2d.default(relu_, [3, 3], stride = [2, 2], padding = [1, 1]);  relu_ = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___residual_conv_weight);  p_getattr_l__self___ext1___0___residual_conv_weight = None\n",
      "            add__1: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked = add__1 = None\n",
      "            batch_norm_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_1, p_getattr_l__self___ext1___0___residual_norm_weight, p_getattr_l__self___ext1___0___residual_norm_bias, b_getattr_l__self___ext1___0___residual_norm_running_mean, b_getattr_l__self___ext1___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_1 = p_getattr_l__self___ext1___0___residual_norm_weight = p_getattr_l__self___ext1___0___residual_norm_bias = b_getattr_l__self___ext1___0___residual_norm_running_mean = b_getattr_l__self___ext1___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___conv1_weight);  max_pool2d = p_getattr_l__self___ext1___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__2: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm1_num_batches_tracked = add__2 = None\n",
      "            batch_norm_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_2, p_getattr_l__self___ext1___0___norm1_weight, p_getattr_l__self___ext1___0___norm1_bias, b_getattr_l__self___ext1___0___norm1_running_mean, b_getattr_l__self___ext1___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_2 = p_getattr_l__self___ext1___0___norm1_weight = p_getattr_l__self___ext1___0___norm1_bias = b_getattr_l__self___ext1___0___norm1_running_mean = b_getattr_l__self___ext1___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__1: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_2);  batch_norm_2 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__1, p_getattr_l__self___ext1___0___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__1 = p_getattr_l__self___ext1___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__3: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm2_num_batches_tracked = add__3 = None\n",
      "            batch_norm_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_3, p_getattr_l__self___ext1___0___norm2_weight, p_getattr_l__self___ext1___0___norm2_bias, b_getattr_l__self___ext1___0___norm2_running_mean, b_getattr_l__self___ext1___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_3 = p_getattr_l__self___ext1___0___norm2_weight = p_getattr_l__self___ext1___0___norm2_bias = b_getattr_l__self___ext1___0___norm2_running_mean = b_getattr_l__self___ext1___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_3);  batch_norm_3 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__2, p_getattr_l__self___ext1___0___conv3_weight);  relu__2 = p_getattr_l__self___ext1___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__4: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm3_num_batches_tracked = add__4 = None\n",
      "            batch_norm_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_4, p_getattr_l__self___ext1___0___norm3_weight, p_getattr_l__self___ext1___0___norm3_bias, b_getattr_l__self___ext1___0___norm3_running_mean, b_getattr_l__self___ext1___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_4 = p_getattr_l__self___ext1___0___norm3_weight = p_getattr_l__self___ext1___0___norm3_bias = b_getattr_l__self___ext1___0___norm3_running_mean = b_getattr_l__self___ext1___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_4, batch_norm_1);  batch_norm_4 = batch_norm_1 = None\n",
      "            relu__3: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add);  add = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__3, p_getattr_l__self___ext1___1___conv1_weight);  p_getattr_l__self___ext1___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__5: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm1_num_batches_tracked = add__5 = None\n",
      "            batch_norm_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_5, p_getattr_l__self___ext1___1___norm1_weight, p_getattr_l__self___ext1___1___norm1_bias, b_getattr_l__self___ext1___1___norm1_running_mean, b_getattr_l__self___ext1___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_5 = p_getattr_l__self___ext1___1___norm1_weight = p_getattr_l__self___ext1___1___norm1_bias = b_getattr_l__self___ext1___1___norm1_running_mean = b_getattr_l__self___ext1___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__4: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_5);  batch_norm_5 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__4, p_getattr_l__self___ext1___1___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__4 = p_getattr_l__self___ext1___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__6: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm2_num_batches_tracked = add__6 = None\n",
      "            batch_norm_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_6, p_getattr_l__self___ext1___1___norm2_weight, p_getattr_l__self___ext1___1___norm2_bias, b_getattr_l__self___ext1___1___norm2_running_mean, b_getattr_l__self___ext1___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_6 = p_getattr_l__self___ext1___1___norm2_weight = p_getattr_l__self___ext1___1___norm2_bias = b_getattr_l__self___ext1___1___norm2_running_mean = b_getattr_l__self___ext1___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_6);  batch_norm_6 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__5, p_getattr_l__self___ext1___1___conv3_weight);  relu__5 = p_getattr_l__self___ext1___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__7: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm3_num_batches_tracked = add__7 = None\n",
      "            batch_norm_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_7, p_getattr_l__self___ext1___1___norm3_weight, p_getattr_l__self___ext1___1___norm3_bias, b_getattr_l__self___ext1___1___norm3_running_mean, b_getattr_l__self___ext1___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_7 = p_getattr_l__self___ext1___1___norm3_weight = p_getattr_l__self___ext1___1___norm3_bias = b_getattr_l__self___ext1___1___norm3_running_mean = b_getattr_l__self___ext1___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_7, relu__3);  batch_norm_7 = relu__3 = None\n",
      "            relu__6: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_1);  add_1 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__6, p_getattr_l__self___ext1___2___conv1_weight);  p_getattr_l__self___ext1___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__8: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm1_num_batches_tracked = add__8 = None\n",
      "            batch_norm_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_8, p_getattr_l__self___ext1___2___norm1_weight, p_getattr_l__self___ext1___2___norm1_bias, b_getattr_l__self___ext1___2___norm1_running_mean, b_getattr_l__self___ext1___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_8 = p_getattr_l__self___ext1___2___norm1_weight = p_getattr_l__self___ext1___2___norm1_bias = b_getattr_l__self___ext1___2___norm1_running_mean = b_getattr_l__self___ext1___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__7: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_8);  batch_norm_8 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__7, p_getattr_l__self___ext1___2___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__7 = p_getattr_l__self___ext1___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__9: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm2_num_batches_tracked = add__9 = None\n",
      "            batch_norm_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_9, p_getattr_l__self___ext1___2___norm2_weight, p_getattr_l__self___ext1___2___norm2_bias, b_getattr_l__self___ext1___2___norm2_running_mean, b_getattr_l__self___ext1___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_9 = p_getattr_l__self___ext1___2___norm2_weight = p_getattr_l__self___ext1___2___norm2_bias = b_getattr_l__self___ext1___2___norm2_running_mean = b_getattr_l__self___ext1___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_9);  batch_norm_9 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__8, p_getattr_l__self___ext1___2___conv3_weight);  relu__8 = p_getattr_l__self___ext1___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__10: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm3_num_batches_tracked = add__10 = None\n",
      "            batch_norm_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_10, p_getattr_l__self___ext1___2___norm3_weight, p_getattr_l__self___ext1___2___norm3_bias, b_getattr_l__self___ext1___2___norm3_running_mean, b_getattr_l__self___ext1___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_10 = p_getattr_l__self___ext1___2___norm3_weight = p_getattr_l__self___ext1___2___norm3_bias = b_getattr_l__self___ext1___2___norm3_running_mean = b_getattr_l__self___ext1___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_2: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_10, relu__6);  batch_norm_10 = relu__6 = None\n",
      "            relu__9: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_2);  add_2 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___residual_conv_weight, bias = None, stride = [2, 2]);  p_getattr_l__self___ext2___0___residual_conv_weight = None\n",
      "            add__11: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked = add__11 = None\n",
      "            batch_norm_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_11, p_getattr_l__self___ext2___0___residual_norm_weight, p_getattr_l__self___ext2___0___residual_norm_bias, b_getattr_l__self___ext2___0___residual_norm_running_mean, b_getattr_l__self___ext2___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_11 = p_getattr_l__self___ext2___0___residual_norm_weight = p_getattr_l__self___ext2___0___residual_norm_bias = b_getattr_l__self___ext2___0___residual_norm_running_mean = b_getattr_l__self___ext2___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___conv1_weight);  relu__9 = p_getattr_l__self___ext2___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__12: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm1_num_batches_tracked = add__12 = None\n",
      "            batch_norm_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_12, p_getattr_l__self___ext2___0___norm1_weight, p_getattr_l__self___ext2___0___norm1_bias, b_getattr_l__self___ext2___0___norm1_running_mean, b_getattr_l__self___ext2___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_12 = p_getattr_l__self___ext2___0___norm1_weight = p_getattr_l__self___ext2___0___norm1_bias = b_getattr_l__self___ext2___0___norm1_running_mean = b_getattr_l__self___ext2___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__10: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_12);  batch_norm_12 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__10, p_getattr_l__self___ext2___0___conv2_weight, bias = None, stride = [2, 2], padding = [1, 1]);  relu__10 = p_getattr_l__self___ext2___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__13: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm2_num_batches_tracked = add__13 = None\n",
      "            batch_norm_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_13, p_getattr_l__self___ext2___0___norm2_weight, p_getattr_l__self___ext2___0___norm2_bias, b_getattr_l__self___ext2___0___norm2_running_mean, b_getattr_l__self___ext2___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_13 = p_getattr_l__self___ext2___0___norm2_weight = p_getattr_l__self___ext2___0___norm2_bias = b_getattr_l__self___ext2___0___norm2_running_mean = b_getattr_l__self___ext2___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__11: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_13);  batch_norm_13 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__11, p_getattr_l__self___ext2___0___conv3_weight);  relu__11 = p_getattr_l__self___ext2___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__14: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm3_num_batches_tracked = add__14 = None\n",
      "            batch_norm_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_14, p_getattr_l__self___ext2___0___norm3_weight, p_getattr_l__self___ext2___0___norm3_bias, b_getattr_l__self___ext2___0___norm3_running_mean, b_getattr_l__self___ext2___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_14 = p_getattr_l__self___ext2___0___norm3_weight = p_getattr_l__self___ext2___0___norm3_bias = b_getattr_l__self___ext2___0___norm3_running_mean = b_getattr_l__self___ext2___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_3: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_14, batch_norm_11);  batch_norm_14 = batch_norm_11 = None\n",
      "            relu__12: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_3);  add_3 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__12, p_getattr_l__self___ext2___1___conv1_weight);  p_getattr_l__self___ext2___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__15: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm1_num_batches_tracked = add__15 = None\n",
      "            batch_norm_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_15, p_getattr_l__self___ext2___1___norm1_weight, p_getattr_l__self___ext2___1___norm1_bias, b_getattr_l__self___ext2___1___norm1_running_mean, b_getattr_l__self___ext2___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_15 = p_getattr_l__self___ext2___1___norm1_weight = p_getattr_l__self___ext2___1___norm1_bias = b_getattr_l__self___ext2___1___norm1_running_mean = b_getattr_l__self___ext2___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_15);  batch_norm_15 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__13, p_getattr_l__self___ext2___1___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__13 = p_getattr_l__self___ext2___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__16: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm2_num_batches_tracked = add__16 = None\n",
      "            batch_norm_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_16, p_getattr_l__self___ext2___1___norm2_weight, p_getattr_l__self___ext2___1___norm2_bias, b_getattr_l__self___ext2___1___norm2_running_mean, b_getattr_l__self___ext2___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_16 = p_getattr_l__self___ext2___1___norm2_weight = p_getattr_l__self___ext2___1___norm2_bias = b_getattr_l__self___ext2___1___norm2_running_mean = b_getattr_l__self___ext2___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__14: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_16);  batch_norm_16 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__14, p_getattr_l__self___ext2___1___conv3_weight);  relu__14 = p_getattr_l__self___ext2___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__17: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm3_num_batches_tracked = add__17 = None\n",
      "            batch_norm_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_17, p_getattr_l__self___ext2___1___norm3_weight, p_getattr_l__self___ext2___1___norm3_bias, b_getattr_l__self___ext2___1___norm3_running_mean, b_getattr_l__self___ext2___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_17 = p_getattr_l__self___ext2___1___norm3_weight = p_getattr_l__self___ext2___1___norm3_bias = b_getattr_l__self___ext2___1___norm3_running_mean = b_getattr_l__self___ext2___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_4: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_17, relu__12);  batch_norm_17 = relu__12 = None\n",
      "            relu__15: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_4);  add_4 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__15, p_getattr_l__self___ext2___2___conv1_weight);  p_getattr_l__self___ext2___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__18: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm1_num_batches_tracked = add__18 = None\n",
      "            batch_norm_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_18, p_getattr_l__self___ext2___2___norm1_weight, p_getattr_l__self___ext2___2___norm1_bias, b_getattr_l__self___ext2___2___norm1_running_mean, b_getattr_l__self___ext2___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_18 = p_getattr_l__self___ext2___2___norm1_weight = p_getattr_l__self___ext2___2___norm1_bias = b_getattr_l__self___ext2___2___norm1_running_mean = b_getattr_l__self___ext2___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_18);  batch_norm_18 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__16, p_getattr_l__self___ext2___2___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__16 = p_getattr_l__self___ext2___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__19: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm2_num_batches_tracked = add__19 = None\n",
      "            batch_norm_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_19, p_getattr_l__self___ext2___2___norm2_weight, p_getattr_l__self___ext2___2___norm2_bias, b_getattr_l__self___ext2___2___norm2_running_mean, b_getattr_l__self___ext2___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_19 = p_getattr_l__self___ext2___2___norm2_weight = p_getattr_l__self___ext2___2___norm2_bias = b_getattr_l__self___ext2___2___norm2_running_mean = b_getattr_l__self___ext2___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__17: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_19);  batch_norm_19 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__17, p_getattr_l__self___ext2___2___conv3_weight);  relu__17 = p_getattr_l__self___ext2___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__20: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm3_num_batches_tracked = add__20 = None\n",
      "            batch_norm_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_20, p_getattr_l__self___ext2___2___norm3_weight, p_getattr_l__self___ext2___2___norm3_bias, b_getattr_l__self___ext2___2___norm3_running_mean, b_getattr_l__self___ext2___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_20 = p_getattr_l__self___ext2___2___norm3_weight = p_getattr_l__self___ext2___2___norm3_bias = b_getattr_l__self___ext2___2___norm3_running_mean = b_getattr_l__self___ext2___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_5: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_20, relu__15);  batch_norm_20 = relu__15 = None\n",
      "            relu__18: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_5);  add_5 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__18, p_getattr_l__self___ext2___3___conv1_weight);  p_getattr_l__self___ext2___3___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__21: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm1_num_batches_tracked = add__21 = None\n",
      "            batch_norm_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_21, p_getattr_l__self___ext2___3___norm1_weight, p_getattr_l__self___ext2___3___norm1_bias, b_getattr_l__self___ext2___3___norm1_running_mean, b_getattr_l__self___ext2___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_21 = p_getattr_l__self___ext2___3___norm1_weight = p_getattr_l__self___ext2___3___norm1_bias = b_getattr_l__self___ext2___3___norm1_running_mean = b_getattr_l__self___ext2___3___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_21);  batch_norm_21 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__19, p_getattr_l__self___ext2___3___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__19 = p_getattr_l__self___ext2___3___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__22: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm2_num_batches_tracked = add__22 = None\n",
      "            batch_norm_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_22, p_getattr_l__self___ext2___3___norm2_weight, p_getattr_l__self___ext2___3___norm2_bias, b_getattr_l__self___ext2___3___norm2_running_mean, b_getattr_l__self___ext2___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_22 = p_getattr_l__self___ext2___3___norm2_weight = p_getattr_l__self___ext2___3___norm2_bias = b_getattr_l__self___ext2___3___norm2_running_mean = b_getattr_l__self___ext2___3___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__20: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_22);  batch_norm_22 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__20, p_getattr_l__self___ext2___3___conv3_weight);  relu__20 = p_getattr_l__self___ext2___3___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__23: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm3_num_batches_tracked = add__23 = None\n",
      "            batch_norm_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_23, p_getattr_l__self___ext2___3___norm3_weight, p_getattr_l__self___ext2___3___norm3_bias, b_getattr_l__self___ext2___3___norm3_running_mean, b_getattr_l__self___ext2___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_23 = p_getattr_l__self___ext2___3___norm3_weight = p_getattr_l__self___ext2___3___norm3_bias = b_getattr_l__self___ext2___3___norm3_running_mean = b_getattr_l__self___ext2___3___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_6: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_23, relu__18);  batch_norm_23 = relu__18 = None\n",
      "            relu__21: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_6);  add_6 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___residual_conv_weight, bias = None, stride = [2, 2]);  p_getattr_l__self___ext3___0___residual_conv_weight = None\n",
      "            add__24: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked = add__24 = None\n",
      "            batch_norm_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_24, p_getattr_l__self___ext3___0___residual_norm_weight, p_getattr_l__self___ext3___0___residual_norm_bias, b_getattr_l__self___ext3___0___residual_norm_running_mean, b_getattr_l__self___ext3___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_24 = p_getattr_l__self___ext3___0___residual_norm_weight = p_getattr_l__self___ext3___0___residual_norm_bias = b_getattr_l__self___ext3___0___residual_norm_running_mean = b_getattr_l__self___ext3___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___conv1_weight);  relu__21 = p_getattr_l__self___ext3___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__25: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm1_num_batches_tracked = add__25 = None\n",
      "            batch_norm_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_25, p_getattr_l__self___ext3___0___norm1_weight, p_getattr_l__self___ext3___0___norm1_bias, b_getattr_l__self___ext3___0___norm1_running_mean, b_getattr_l__self___ext3___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_25 = p_getattr_l__self___ext3___0___norm1_weight = p_getattr_l__self___ext3___0___norm1_bias = b_getattr_l__self___ext3___0___norm1_running_mean = b_getattr_l__self___ext3___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__22: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_25);  batch_norm_25 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__22, p_getattr_l__self___ext3___0___conv2_weight, bias = None, stride = [2, 2], padding = [1, 1]);  relu__22 = p_getattr_l__self___ext3___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__26: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm2_num_batches_tracked = add__26 = None\n",
      "            batch_norm_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_26, p_getattr_l__self___ext3___0___norm2_weight, p_getattr_l__self___ext3___0___norm2_bias, b_getattr_l__self___ext3___0___norm2_running_mean, b_getattr_l__self___ext3___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_26 = p_getattr_l__self___ext3___0___norm2_weight = p_getattr_l__self___ext3___0___norm2_bias = b_getattr_l__self___ext3___0___norm2_running_mean = b_getattr_l__self___ext3___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__23: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_26);  batch_norm_26 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__23, p_getattr_l__self___ext3___0___conv3_weight);  relu__23 = p_getattr_l__self___ext3___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__27: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm3_num_batches_tracked = add__27 = None\n",
      "            batch_norm_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_27, p_getattr_l__self___ext3___0___norm3_weight, p_getattr_l__self___ext3___0___norm3_bias, b_getattr_l__self___ext3___0___norm3_running_mean, b_getattr_l__self___ext3___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_27 = p_getattr_l__self___ext3___0___norm3_weight = p_getattr_l__self___ext3___0___norm3_bias = b_getattr_l__self___ext3___0___norm3_running_mean = b_getattr_l__self___ext3___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_7: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_27, batch_norm_24);  batch_norm_27 = batch_norm_24 = None\n",
      "            relu__24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_7);  add_7 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__24, p_getattr_l__self___ext3___1___conv1_weight);  p_getattr_l__self___ext3___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__28: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm1_num_batches_tracked = add__28 = None\n",
      "            batch_norm_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_28, p_getattr_l__self___ext3___1___norm1_weight, p_getattr_l__self___ext3___1___norm1_bias, b_getattr_l__self___ext3___1___norm1_running_mean, b_getattr_l__self___ext3___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_28 = p_getattr_l__self___ext3___1___norm1_weight = p_getattr_l__self___ext3___1___norm1_bias = b_getattr_l__self___ext3___1___norm1_running_mean = b_getattr_l__self___ext3___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__25: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_28);  batch_norm_28 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__25, p_getattr_l__self___ext3___1___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__25 = p_getattr_l__self___ext3___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__29: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm2_num_batches_tracked = add__29 = None\n",
      "            batch_norm_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_29, p_getattr_l__self___ext3___1___norm2_weight, p_getattr_l__self___ext3___1___norm2_bias, b_getattr_l__self___ext3___1___norm2_running_mean, b_getattr_l__self___ext3___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_29 = p_getattr_l__self___ext3___1___norm2_weight = p_getattr_l__self___ext3___1___norm2_bias = b_getattr_l__self___ext3___1___norm2_running_mean = b_getattr_l__self___ext3___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_29);  batch_norm_29 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__26, p_getattr_l__self___ext3___1___conv3_weight);  relu__26 = p_getattr_l__self___ext3___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__30: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm3_num_batches_tracked = add__30 = None\n",
      "            batch_norm_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_30, p_getattr_l__self___ext3___1___norm3_weight, p_getattr_l__self___ext3___1___norm3_bias, b_getattr_l__self___ext3___1___norm3_running_mean, b_getattr_l__self___ext3___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_30 = p_getattr_l__self___ext3___1___norm3_weight = p_getattr_l__self___ext3___1___norm3_bias = b_getattr_l__self___ext3___1___norm3_running_mean = b_getattr_l__self___ext3___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_8: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_30, relu__24);  batch_norm_30 = relu__24 = None\n",
      "            relu__27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_8);  add_8 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__27, p_getattr_l__self___ext3___2___conv1_weight);  p_getattr_l__self___ext3___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__31: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm1_num_batches_tracked = add__31 = None\n",
      "            batch_norm_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_31, p_getattr_l__self___ext3___2___norm1_weight, p_getattr_l__self___ext3___2___norm1_bias, b_getattr_l__self___ext3___2___norm1_running_mean, b_getattr_l__self___ext3___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_31 = p_getattr_l__self___ext3___2___norm1_weight = p_getattr_l__self___ext3___2___norm1_bias = b_getattr_l__self___ext3___2___norm1_running_mean = b_getattr_l__self___ext3___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_31);  batch_norm_31 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__28, p_getattr_l__self___ext3___2___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__28 = p_getattr_l__self___ext3___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__32: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm2_num_batches_tracked = add__32 = None\n",
      "            batch_norm_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_32, p_getattr_l__self___ext3___2___norm2_weight, p_getattr_l__self___ext3___2___norm2_bias, b_getattr_l__self___ext3___2___norm2_running_mean, b_getattr_l__self___ext3___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_32 = p_getattr_l__self___ext3___2___norm2_weight = p_getattr_l__self___ext3___2___norm2_bias = b_getattr_l__self___ext3___2___norm2_running_mean = b_getattr_l__self___ext3___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_32);  batch_norm_32 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__29, p_getattr_l__self___ext3___2___conv3_weight);  relu__29 = p_getattr_l__self___ext3___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__33: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm3_num_batches_tracked = add__33 = None\n",
      "            batch_norm_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_33, p_getattr_l__self___ext3___2___norm3_weight, p_getattr_l__self___ext3___2___norm3_bias, b_getattr_l__self___ext3___2___norm3_running_mean, b_getattr_l__self___ext3___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_33 = p_getattr_l__self___ext3___2___norm3_weight = p_getattr_l__self___ext3___2___norm3_bias = b_getattr_l__self___ext3___2___norm3_running_mean = b_getattr_l__self___ext3___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_9: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_33, relu__27);  batch_norm_33 = relu__27 = None\n",
      "            relu__30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_9);  add_9 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__30, p_getattr_l__self___ext3___3___conv1_weight);  p_getattr_l__self___ext3___3___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__34: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm1_num_batches_tracked = add__34 = None\n",
      "            batch_norm_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_34, p_getattr_l__self___ext3___3___norm1_weight, p_getattr_l__self___ext3___3___norm1_bias, b_getattr_l__self___ext3___3___norm1_running_mean, b_getattr_l__self___ext3___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_34 = p_getattr_l__self___ext3___3___norm1_weight = p_getattr_l__self___ext3___3___norm1_bias = b_getattr_l__self___ext3___3___norm1_running_mean = b_getattr_l__self___ext3___3___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_34);  batch_norm_34 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__31, p_getattr_l__self___ext3___3___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__31 = p_getattr_l__self___ext3___3___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__35: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm2_num_batches_tracked = add__35 = None\n",
      "            batch_norm_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_35, p_getattr_l__self___ext3___3___norm2_weight, p_getattr_l__self___ext3___3___norm2_bias, b_getattr_l__self___ext3___3___norm2_running_mean, b_getattr_l__self___ext3___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_35 = p_getattr_l__self___ext3___3___norm2_weight = p_getattr_l__self___ext3___3___norm2_bias = b_getattr_l__self___ext3___3___norm2_running_mean = b_getattr_l__self___ext3___3___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_35);  batch_norm_35 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__32, p_getattr_l__self___ext3___3___conv3_weight);  relu__32 = p_getattr_l__self___ext3___3___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__36: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm3_num_batches_tracked = add__36 = None\n",
      "            batch_norm_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_36, p_getattr_l__self___ext3___3___norm3_weight, p_getattr_l__self___ext3___3___norm3_bias, b_getattr_l__self___ext3___3___norm3_running_mean, b_getattr_l__self___ext3___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_36 = p_getattr_l__self___ext3___3___norm3_weight = p_getattr_l__self___ext3___3___norm3_bias = b_getattr_l__self___ext3___3___norm3_running_mean = b_getattr_l__self___ext3___3___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_10: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_36, relu__30);  batch_norm_36 = relu__30 = None\n",
      "            relu__33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_10);  add_10 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__33, p_getattr_l__self___ext3___4___conv1_weight);  p_getattr_l__self___ext3___4___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__37: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm1_num_batches_tracked = add__37 = None\n",
      "            batch_norm_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_37, p_getattr_l__self___ext3___4___norm1_weight, p_getattr_l__self___ext3___4___norm1_bias, b_getattr_l__self___ext3___4___norm1_running_mean, b_getattr_l__self___ext3___4___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_37 = p_getattr_l__self___ext3___4___norm1_weight = p_getattr_l__self___ext3___4___norm1_bias = b_getattr_l__self___ext3___4___norm1_running_mean = b_getattr_l__self___ext3___4___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_37);  batch_norm_37 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__34, p_getattr_l__self___ext3___4___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__34 = p_getattr_l__self___ext3___4___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__38: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm2_num_batches_tracked = add__38 = None\n",
      "            batch_norm_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_38, p_getattr_l__self___ext3___4___norm2_weight, p_getattr_l__self___ext3___4___norm2_bias, b_getattr_l__self___ext3___4___norm2_running_mean, b_getattr_l__self___ext3___4___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_38 = p_getattr_l__self___ext3___4___norm2_weight = p_getattr_l__self___ext3___4___norm2_bias = b_getattr_l__self___ext3___4___norm2_running_mean = b_getattr_l__self___ext3___4___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_38);  batch_norm_38 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__35, p_getattr_l__self___ext3___4___conv3_weight);  relu__35 = p_getattr_l__self___ext3___4___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__39: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm3_num_batches_tracked = add__39 = None\n",
      "            batch_norm_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_39, p_getattr_l__self___ext3___4___norm3_weight, p_getattr_l__self___ext3___4___norm3_bias, b_getattr_l__self___ext3___4___norm3_running_mean, b_getattr_l__self___ext3___4___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_39 = p_getattr_l__self___ext3___4___norm3_weight = p_getattr_l__self___ext3___4___norm3_bias = b_getattr_l__self___ext3___4___norm3_running_mean = b_getattr_l__self___ext3___4___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_11: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_39, relu__33);  batch_norm_39 = relu__33 = None\n",
      "            relu__36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_11);  add_11 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__36, p_getattr_l__self___ext3___5___conv1_weight);  p_getattr_l__self___ext3___5___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__40: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm1_num_batches_tracked = add__40 = None\n",
      "            batch_norm_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_40, p_getattr_l__self___ext3___5___norm1_weight, p_getattr_l__self___ext3___5___norm1_bias, b_getattr_l__self___ext3___5___norm1_running_mean, b_getattr_l__self___ext3___5___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_40 = p_getattr_l__self___ext3___5___norm1_weight = p_getattr_l__self___ext3___5___norm1_bias = b_getattr_l__self___ext3___5___norm1_running_mean = b_getattr_l__self___ext3___5___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_40);  batch_norm_40 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__37, p_getattr_l__self___ext3___5___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__37 = p_getattr_l__self___ext3___5___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__41: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm2_num_batches_tracked = add__41 = None\n",
      "            batch_norm_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_41, p_getattr_l__self___ext3___5___norm2_weight, p_getattr_l__self___ext3___5___norm2_bias, b_getattr_l__self___ext3___5___norm2_running_mean, b_getattr_l__self___ext3___5___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_41 = p_getattr_l__self___ext3___5___norm2_weight = p_getattr_l__self___ext3___5___norm2_bias = b_getattr_l__self___ext3___5___norm2_running_mean = b_getattr_l__self___ext3___5___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_41);  batch_norm_41 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__38, p_getattr_l__self___ext3___5___conv3_weight);  relu__38 = p_getattr_l__self___ext3___5___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__42: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm3_num_batches_tracked = add__42 = None\n",
      "            batch_norm_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_42, p_getattr_l__self___ext3___5___norm3_weight, p_getattr_l__self___ext3___5___norm3_bias, b_getattr_l__self___ext3___5___norm3_running_mean, b_getattr_l__self___ext3___5___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_42 = p_getattr_l__self___ext3___5___norm3_weight = p_getattr_l__self___ext3___5___norm3_bias = b_getattr_l__self___ext3___5___norm3_running_mean = b_getattr_l__self___ext3___5___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_12: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_42, relu__36);  batch_norm_42 = relu__36 = None\n",
      "            relu__39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_12);  add_12 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:128 in forward, code: res = self.residual(x)\n",
      "            conv2d_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___residual_conv_weight, bias = None, stride = [2, 2]);  p_getattr_l__self___ext4___0___residual_conv_weight = None\n",
      "            add__43: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked = add__43 = None\n",
      "            batch_norm_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_43, p_getattr_l__self___ext4___0___residual_norm_weight, p_getattr_l__self___ext4___0___residual_norm_bias, b_getattr_l__self___ext4___0___residual_norm_running_mean, b_getattr_l__self___ext4___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_43 = p_getattr_l__self___ext4___0___residual_norm_weight = p_getattr_l__self___ext4___0___residual_norm_bias = b_getattr_l__self___ext4___0___residual_norm_running_mean = b_getattr_l__self___ext4___0___residual_norm_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___conv1_weight);  relu__39 = p_getattr_l__self___ext4___0___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__44: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm1_num_batches_tracked = add__44 = None\n",
      "            batch_norm_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_44, p_getattr_l__self___ext4___0___norm1_weight, p_getattr_l__self___ext4___0___norm1_bias, b_getattr_l__self___ext4___0___norm1_running_mean, b_getattr_l__self___ext4___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_44 = p_getattr_l__self___ext4___0___norm1_weight = p_getattr_l__self___ext4___0___norm1_bias = b_getattr_l__self___ext4___0___norm1_running_mean = b_getattr_l__self___ext4___0___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__40: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_44);  batch_norm_44 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__40, p_getattr_l__self___ext4___0___conv2_weight, bias = None, stride = [2, 2], padding = [1, 1]);  relu__40 = p_getattr_l__self___ext4___0___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__45: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm2_num_batches_tracked = add__45 = None\n",
      "            batch_norm_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_45, p_getattr_l__self___ext4___0___norm2_weight, p_getattr_l__self___ext4___0___norm2_bias, b_getattr_l__self___ext4___0___norm2_running_mean, b_getattr_l__self___ext4___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_45 = p_getattr_l__self___ext4___0___norm2_weight = p_getattr_l__self___ext4___0___norm2_bias = b_getattr_l__self___ext4___0___norm2_running_mean = b_getattr_l__self___ext4___0___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__41: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_45);  batch_norm_45 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__41, p_getattr_l__self___ext4___0___conv3_weight);  relu__41 = p_getattr_l__self___ext4___0___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__46: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm3_num_batches_tracked = add__46 = None\n",
      "            batch_norm_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_46, p_getattr_l__self___ext4___0___norm3_weight, p_getattr_l__self___ext4___0___norm3_bias, b_getattr_l__self___ext4___0___norm3_running_mean, b_getattr_l__self___ext4___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_46 = p_getattr_l__self___ext4___0___norm3_weight = p_getattr_l__self___ext4___0___norm3_bias = b_getattr_l__self___ext4___0___norm3_running_mean = b_getattr_l__self___ext4___0___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_13: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_46, batch_norm_43);  batch_norm_46 = batch_norm_43 = None\n",
      "            relu__42: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_13);  add_13 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__42, p_getattr_l__self___ext4___1___conv1_weight);  p_getattr_l__self___ext4___1___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__47: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm1_num_batches_tracked = add__47 = None\n",
      "            batch_norm_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_47, p_getattr_l__self___ext4___1___norm1_weight, p_getattr_l__self___ext4___1___norm1_bias, b_getattr_l__self___ext4___1___norm1_running_mean, b_getattr_l__self___ext4___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_47 = p_getattr_l__self___ext4___1___norm1_weight = p_getattr_l__self___ext4___1___norm1_bias = b_getattr_l__self___ext4___1___norm1_running_mean = b_getattr_l__self___ext4___1___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__43: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_47);  batch_norm_47 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__43, p_getattr_l__self___ext4___1___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__43 = p_getattr_l__self___ext4___1___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__48: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm2_num_batches_tracked = add__48 = None\n",
      "            batch_norm_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_48, p_getattr_l__self___ext4___1___norm2_weight, p_getattr_l__self___ext4___1___norm2_bias, b_getattr_l__self___ext4___1___norm2_running_mean, b_getattr_l__self___ext4___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_48 = p_getattr_l__self___ext4___1___norm2_weight = p_getattr_l__self___ext4___1___norm2_bias = b_getattr_l__self___ext4___1___norm2_running_mean = b_getattr_l__self___ext4___1___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__44: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_48);  batch_norm_48 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__44, p_getattr_l__self___ext4___1___conv3_weight);  relu__44 = p_getattr_l__self___ext4___1___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__49: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm3_num_batches_tracked = add__49 = None\n",
      "            batch_norm_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_49, p_getattr_l__self___ext4___1___norm3_weight, p_getattr_l__self___ext4___1___norm3_bias, b_getattr_l__self___ext4___1___norm3_running_mean, b_getattr_l__self___ext4___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_49 = p_getattr_l__self___ext4___1___norm3_weight = p_getattr_l__self___ext4___1___norm3_bias = b_getattr_l__self___ext4___1___norm3_running_mean = b_getattr_l__self___ext4___1___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_14: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_49, relu__42);  batch_norm_49 = relu__42 = None\n",
      "            relu__45: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_14);  add_14 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:130 in forward, code: out = self.conv1(x)\n",
      "            conv2d_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__45, p_getattr_l__self___ext4___2___conv1_weight);  p_getattr_l__self___ext4___2___conv1_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:131 in forward, code: out = self.norm1(out)\n",
      "            add__50: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm1_num_batches_tracked = add__50 = None\n",
      "            batch_norm_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_50, p_getattr_l__self___ext4___2___norm1_weight, p_getattr_l__self___ext4___2___norm1_bias, b_getattr_l__self___ext4___2___norm1_running_mean, b_getattr_l__self___ext4___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_50 = p_getattr_l__self___ext4___2___norm1_weight = p_getattr_l__self___ext4___2___norm1_bias = b_getattr_l__self___ext4___2___norm1_running_mean = b_getattr_l__self___ext4___2___norm1_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:132 in forward, code: out = self.activation(out)\n",
      "            relu__46: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_50);  batch_norm_50 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:134 in forward, code: out = self.conv2(out)\n",
      "            conv2d_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__46, p_getattr_l__self___ext4___2___conv2_weight, bias = None, stride = [1, 1], padding = [1, 1]);  relu__46 = p_getattr_l__self___ext4___2___conv2_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:135 in forward, code: out = self.norm2(out)\n",
      "            add__51: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm2_num_batches_tracked = add__51 = None\n",
      "            batch_norm_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_51, p_getattr_l__self___ext4___2___norm2_weight, p_getattr_l__self___ext4___2___norm2_bias, b_getattr_l__self___ext4___2___norm2_running_mean, b_getattr_l__self___ext4___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_51 = p_getattr_l__self___ext4___2___norm2_weight = p_getattr_l__self___ext4___2___norm2_bias = b_getattr_l__self___ext4___2___norm2_running_mean = b_getattr_l__self___ext4___2___norm2_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:136 in forward, code: out = self.activation(out)\n",
      "            relu__47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_51);  batch_norm_51 = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:138 in forward, code: out = self.conv3(out)\n",
      "            conv2d_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__47, p_getattr_l__self___ext4___2___conv3_weight);  relu__47 = p_getattr_l__self___ext4___2___conv3_weight = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:139 in forward, code: out = self.norm3(out)\n",
      "            add__52: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm3_num_batches_tracked = add__52 = None\n",
      "            batch_norm_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_52, p_getattr_l__self___ext4___2___norm3_weight, p_getattr_l__self___ext4___2___norm3_bias, b_getattr_l__self___ext4___2___norm3_running_mean, b_getattr_l__self___ext4___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_52 = p_getattr_l__self___ext4___2___norm3_weight = p_getattr_l__self___ext4___2___norm3_bias = b_getattr_l__self___ext4___2___norm3_running_mean = b_getattr_l__self___ext4___2___norm3_running_var = None\n",
      "            \n",
      "             # File: /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:141 in forward, code: return self.activation(out + res)\n",
      "            add_15: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_52, relu__45);  batch_norm_52 = relu__45 = None\n",
      "            relu__48: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_15);  add_15 = None\n",
      "            return (relu__48,)\n",
      "            \n",
      "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_stem_conv_weight'), target='stem.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_stem_norm_weight'), target='stem.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_stem_norm_bias'), target='stem.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___residual_conv_weight'), target='ext1.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___residual_norm_weight'), target='ext1.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___residual_norm_bias'), target='ext1.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___conv1_weight'), target='ext1.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm1_weight'), target='ext1.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm1_bias'), target='ext1.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___conv2_weight'), target='ext1.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm2_weight'), target='ext1.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm2_bias'), target='ext1.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___conv3_weight'), target='ext1.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm3_weight'), target='ext1.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___0___norm3_bias'), target='ext1.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___conv1_weight'), target='ext1.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm1_weight'), target='ext1.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm1_bias'), target='ext1.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___conv2_weight'), target='ext1.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm2_weight'), target='ext1.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm2_bias'), target='ext1.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___conv3_weight'), target='ext1.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm3_weight'), target='ext1.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___1___norm3_bias'), target='ext1.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___conv1_weight'), target='ext1.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm1_weight'), target='ext1.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm1_bias'), target='ext1.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___conv2_weight'), target='ext1.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm2_weight'), target='ext1.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm2_bias'), target='ext1.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___conv3_weight'), target='ext1.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm3_weight'), target='ext1.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext1___2___norm3_bias'), target='ext1.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___residual_conv_weight'), target='ext2.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___residual_norm_weight'), target='ext2.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___residual_norm_bias'), target='ext2.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___conv1_weight'), target='ext2.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm1_weight'), target='ext2.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm1_bias'), target='ext2.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___conv2_weight'), target='ext2.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm2_weight'), target='ext2.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm2_bias'), target='ext2.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___conv3_weight'), target='ext2.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm3_weight'), target='ext2.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___0___norm3_bias'), target='ext2.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___conv1_weight'), target='ext2.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm1_weight'), target='ext2.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm1_bias'), target='ext2.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___conv2_weight'), target='ext2.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm2_weight'), target='ext2.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm2_bias'), target='ext2.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___conv3_weight'), target='ext2.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm3_weight'), target='ext2.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___1___norm3_bias'), target='ext2.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___conv1_weight'), target='ext2.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm1_weight'), target='ext2.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm1_bias'), target='ext2.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___conv2_weight'), target='ext2.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm2_weight'), target='ext2.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm2_bias'), target='ext2.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___conv3_weight'), target='ext2.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm3_weight'), target='ext2.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___2___norm3_bias'), target='ext2.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___conv1_weight'), target='ext2.3.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm1_weight'), target='ext2.3.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm1_bias'), target='ext2.3.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___conv2_weight'), target='ext2.3.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm2_weight'), target='ext2.3.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm2_bias'), target='ext2.3.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___conv3_weight'), target='ext2.3.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm3_weight'), target='ext2.3.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext2___3___norm3_bias'), target='ext2.3.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___residual_conv_weight'), target='ext3.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___residual_norm_weight'), target='ext3.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___residual_norm_bias'), target='ext3.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___conv1_weight'), target='ext3.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm1_weight'), target='ext3.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm1_bias'), target='ext3.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___conv2_weight'), target='ext3.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm2_weight'), target='ext3.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm2_bias'), target='ext3.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___conv3_weight'), target='ext3.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm3_weight'), target='ext3.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___0___norm3_bias'), target='ext3.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___conv1_weight'), target='ext3.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm1_weight'), target='ext3.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm1_bias'), target='ext3.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___conv2_weight'), target='ext3.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm2_weight'), target='ext3.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm2_bias'), target='ext3.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___conv3_weight'), target='ext3.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm3_weight'), target='ext3.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___1___norm3_bias'), target='ext3.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___conv1_weight'), target='ext3.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm1_weight'), target='ext3.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm1_bias'), target='ext3.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___conv2_weight'), target='ext3.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm2_weight'), target='ext3.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm2_bias'), target='ext3.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___conv3_weight'), target='ext3.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm3_weight'), target='ext3.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___2___norm3_bias'), target='ext3.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___conv1_weight'), target='ext3.3.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm1_weight'), target='ext3.3.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm1_bias'), target='ext3.3.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___conv2_weight'), target='ext3.3.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm2_weight'), target='ext3.3.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm2_bias'), target='ext3.3.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___conv3_weight'), target='ext3.3.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm3_weight'), target='ext3.3.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___3___norm3_bias'), target='ext3.3.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___conv1_weight'), target='ext3.4.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm1_weight'), target='ext3.4.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm1_bias'), target='ext3.4.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___conv2_weight'), target='ext3.4.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm2_weight'), target='ext3.4.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm2_bias'), target='ext3.4.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___conv3_weight'), target='ext3.4.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm3_weight'), target='ext3.4.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___4___norm3_bias'), target='ext3.4.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___conv1_weight'), target='ext3.5.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm1_weight'), target='ext3.5.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm1_bias'), target='ext3.5.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___conv2_weight'), target='ext3.5.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm2_weight'), target='ext3.5.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm2_bias'), target='ext3.5.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___conv3_weight'), target='ext3.5.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm3_weight'), target='ext3.5.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext3___5___norm3_bias'), target='ext3.5.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___residual_conv_weight'), target='ext4.0.residual.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___residual_norm_weight'), target='ext4.0.residual.norm.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___residual_norm_bias'), target='ext4.0.residual.norm.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___conv1_weight'), target='ext4.0.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm1_weight'), target='ext4.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm1_bias'), target='ext4.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___conv2_weight'), target='ext4.0.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm2_weight'), target='ext4.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm2_bias'), target='ext4.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___conv3_weight'), target='ext4.0.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm3_weight'), target='ext4.0.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___0___norm3_bias'), target='ext4.0.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___conv1_weight'), target='ext4.1.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm1_weight'), target='ext4.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm1_bias'), target='ext4.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___conv2_weight'), target='ext4.1.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm2_weight'), target='ext4.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm2_bias'), target='ext4.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___conv3_weight'), target='ext4.1.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm3_weight'), target='ext4.1.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___1___norm3_bias'), target='ext4.1.norm3.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___conv1_weight'), target='ext4.2.conv1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm1_weight'), target='ext4.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm1_bias'), target='ext4.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___conv2_weight'), target='ext4.2.conv2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm2_weight'), target='ext4.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm2_bias'), target='ext4.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___conv3_weight'), target='ext4.2.conv3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm3_weight'), target='ext4.2.norm3.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_getattr_l__self___ext4___2___norm3_bias'), target='ext4.2.norm3.bias', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_stem_norm_running_mean'), target='stem.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_stem_norm_running_var'), target='stem.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_stem_norm_num_batches_tracked'), target='stem.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___residual_norm_running_mean'), target='ext1.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___residual_norm_running_var'), target='ext1.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked'), target='ext1.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm1_running_mean'), target='ext1.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm1_running_var'), target='ext1.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm1_num_batches_tracked'), target='ext1.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm2_running_mean'), target='ext1.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm2_running_var'), target='ext1.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm2_num_batches_tracked'), target='ext1.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm3_running_mean'), target='ext1.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm3_running_var'), target='ext1.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___0___norm3_num_batches_tracked'), target='ext1.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm1_running_mean'), target='ext1.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm1_running_var'), target='ext1.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm1_num_batches_tracked'), target='ext1.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm2_running_mean'), target='ext1.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm2_running_var'), target='ext1.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm2_num_batches_tracked'), target='ext1.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm3_running_mean'), target='ext1.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm3_running_var'), target='ext1.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___1___norm3_num_batches_tracked'), target='ext1.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm1_running_mean'), target='ext1.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm1_running_var'), target='ext1.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm1_num_batches_tracked'), target='ext1.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm2_running_mean'), target='ext1.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm2_running_var'), target='ext1.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm2_num_batches_tracked'), target='ext1.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm3_running_mean'), target='ext1.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm3_running_var'), target='ext1.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext1___2___norm3_num_batches_tracked'), target='ext1.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___residual_norm_running_mean'), target='ext2.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___residual_norm_running_var'), target='ext2.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked'), target='ext2.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm1_running_mean'), target='ext2.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm1_running_var'), target='ext2.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm1_num_batches_tracked'), target='ext2.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm2_running_mean'), target='ext2.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm2_running_var'), target='ext2.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm2_num_batches_tracked'), target='ext2.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm3_running_mean'), target='ext2.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm3_running_var'), target='ext2.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___0___norm3_num_batches_tracked'), target='ext2.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm1_running_mean'), target='ext2.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm1_running_var'), target='ext2.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm1_num_batches_tracked'), target='ext2.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm2_running_mean'), target='ext2.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm2_running_var'), target='ext2.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm2_num_batches_tracked'), target='ext2.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm3_running_mean'), target='ext2.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm3_running_var'), target='ext2.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___1___norm3_num_batches_tracked'), target='ext2.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm1_running_mean'), target='ext2.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm1_running_var'), target='ext2.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm1_num_batches_tracked'), target='ext2.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm2_running_mean'), target='ext2.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm2_running_var'), target='ext2.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm2_num_batches_tracked'), target='ext2.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm3_running_mean'), target='ext2.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm3_running_var'), target='ext2.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___2___norm3_num_batches_tracked'), target='ext2.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm1_running_mean'), target='ext2.3.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm1_running_var'), target='ext2.3.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm1_num_batches_tracked'), target='ext2.3.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm2_running_mean'), target='ext2.3.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm2_running_var'), target='ext2.3.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm2_num_batches_tracked'), target='ext2.3.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm3_running_mean'), target='ext2.3.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm3_running_var'), target='ext2.3.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext2___3___norm3_num_batches_tracked'), target='ext2.3.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___residual_norm_running_mean'), target='ext3.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___residual_norm_running_var'), target='ext3.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked'), target='ext3.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm1_running_mean'), target='ext3.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm1_running_var'), target='ext3.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm1_num_batches_tracked'), target='ext3.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm2_running_mean'), target='ext3.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm2_running_var'), target='ext3.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm2_num_batches_tracked'), target='ext3.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm3_running_mean'), target='ext3.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm3_running_var'), target='ext3.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___0___norm3_num_batches_tracked'), target='ext3.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm1_running_mean'), target='ext3.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm1_running_var'), target='ext3.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm1_num_batches_tracked'), target='ext3.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm2_running_mean'), target='ext3.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm2_running_var'), target='ext3.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm2_num_batches_tracked'), target='ext3.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm3_running_mean'), target='ext3.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm3_running_var'), target='ext3.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___1___norm3_num_batches_tracked'), target='ext3.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm1_running_mean'), target='ext3.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm1_running_var'), target='ext3.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm1_num_batches_tracked'), target='ext3.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm2_running_mean'), target='ext3.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm2_running_var'), target='ext3.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm2_num_batches_tracked'), target='ext3.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm3_running_mean'), target='ext3.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm3_running_var'), target='ext3.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___2___norm3_num_batches_tracked'), target='ext3.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm1_running_mean'), target='ext3.3.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm1_running_var'), target='ext3.3.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm1_num_batches_tracked'), target='ext3.3.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm2_running_mean'), target='ext3.3.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm2_running_var'), target='ext3.3.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm2_num_batches_tracked'), target='ext3.3.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm3_running_mean'), target='ext3.3.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm3_running_var'), target='ext3.3.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___3___norm3_num_batches_tracked'), target='ext3.3.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm1_running_mean'), target='ext3.4.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm1_running_var'), target='ext3.4.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm1_num_batches_tracked'), target='ext3.4.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm2_running_mean'), target='ext3.4.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm2_running_var'), target='ext3.4.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm2_num_batches_tracked'), target='ext3.4.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm3_running_mean'), target='ext3.4.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm3_running_var'), target='ext3.4.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___4___norm3_num_batches_tracked'), target='ext3.4.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm1_running_mean'), target='ext3.5.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm1_running_var'), target='ext3.5.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm1_num_batches_tracked'), target='ext3.5.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm2_running_mean'), target='ext3.5.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm2_running_var'), target='ext3.5.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm2_num_batches_tracked'), target='ext3.5.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm3_running_mean'), target='ext3.5.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm3_running_var'), target='ext3.5.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext3___5___norm3_num_batches_tracked'), target='ext3.5.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___residual_norm_running_mean'), target='ext4.0.residual.norm.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___residual_norm_running_var'), target='ext4.0.residual.norm.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked'), target='ext4.0.residual.norm.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm1_running_mean'), target='ext4.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm1_running_var'), target='ext4.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm1_num_batches_tracked'), target='ext4.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm2_running_mean'), target='ext4.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm2_running_var'), target='ext4.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm2_num_batches_tracked'), target='ext4.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm3_running_mean'), target='ext4.0.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm3_running_var'), target='ext4.0.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___0___norm3_num_batches_tracked'), target='ext4.0.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm1_running_mean'), target='ext4.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm1_running_var'), target='ext4.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm1_num_batches_tracked'), target='ext4.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm2_running_mean'), target='ext4.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm2_running_var'), target='ext4.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm2_num_batches_tracked'), target='ext4.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm3_running_mean'), target='ext4.1.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm3_running_var'), target='ext4.1.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___1___norm3_num_batches_tracked'), target='ext4.1.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm1_running_mean'), target='ext4.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm1_running_var'), target='ext4.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm1_num_batches_tracked'), target='ext4.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm2_running_mean'), target='ext4.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm2_running_var'), target='ext4.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm2_num_batches_tracked'), target='ext4.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm3_running_mean'), target='ext4.2.norm3.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm3_running_var'), target='ext4.2.norm3.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_getattr_l__self___ext4___2___norm3_num_batches_tracked'), target='ext4.2.norm3.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='relu__48'), target=None)])\n",
      "Range constraints: {s0: VR[1, int_oo], 2*s3: VR[256, 1024], 2*s4: VR[256, 1024], s3: VR[128, 512], s4: VR[128, 512]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rn50_load = torch.export.load(\"resnet50.pt2\")\n",
    "\n",
    "print(rn50_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ResNet(torch.nn.Module):\n",
      "    def forward(self, x : torch.Tensor):\n",
      "        # No stacktrace found for following nodes\n",
      "        stem_conv = self.stem.conv(x);  x = None\n",
      "        stem_norm = self.stem.norm(stem_conv);  stem_conv = None\n",
      "        relu = torch.nn.functional.relu(stem_norm, inplace = True);  stem_norm = None\n",
      "        stem_pool = self.stem.pool(relu);  relu = None\n",
      "        ext1_0_residual_conv = getattr(self.ext1, \"0\").residual.conv(stem_pool)\n",
      "        ext1_0_residual_norm = getattr(self.ext1, \"0\").residual.norm(ext1_0_residual_conv);  ext1_0_residual_conv = None\n",
      "        ext1_0_conv1 = getattr(self.ext1, \"0\").conv1(stem_pool);  stem_pool = None\n",
      "        ext1_0_norm1 = getattr(self.ext1, \"0\").norm1(ext1_0_conv1);  ext1_0_conv1 = None\n",
      "        relu_1 = torch.nn.functional.relu(ext1_0_norm1, inplace = True);  ext1_0_norm1 = None\n",
      "        ext1_0_conv2 = getattr(self.ext1, \"0\").conv2(relu_1);  relu_1 = None\n",
      "        ext1_0_norm2 = getattr(self.ext1, \"0\").norm2(ext1_0_conv2);  ext1_0_conv2 = None\n",
      "        relu_2 = torch.nn.functional.relu(ext1_0_norm2, inplace = True);  ext1_0_norm2 = None\n",
      "        ext1_0_conv3 = getattr(self.ext1, \"0\").conv3(relu_2);  relu_2 = None\n",
      "        ext1_0_norm3 = getattr(self.ext1, \"0\").norm3(ext1_0_conv3);  ext1_0_conv3 = None\n",
      "        add = ext1_0_norm3 + ext1_0_residual_norm;  ext1_0_norm3 = ext1_0_residual_norm = None\n",
      "        relu_3 = torch.nn.functional.relu(add, inplace = True);  add = None\n",
      "        ext1_1_residual = getattr(self.ext1, \"1\").residual(relu_3)\n",
      "        ext1_1_conv1 = getattr(self.ext1, \"1\").conv1(relu_3);  relu_3 = None\n",
      "        ext1_1_norm1 = getattr(self.ext1, \"1\").norm1(ext1_1_conv1);  ext1_1_conv1 = None\n",
      "        relu_4 = torch.nn.functional.relu(ext1_1_norm1, inplace = True);  ext1_1_norm1 = None\n",
      "        ext1_1_conv2 = getattr(self.ext1, \"1\").conv2(relu_4);  relu_4 = None\n",
      "        ext1_1_norm2 = getattr(self.ext1, \"1\").norm2(ext1_1_conv2);  ext1_1_conv2 = None\n",
      "        relu_5 = torch.nn.functional.relu(ext1_1_norm2, inplace = True);  ext1_1_norm2 = None\n",
      "        ext1_1_conv3 = getattr(self.ext1, \"1\").conv3(relu_5);  relu_5 = None\n",
      "        ext1_1_norm3 = getattr(self.ext1, \"1\").norm3(ext1_1_conv3);  ext1_1_conv3 = None\n",
      "        add_1 = ext1_1_norm3 + ext1_1_residual;  ext1_1_norm3 = ext1_1_residual = None\n",
      "        relu_6 = torch.nn.functional.relu(add_1, inplace = True);  add_1 = None\n",
      "        ext1_2_residual = getattr(self.ext1, \"2\").residual(relu_6)\n",
      "        ext1_2_conv1 = getattr(self.ext1, \"2\").conv1(relu_6);  relu_6 = None\n",
      "        ext1_2_norm1 = getattr(self.ext1, \"2\").norm1(ext1_2_conv1);  ext1_2_conv1 = None\n",
      "        relu_7 = torch.nn.functional.relu(ext1_2_norm1, inplace = True);  ext1_2_norm1 = None\n",
      "        ext1_2_conv2 = getattr(self.ext1, \"2\").conv2(relu_7);  relu_7 = None\n",
      "        ext1_2_norm2 = getattr(self.ext1, \"2\").norm2(ext1_2_conv2);  ext1_2_conv2 = None\n",
      "        relu_8 = torch.nn.functional.relu(ext1_2_norm2, inplace = True);  ext1_2_norm2 = None\n",
      "        ext1_2_conv3 = getattr(self.ext1, \"2\").conv3(relu_8);  relu_8 = None\n",
      "        ext1_2_norm3 = getattr(self.ext1, \"2\").norm3(ext1_2_conv3);  ext1_2_conv3 = None\n",
      "        add_2 = ext1_2_norm3 + ext1_2_residual;  ext1_2_norm3 = ext1_2_residual = None\n",
      "        relu_9 = torch.nn.functional.relu(add_2, inplace = True);  add_2 = None\n",
      "        ext2_0_residual_conv = getattr(self.ext2, \"0\").residual.conv(relu_9)\n",
      "        ext2_0_residual_norm = getattr(self.ext2, \"0\").residual.norm(ext2_0_residual_conv);  ext2_0_residual_conv = None\n",
      "        ext2_0_conv1 = getattr(self.ext2, \"0\").conv1(relu_9)\n",
      "        ext2_0_norm1 = getattr(self.ext2, \"0\").norm1(ext2_0_conv1);  ext2_0_conv1 = None\n",
      "        relu_10 = torch.nn.functional.relu(ext2_0_norm1, inplace = True);  ext2_0_norm1 = None\n",
      "        ext2_0_conv2 = getattr(self.ext2, \"0\").conv2(relu_10);  relu_10 = None\n",
      "        ext2_0_norm2 = getattr(self.ext2, \"0\").norm2(ext2_0_conv2);  ext2_0_conv2 = None\n",
      "        relu_11 = torch.nn.functional.relu(ext2_0_norm2, inplace = True);  ext2_0_norm2 = None\n",
      "        ext2_0_conv3 = getattr(self.ext2, \"0\").conv3(relu_11);  relu_11 = None\n",
      "        ext2_0_norm3 = getattr(self.ext2, \"0\").norm3(ext2_0_conv3);  ext2_0_conv3 = None\n",
      "        add_3 = ext2_0_norm3 + ext2_0_residual_norm;  ext2_0_norm3 = ext2_0_residual_norm = None\n",
      "        relu_12 = torch.nn.functional.relu(add_3, inplace = True);  add_3 = None\n",
      "        ext2_1_residual = getattr(self.ext2, \"1\").residual(relu_12)\n",
      "        ext2_1_conv1 = getattr(self.ext2, \"1\").conv1(relu_12);  relu_12 = None\n",
      "        ext2_1_norm1 = getattr(self.ext2, \"1\").norm1(ext2_1_conv1);  ext2_1_conv1 = None\n",
      "        relu_13 = torch.nn.functional.relu(ext2_1_norm1, inplace = True);  ext2_1_norm1 = None\n",
      "        ext2_1_conv2 = getattr(self.ext2, \"1\").conv2(relu_13);  relu_13 = None\n",
      "        ext2_1_norm2 = getattr(self.ext2, \"1\").norm2(ext2_1_conv2);  ext2_1_conv2 = None\n",
      "        relu_14 = torch.nn.functional.relu(ext2_1_norm2, inplace = True);  ext2_1_norm2 = None\n",
      "        ext2_1_conv3 = getattr(self.ext2, \"1\").conv3(relu_14);  relu_14 = None\n",
      "        ext2_1_norm3 = getattr(self.ext2, \"1\").norm3(ext2_1_conv3);  ext2_1_conv3 = None\n",
      "        add_4 = ext2_1_norm3 + ext2_1_residual;  ext2_1_norm3 = ext2_1_residual = None\n",
      "        relu_15 = torch.nn.functional.relu(add_4, inplace = True);  add_4 = None\n",
      "        ext2_2_residual = getattr(self.ext2, \"2\").residual(relu_15)\n",
      "        ext2_2_conv1 = getattr(self.ext2, \"2\").conv1(relu_15);  relu_15 = None\n",
      "        ext2_2_norm1 = getattr(self.ext2, \"2\").norm1(ext2_2_conv1);  ext2_2_conv1 = None\n",
      "        relu_16 = torch.nn.functional.relu(ext2_2_norm1, inplace = True);  ext2_2_norm1 = None\n",
      "        ext2_2_conv2 = getattr(self.ext2, \"2\").conv2(relu_16);  relu_16 = None\n",
      "        ext2_2_norm2 = getattr(self.ext2, \"2\").norm2(ext2_2_conv2);  ext2_2_conv2 = None\n",
      "        relu_17 = torch.nn.functional.relu(ext2_2_norm2, inplace = True);  ext2_2_norm2 = None\n",
      "        ext2_2_conv3 = getattr(self.ext2, \"2\").conv3(relu_17);  relu_17 = None\n",
      "        ext2_2_norm3 = getattr(self.ext2, \"2\").norm3(ext2_2_conv3);  ext2_2_conv3 = None\n",
      "        add_5 = ext2_2_norm3 + ext2_2_residual;  ext2_2_norm3 = ext2_2_residual = None\n",
      "        relu_18 = torch.nn.functional.relu(add_5, inplace = True);  add_5 = None\n",
      "        ext2_3_residual = getattr(self.ext2, \"3\").residual(relu_18)\n",
      "        ext2_3_conv1 = getattr(self.ext2, \"3\").conv1(relu_18);  relu_18 = None\n",
      "        ext2_3_norm1 = getattr(self.ext2, \"3\").norm1(ext2_3_conv1);  ext2_3_conv1 = None\n",
      "        relu_19 = torch.nn.functional.relu(ext2_3_norm1, inplace = True);  ext2_3_norm1 = None\n",
      "        ext2_3_conv2 = getattr(self.ext2, \"3\").conv2(relu_19);  relu_19 = None\n",
      "        ext2_3_norm2 = getattr(self.ext2, \"3\").norm2(ext2_3_conv2);  ext2_3_conv2 = None\n",
      "        relu_20 = torch.nn.functional.relu(ext2_3_norm2, inplace = True);  ext2_3_norm2 = None\n",
      "        ext2_3_conv3 = getattr(self.ext2, \"3\").conv3(relu_20);  relu_20 = None\n",
      "        ext2_3_norm3 = getattr(self.ext2, \"3\").norm3(ext2_3_conv3);  ext2_3_conv3 = None\n",
      "        add_6 = ext2_3_norm3 + ext2_3_residual;  ext2_3_norm3 = ext2_3_residual = None\n",
      "        relu_21 = torch.nn.functional.relu(add_6, inplace = True);  add_6 = None\n",
      "        ext3_0_residual_conv = getattr(self.ext3, \"0\").residual.conv(relu_21)\n",
      "        ext3_0_residual_norm = getattr(self.ext3, \"0\").residual.norm(ext3_0_residual_conv);  ext3_0_residual_conv = None\n",
      "        ext3_0_conv1 = getattr(self.ext3, \"0\").conv1(relu_21)\n",
      "        ext3_0_norm1 = getattr(self.ext3, \"0\").norm1(ext3_0_conv1);  ext3_0_conv1 = None\n",
      "        relu_22 = torch.nn.functional.relu(ext3_0_norm1, inplace = True);  ext3_0_norm1 = None\n",
      "        ext3_0_conv2 = getattr(self.ext3, \"0\").conv2(relu_22);  relu_22 = None\n",
      "        ext3_0_norm2 = getattr(self.ext3, \"0\").norm2(ext3_0_conv2);  ext3_0_conv2 = None\n",
      "        relu_23 = torch.nn.functional.relu(ext3_0_norm2, inplace = True);  ext3_0_norm2 = None\n",
      "        ext3_0_conv3 = getattr(self.ext3, \"0\").conv3(relu_23);  relu_23 = None\n",
      "        ext3_0_norm3 = getattr(self.ext3, \"0\").norm3(ext3_0_conv3);  ext3_0_conv3 = None\n",
      "        add_7 = ext3_0_norm3 + ext3_0_residual_norm;  ext3_0_norm3 = ext3_0_residual_norm = None\n",
      "        relu_24 = torch.nn.functional.relu(add_7, inplace = True);  add_7 = None\n",
      "        ext3_1_residual = getattr(self.ext3, \"1\").residual(relu_24)\n",
      "        ext3_1_conv1 = getattr(self.ext3, \"1\").conv1(relu_24);  relu_24 = None\n",
      "        ext3_1_norm1 = getattr(self.ext3, \"1\").norm1(ext3_1_conv1);  ext3_1_conv1 = None\n",
      "        relu_25 = torch.nn.functional.relu(ext3_1_norm1, inplace = True);  ext3_1_norm1 = None\n",
      "        ext3_1_conv2 = getattr(self.ext3, \"1\").conv2(relu_25);  relu_25 = None\n",
      "        ext3_1_norm2 = getattr(self.ext3, \"1\").norm2(ext3_1_conv2);  ext3_1_conv2 = None\n",
      "        relu_26 = torch.nn.functional.relu(ext3_1_norm2, inplace = True);  ext3_1_norm2 = None\n",
      "        ext3_1_conv3 = getattr(self.ext3, \"1\").conv3(relu_26);  relu_26 = None\n",
      "        ext3_1_norm3 = getattr(self.ext3, \"1\").norm3(ext3_1_conv3);  ext3_1_conv3 = None\n",
      "        add_8 = ext3_1_norm3 + ext3_1_residual;  ext3_1_norm3 = ext3_1_residual = None\n",
      "        relu_27 = torch.nn.functional.relu(add_8, inplace = True);  add_8 = None\n",
      "        ext3_2_residual = getattr(self.ext3, \"2\").residual(relu_27)\n",
      "        ext3_2_conv1 = getattr(self.ext3, \"2\").conv1(relu_27);  relu_27 = None\n",
      "        ext3_2_norm1 = getattr(self.ext3, \"2\").norm1(ext3_2_conv1);  ext3_2_conv1 = None\n",
      "        relu_28 = torch.nn.functional.relu(ext3_2_norm1, inplace = True);  ext3_2_norm1 = None\n",
      "        ext3_2_conv2 = getattr(self.ext3, \"2\").conv2(relu_28);  relu_28 = None\n",
      "        ext3_2_norm2 = getattr(self.ext3, \"2\").norm2(ext3_2_conv2);  ext3_2_conv2 = None\n",
      "        relu_29 = torch.nn.functional.relu(ext3_2_norm2, inplace = True);  ext3_2_norm2 = None\n",
      "        ext3_2_conv3 = getattr(self.ext3, \"2\").conv3(relu_29);  relu_29 = None\n",
      "        ext3_2_norm3 = getattr(self.ext3, \"2\").norm3(ext3_2_conv3);  ext3_2_conv3 = None\n",
      "        add_9 = ext3_2_norm3 + ext3_2_residual;  ext3_2_norm3 = ext3_2_residual = None\n",
      "        relu_30 = torch.nn.functional.relu(add_9, inplace = True);  add_9 = None\n",
      "        ext3_3_residual = getattr(self.ext3, \"3\").residual(relu_30)\n",
      "        ext3_3_conv1 = getattr(self.ext3, \"3\").conv1(relu_30);  relu_30 = None\n",
      "        ext3_3_norm1 = getattr(self.ext3, \"3\").norm1(ext3_3_conv1);  ext3_3_conv1 = None\n",
      "        relu_31 = torch.nn.functional.relu(ext3_3_norm1, inplace = True);  ext3_3_norm1 = None\n",
      "        ext3_3_conv2 = getattr(self.ext3, \"3\").conv2(relu_31);  relu_31 = None\n",
      "        ext3_3_norm2 = getattr(self.ext3, \"3\").norm2(ext3_3_conv2);  ext3_3_conv2 = None\n",
      "        relu_32 = torch.nn.functional.relu(ext3_3_norm2, inplace = True);  ext3_3_norm2 = None\n",
      "        ext3_3_conv3 = getattr(self.ext3, \"3\").conv3(relu_32);  relu_32 = None\n",
      "        ext3_3_norm3 = getattr(self.ext3, \"3\").norm3(ext3_3_conv3);  ext3_3_conv3 = None\n",
      "        add_10 = ext3_3_norm3 + ext3_3_residual;  ext3_3_norm3 = ext3_3_residual = None\n",
      "        relu_33 = torch.nn.functional.relu(add_10, inplace = True);  add_10 = None\n",
      "        ext3_4_residual = getattr(self.ext3, \"4\").residual(relu_33)\n",
      "        ext3_4_conv1 = getattr(self.ext3, \"4\").conv1(relu_33);  relu_33 = None\n",
      "        ext3_4_norm1 = getattr(self.ext3, \"4\").norm1(ext3_4_conv1);  ext3_4_conv1 = None\n",
      "        relu_34 = torch.nn.functional.relu(ext3_4_norm1, inplace = True);  ext3_4_norm1 = None\n",
      "        ext3_4_conv2 = getattr(self.ext3, \"4\").conv2(relu_34);  relu_34 = None\n",
      "        ext3_4_norm2 = getattr(self.ext3, \"4\").norm2(ext3_4_conv2);  ext3_4_conv2 = None\n",
      "        relu_35 = torch.nn.functional.relu(ext3_4_norm2, inplace = True);  ext3_4_norm2 = None\n",
      "        ext3_4_conv3 = getattr(self.ext3, \"4\").conv3(relu_35);  relu_35 = None\n",
      "        ext3_4_norm3 = getattr(self.ext3, \"4\").norm3(ext3_4_conv3);  ext3_4_conv3 = None\n",
      "        add_11 = ext3_4_norm3 + ext3_4_residual;  ext3_4_norm3 = ext3_4_residual = None\n",
      "        relu_36 = torch.nn.functional.relu(add_11, inplace = True);  add_11 = None\n",
      "        ext3_5_residual = getattr(self.ext3, \"5\").residual(relu_36)\n",
      "        ext3_5_conv1 = getattr(self.ext3, \"5\").conv1(relu_36);  relu_36 = None\n",
      "        ext3_5_norm1 = getattr(self.ext3, \"5\").norm1(ext3_5_conv1);  ext3_5_conv1 = None\n",
      "        relu_37 = torch.nn.functional.relu(ext3_5_norm1, inplace = True);  ext3_5_norm1 = None\n",
      "        ext3_5_conv2 = getattr(self.ext3, \"5\").conv2(relu_37);  relu_37 = None\n",
      "        ext3_5_norm2 = getattr(self.ext3, \"5\").norm2(ext3_5_conv2);  ext3_5_conv2 = None\n",
      "        relu_38 = torch.nn.functional.relu(ext3_5_norm2, inplace = True);  ext3_5_norm2 = None\n",
      "        ext3_5_conv3 = getattr(self.ext3, \"5\").conv3(relu_38);  relu_38 = None\n",
      "        ext3_5_norm3 = getattr(self.ext3, \"5\").norm3(ext3_5_conv3);  ext3_5_conv3 = None\n",
      "        add_12 = ext3_5_norm3 + ext3_5_residual;  ext3_5_norm3 = ext3_5_residual = None\n",
      "        relu_39 = torch.nn.functional.relu(add_12, inplace = True);  add_12 = None\n",
      "        ext4_0_residual_conv = getattr(self.ext4, \"0\").residual.conv(relu_39)\n",
      "        ext4_0_residual_norm = getattr(self.ext4, \"0\").residual.norm(ext4_0_residual_conv);  ext4_0_residual_conv = None\n",
      "        ext4_0_conv1 = getattr(self.ext4, \"0\").conv1(relu_39)\n",
      "        ext4_0_norm1 = getattr(self.ext4, \"0\").norm1(ext4_0_conv1);  ext4_0_conv1 = None\n",
      "        relu_40 = torch.nn.functional.relu(ext4_0_norm1, inplace = True);  ext4_0_norm1 = None\n",
      "        ext4_0_conv2 = getattr(self.ext4, \"0\").conv2(relu_40);  relu_40 = None\n",
      "        ext4_0_norm2 = getattr(self.ext4, \"0\").norm2(ext4_0_conv2);  ext4_0_conv2 = None\n",
      "        relu_41 = torch.nn.functional.relu(ext4_0_norm2, inplace = True);  ext4_0_norm2 = None\n",
      "        ext4_0_conv3 = getattr(self.ext4, \"0\").conv3(relu_41);  relu_41 = None\n",
      "        ext4_0_norm3 = getattr(self.ext4, \"0\").norm3(ext4_0_conv3);  ext4_0_conv3 = None\n",
      "        add_13 = ext4_0_norm3 + ext4_0_residual_norm;  ext4_0_norm3 = ext4_0_residual_norm = None\n",
      "        relu_42 = torch.nn.functional.relu(add_13, inplace = True);  add_13 = None\n",
      "        ext4_1_residual = getattr(self.ext4, \"1\").residual(relu_42)\n",
      "        ext4_1_conv1 = getattr(self.ext4, \"1\").conv1(relu_42);  relu_42 = None\n",
      "        ext4_1_norm1 = getattr(self.ext4, \"1\").norm1(ext4_1_conv1);  ext4_1_conv1 = None\n",
      "        relu_43 = torch.nn.functional.relu(ext4_1_norm1, inplace = True);  ext4_1_norm1 = None\n",
      "        ext4_1_conv2 = getattr(self.ext4, \"1\").conv2(relu_43);  relu_43 = None\n",
      "        ext4_1_norm2 = getattr(self.ext4, \"1\").norm2(ext4_1_conv2);  ext4_1_conv2 = None\n",
      "        relu_44 = torch.nn.functional.relu(ext4_1_norm2, inplace = True);  ext4_1_norm2 = None\n",
      "        ext4_1_conv3 = getattr(self.ext4, \"1\").conv3(relu_44);  relu_44 = None\n",
      "        ext4_1_norm3 = getattr(self.ext4, \"1\").norm3(ext4_1_conv3);  ext4_1_conv3 = None\n",
      "        add_14 = ext4_1_norm3 + ext4_1_residual;  ext4_1_norm3 = ext4_1_residual = None\n",
      "        relu_45 = torch.nn.functional.relu(add_14, inplace = True);  add_14 = None\n",
      "        ext4_2_residual = getattr(self.ext4, \"2\").residual(relu_45)\n",
      "        ext4_2_conv1 = getattr(self.ext4, \"2\").conv1(relu_45);  relu_45 = None\n",
      "        ext4_2_norm1 = getattr(self.ext4, \"2\").norm1(ext4_2_conv1);  ext4_2_conv1 = None\n",
      "        relu_46 = torch.nn.functional.relu(ext4_2_norm1, inplace = True);  ext4_2_norm1 = None\n",
      "        ext4_2_conv2 = getattr(self.ext4, \"2\").conv2(relu_46);  relu_46 = None\n",
      "        ext4_2_norm2 = getattr(self.ext4, \"2\").norm2(ext4_2_conv2);  ext4_2_conv2 = None\n",
      "        relu_47 = torch.nn.functional.relu(ext4_2_norm2, inplace = True);  ext4_2_norm2 = None\n",
      "        ext4_2_conv3 = getattr(self.ext4, \"2\").conv3(relu_47);  relu_47 = None\n",
      "        ext4_2_norm3 = getattr(self.ext4, \"2\").norm3(ext4_2_conv3);  ext4_2_conv3 = None\n",
      "        add_15 = ext4_2_norm3 + ext4_2_residual;  ext4_2_norm3 = ext4_2_residual = None\n",
      "        relu_48 = torch.nn.functional.relu(add_15, inplace = True);  add_15 = None\n",
      "        return {'ext1': relu_9, 'ext2': relu_21, 'ext3': relu_39, 'ext4': relu_48}\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class ResNet(torch.nn.Module):\\n    def forward(self, x : torch.Tensor):\\n        # No stacktrace found for following nodes\\n        stem_conv = self.stem.conv(x);  x = None\\n        stem_norm = self.stem.norm(stem_conv);  stem_conv = None\\n        relu = torch.nn.functional.relu(stem_norm, inplace = True);  stem_norm = None\\n        stem_pool = self.stem.pool(relu);  relu = None\\n        ext1_0_residual_conv = getattr(self.ext1, \"0\").residual.conv(stem_pool)\\n        ext1_0_residual_norm = getattr(self.ext1, \"0\").residual.norm(ext1_0_residual_conv);  ext1_0_residual_conv = None\\n        ext1_0_conv1 = getattr(self.ext1, \"0\").conv1(stem_pool);  stem_pool = None\\n        ext1_0_norm1 = getattr(self.ext1, \"0\").norm1(ext1_0_conv1);  ext1_0_conv1 = None\\n        relu_1 = torch.nn.functional.relu(ext1_0_norm1, inplace = True);  ext1_0_norm1 = None\\n        ext1_0_conv2 = getattr(self.ext1, \"0\").conv2(relu_1);  relu_1 = None\\n        ext1_0_norm2 = getattr(self.ext1, \"0\").norm2(ext1_0_conv2);  ext1_0_conv2 = None\\n        relu_2 = torch.nn.functional.relu(ext1_0_norm2, inplace = True);  ext1_0_norm2 = None\\n        ext1_0_conv3 = getattr(self.ext1, \"0\").conv3(relu_2);  relu_2 = None\\n        ext1_0_norm3 = getattr(self.ext1, \"0\").norm3(ext1_0_conv3);  ext1_0_conv3 = None\\n        add = ext1_0_norm3 + ext1_0_residual_norm;  ext1_0_norm3 = ext1_0_residual_norm = None\\n        relu_3 = torch.nn.functional.relu(add, inplace = True);  add = None\\n        ext1_1_residual = getattr(self.ext1, \"1\").residual(relu_3)\\n        ext1_1_conv1 = getattr(self.ext1, \"1\").conv1(relu_3);  relu_3 = None\\n        ext1_1_norm1 = getattr(self.ext1, \"1\").norm1(ext1_1_conv1);  ext1_1_conv1 = None\\n        relu_4 = torch.nn.functional.relu(ext1_1_norm1, inplace = True);  ext1_1_norm1 = None\\n        ext1_1_conv2 = getattr(self.ext1, \"1\").conv2(relu_4);  relu_4 = None\\n        ext1_1_norm2 = getattr(self.ext1, \"1\").norm2(ext1_1_conv2);  ext1_1_conv2 = None\\n        relu_5 = torch.nn.functional.relu(ext1_1_norm2, inplace = True);  ext1_1_norm2 = None\\n        ext1_1_conv3 = getattr(self.ext1, \"1\").conv3(relu_5);  relu_5 = None\\n        ext1_1_norm3 = getattr(self.ext1, \"1\").norm3(ext1_1_conv3);  ext1_1_conv3 = None\\n        add_1 = ext1_1_norm3 + ext1_1_residual;  ext1_1_norm3 = ext1_1_residual = None\\n        relu_6 = torch.nn.functional.relu(add_1, inplace = True);  add_1 = None\\n        ext1_2_residual = getattr(self.ext1, \"2\").residual(relu_6)\\n        ext1_2_conv1 = getattr(self.ext1, \"2\").conv1(relu_6);  relu_6 = None\\n        ext1_2_norm1 = getattr(self.ext1, \"2\").norm1(ext1_2_conv1);  ext1_2_conv1 = None\\n        relu_7 = torch.nn.functional.relu(ext1_2_norm1, inplace = True);  ext1_2_norm1 = None\\n        ext1_2_conv2 = getattr(self.ext1, \"2\").conv2(relu_7);  relu_7 = None\\n        ext1_2_norm2 = getattr(self.ext1, \"2\").norm2(ext1_2_conv2);  ext1_2_conv2 = None\\n        relu_8 = torch.nn.functional.relu(ext1_2_norm2, inplace = True);  ext1_2_norm2 = None\\n        ext1_2_conv3 = getattr(self.ext1, \"2\").conv3(relu_8);  relu_8 = None\\n        ext1_2_norm3 = getattr(self.ext1, \"2\").norm3(ext1_2_conv3);  ext1_2_conv3 = None\\n        add_2 = ext1_2_norm3 + ext1_2_residual;  ext1_2_norm3 = ext1_2_residual = None\\n        relu_9 = torch.nn.functional.relu(add_2, inplace = True);  add_2 = None\\n        ext2_0_residual_conv = getattr(self.ext2, \"0\").residual.conv(relu_9)\\n        ext2_0_residual_norm = getattr(self.ext2, \"0\").residual.norm(ext2_0_residual_conv);  ext2_0_residual_conv = None\\n        ext2_0_conv1 = getattr(self.ext2, \"0\").conv1(relu_9)\\n        ext2_0_norm1 = getattr(self.ext2, \"0\").norm1(ext2_0_conv1);  ext2_0_conv1 = None\\n        relu_10 = torch.nn.functional.relu(ext2_0_norm1, inplace = True);  ext2_0_norm1 = None\\n        ext2_0_conv2 = getattr(self.ext2, \"0\").conv2(relu_10);  relu_10 = None\\n        ext2_0_norm2 = getattr(self.ext2, \"0\").norm2(ext2_0_conv2);  ext2_0_conv2 = None\\n        relu_11 = torch.nn.functional.relu(ext2_0_norm2, inplace = True);  ext2_0_norm2 = None\\n        ext2_0_conv3 = getattr(self.ext2, \"0\").conv3(relu_11);  relu_11 = None\\n        ext2_0_norm3 = getattr(self.ext2, \"0\").norm3(ext2_0_conv3);  ext2_0_conv3 = None\\n        add_3 = ext2_0_norm3 + ext2_0_residual_norm;  ext2_0_norm3 = ext2_0_residual_norm = None\\n        relu_12 = torch.nn.functional.relu(add_3, inplace = True);  add_3 = None\\n        ext2_1_residual = getattr(self.ext2, \"1\").residual(relu_12)\\n        ext2_1_conv1 = getattr(self.ext2, \"1\").conv1(relu_12);  relu_12 = None\\n        ext2_1_norm1 = getattr(self.ext2, \"1\").norm1(ext2_1_conv1);  ext2_1_conv1 = None\\n        relu_13 = torch.nn.functional.relu(ext2_1_norm1, inplace = True);  ext2_1_norm1 = None\\n        ext2_1_conv2 = getattr(self.ext2, \"1\").conv2(relu_13);  relu_13 = None\\n        ext2_1_norm2 = getattr(self.ext2, \"1\").norm2(ext2_1_conv2);  ext2_1_conv2 = None\\n        relu_14 = torch.nn.functional.relu(ext2_1_norm2, inplace = True);  ext2_1_norm2 = None\\n        ext2_1_conv3 = getattr(self.ext2, \"1\").conv3(relu_14);  relu_14 = None\\n        ext2_1_norm3 = getattr(self.ext2, \"1\").norm3(ext2_1_conv3);  ext2_1_conv3 = None\\n        add_4 = ext2_1_norm3 + ext2_1_residual;  ext2_1_norm3 = ext2_1_residual = None\\n        relu_15 = torch.nn.functional.relu(add_4, inplace = True);  add_4 = None\\n        ext2_2_residual = getattr(self.ext2, \"2\").residual(relu_15)\\n        ext2_2_conv1 = getattr(self.ext2, \"2\").conv1(relu_15);  relu_15 = None\\n        ext2_2_norm1 = getattr(self.ext2, \"2\").norm1(ext2_2_conv1);  ext2_2_conv1 = None\\n        relu_16 = torch.nn.functional.relu(ext2_2_norm1, inplace = True);  ext2_2_norm1 = None\\n        ext2_2_conv2 = getattr(self.ext2, \"2\").conv2(relu_16);  relu_16 = None\\n        ext2_2_norm2 = getattr(self.ext2, \"2\").norm2(ext2_2_conv2);  ext2_2_conv2 = None\\n        relu_17 = torch.nn.functional.relu(ext2_2_norm2, inplace = True);  ext2_2_norm2 = None\\n        ext2_2_conv3 = getattr(self.ext2, \"2\").conv3(relu_17);  relu_17 = None\\n        ext2_2_norm3 = getattr(self.ext2, \"2\").norm3(ext2_2_conv3);  ext2_2_conv3 = None\\n        add_5 = ext2_2_norm3 + ext2_2_residual;  ext2_2_norm3 = ext2_2_residual = None\\n        relu_18 = torch.nn.functional.relu(add_5, inplace = True);  add_5 = None\\n        ext2_3_residual = getattr(self.ext2, \"3\").residual(relu_18)\\n        ext2_3_conv1 = getattr(self.ext2, \"3\").conv1(relu_18);  relu_18 = None\\n        ext2_3_norm1 = getattr(self.ext2, \"3\").norm1(ext2_3_conv1);  ext2_3_conv1 = None\\n        relu_19 = torch.nn.functional.relu(ext2_3_norm1, inplace = True);  ext2_3_norm1 = None\\n        ext2_3_conv2 = getattr(self.ext2, \"3\").conv2(relu_19);  relu_19 = None\\n        ext2_3_norm2 = getattr(self.ext2, \"3\").norm2(ext2_3_conv2);  ext2_3_conv2 = None\\n        relu_20 = torch.nn.functional.relu(ext2_3_norm2, inplace = True);  ext2_3_norm2 = None\\n        ext2_3_conv3 = getattr(self.ext2, \"3\").conv3(relu_20);  relu_20 = None\\n        ext2_3_norm3 = getattr(self.ext2, \"3\").norm3(ext2_3_conv3);  ext2_3_conv3 = None\\n        add_6 = ext2_3_norm3 + ext2_3_residual;  ext2_3_norm3 = ext2_3_residual = None\\n        relu_21 = torch.nn.functional.relu(add_6, inplace = True);  add_6 = None\\n        ext3_0_residual_conv = getattr(self.ext3, \"0\").residual.conv(relu_21)\\n        ext3_0_residual_norm = getattr(self.ext3, \"0\").residual.norm(ext3_0_residual_conv);  ext3_0_residual_conv = None\\n        ext3_0_conv1 = getattr(self.ext3, \"0\").conv1(relu_21)\\n        ext3_0_norm1 = getattr(self.ext3, \"0\").norm1(ext3_0_conv1);  ext3_0_conv1 = None\\n        relu_22 = torch.nn.functional.relu(ext3_0_norm1, inplace = True);  ext3_0_norm1 = None\\n        ext3_0_conv2 = getattr(self.ext3, \"0\").conv2(relu_22);  relu_22 = None\\n        ext3_0_norm2 = getattr(self.ext3, \"0\").norm2(ext3_0_conv2);  ext3_0_conv2 = None\\n        relu_23 = torch.nn.functional.relu(ext3_0_norm2, inplace = True);  ext3_0_norm2 = None\\n        ext3_0_conv3 = getattr(self.ext3, \"0\").conv3(relu_23);  relu_23 = None\\n        ext3_0_norm3 = getattr(self.ext3, \"0\").norm3(ext3_0_conv3);  ext3_0_conv3 = None\\n        add_7 = ext3_0_norm3 + ext3_0_residual_norm;  ext3_0_norm3 = ext3_0_residual_norm = None\\n        relu_24 = torch.nn.functional.relu(add_7, inplace = True);  add_7 = None\\n        ext3_1_residual = getattr(self.ext3, \"1\").residual(relu_24)\\n        ext3_1_conv1 = getattr(self.ext3, \"1\").conv1(relu_24);  relu_24 = None\\n        ext3_1_norm1 = getattr(self.ext3, \"1\").norm1(ext3_1_conv1);  ext3_1_conv1 = None\\n        relu_25 = torch.nn.functional.relu(ext3_1_norm1, inplace = True);  ext3_1_norm1 = None\\n        ext3_1_conv2 = getattr(self.ext3, \"1\").conv2(relu_25);  relu_25 = None\\n        ext3_1_norm2 = getattr(self.ext3, \"1\").norm2(ext3_1_conv2);  ext3_1_conv2 = None\\n        relu_26 = torch.nn.functional.relu(ext3_1_norm2, inplace = True);  ext3_1_norm2 = None\\n        ext3_1_conv3 = getattr(self.ext3, \"1\").conv3(relu_26);  relu_26 = None\\n        ext3_1_norm3 = getattr(self.ext3, \"1\").norm3(ext3_1_conv3);  ext3_1_conv3 = None\\n        add_8 = ext3_1_norm3 + ext3_1_residual;  ext3_1_norm3 = ext3_1_residual = None\\n        relu_27 = torch.nn.functional.relu(add_8, inplace = True);  add_8 = None\\n        ext3_2_residual = getattr(self.ext3, \"2\").residual(relu_27)\\n        ext3_2_conv1 = getattr(self.ext3, \"2\").conv1(relu_27);  relu_27 = None\\n        ext3_2_norm1 = getattr(self.ext3, \"2\").norm1(ext3_2_conv1);  ext3_2_conv1 = None\\n        relu_28 = torch.nn.functional.relu(ext3_2_norm1, inplace = True);  ext3_2_norm1 = None\\n        ext3_2_conv2 = getattr(self.ext3, \"2\").conv2(relu_28);  relu_28 = None\\n        ext3_2_norm2 = getattr(self.ext3, \"2\").norm2(ext3_2_conv2);  ext3_2_conv2 = None\\n        relu_29 = torch.nn.functional.relu(ext3_2_norm2, inplace = True);  ext3_2_norm2 = None\\n        ext3_2_conv3 = getattr(self.ext3, \"2\").conv3(relu_29);  relu_29 = None\\n        ext3_2_norm3 = getattr(self.ext3, \"2\").norm3(ext3_2_conv3);  ext3_2_conv3 = None\\n        add_9 = ext3_2_norm3 + ext3_2_residual;  ext3_2_norm3 = ext3_2_residual = None\\n        relu_30 = torch.nn.functional.relu(add_9, inplace = True);  add_9 = None\\n        ext3_3_residual = getattr(self.ext3, \"3\").residual(relu_30)\\n        ext3_3_conv1 = getattr(self.ext3, \"3\").conv1(relu_30);  relu_30 = None\\n        ext3_3_norm1 = getattr(self.ext3, \"3\").norm1(ext3_3_conv1);  ext3_3_conv1 = None\\n        relu_31 = torch.nn.functional.relu(ext3_3_norm1, inplace = True);  ext3_3_norm1 = None\\n        ext3_3_conv2 = getattr(self.ext3, \"3\").conv2(relu_31);  relu_31 = None\\n        ext3_3_norm2 = getattr(self.ext3, \"3\").norm2(ext3_3_conv2);  ext3_3_conv2 = None\\n        relu_32 = torch.nn.functional.relu(ext3_3_norm2, inplace = True);  ext3_3_norm2 = None\\n        ext3_3_conv3 = getattr(self.ext3, \"3\").conv3(relu_32);  relu_32 = None\\n        ext3_3_norm3 = getattr(self.ext3, \"3\").norm3(ext3_3_conv3);  ext3_3_conv3 = None\\n        add_10 = ext3_3_norm3 + ext3_3_residual;  ext3_3_norm3 = ext3_3_residual = None\\n        relu_33 = torch.nn.functional.relu(add_10, inplace = True);  add_10 = None\\n        ext3_4_residual = getattr(self.ext3, \"4\").residual(relu_33)\\n        ext3_4_conv1 = getattr(self.ext3, \"4\").conv1(relu_33);  relu_33 = None\\n        ext3_4_norm1 = getattr(self.ext3, \"4\").norm1(ext3_4_conv1);  ext3_4_conv1 = None\\n        relu_34 = torch.nn.functional.relu(ext3_4_norm1, inplace = True);  ext3_4_norm1 = None\\n        ext3_4_conv2 = getattr(self.ext3, \"4\").conv2(relu_34);  relu_34 = None\\n        ext3_4_norm2 = getattr(self.ext3, \"4\").norm2(ext3_4_conv2);  ext3_4_conv2 = None\\n        relu_35 = torch.nn.functional.relu(ext3_4_norm2, inplace = True);  ext3_4_norm2 = None\\n        ext3_4_conv3 = getattr(self.ext3, \"4\").conv3(relu_35);  relu_35 = None\\n        ext3_4_norm3 = getattr(self.ext3, \"4\").norm3(ext3_4_conv3);  ext3_4_conv3 = None\\n        add_11 = ext3_4_norm3 + ext3_4_residual;  ext3_4_norm3 = ext3_4_residual = None\\n        relu_36 = torch.nn.functional.relu(add_11, inplace = True);  add_11 = None\\n        ext3_5_residual = getattr(self.ext3, \"5\").residual(relu_36)\\n        ext3_5_conv1 = getattr(self.ext3, \"5\").conv1(relu_36);  relu_36 = None\\n        ext3_5_norm1 = getattr(self.ext3, \"5\").norm1(ext3_5_conv1);  ext3_5_conv1 = None\\n        relu_37 = torch.nn.functional.relu(ext3_5_norm1, inplace = True);  ext3_5_norm1 = None\\n        ext3_5_conv2 = getattr(self.ext3, \"5\").conv2(relu_37);  relu_37 = None\\n        ext3_5_norm2 = getattr(self.ext3, \"5\").norm2(ext3_5_conv2);  ext3_5_conv2 = None\\n        relu_38 = torch.nn.functional.relu(ext3_5_norm2, inplace = True);  ext3_5_norm2 = None\\n        ext3_5_conv3 = getattr(self.ext3, \"5\").conv3(relu_38);  relu_38 = None\\n        ext3_5_norm3 = getattr(self.ext3, \"5\").norm3(ext3_5_conv3);  ext3_5_conv3 = None\\n        add_12 = ext3_5_norm3 + ext3_5_residual;  ext3_5_norm3 = ext3_5_residual = None\\n        relu_39 = torch.nn.functional.relu(add_12, inplace = True);  add_12 = None\\n        ext4_0_residual_conv = getattr(self.ext4, \"0\").residual.conv(relu_39)\\n        ext4_0_residual_norm = getattr(self.ext4, \"0\").residual.norm(ext4_0_residual_conv);  ext4_0_residual_conv = None\\n        ext4_0_conv1 = getattr(self.ext4, \"0\").conv1(relu_39)\\n        ext4_0_norm1 = getattr(self.ext4, \"0\").norm1(ext4_0_conv1);  ext4_0_conv1 = None\\n        relu_40 = torch.nn.functional.relu(ext4_0_norm1, inplace = True);  ext4_0_norm1 = None\\n        ext4_0_conv2 = getattr(self.ext4, \"0\").conv2(relu_40);  relu_40 = None\\n        ext4_0_norm2 = getattr(self.ext4, \"0\").norm2(ext4_0_conv2);  ext4_0_conv2 = None\\n        relu_41 = torch.nn.functional.relu(ext4_0_norm2, inplace = True);  ext4_0_norm2 = None\\n        ext4_0_conv3 = getattr(self.ext4, \"0\").conv3(relu_41);  relu_41 = None\\n        ext4_0_norm3 = getattr(self.ext4, \"0\").norm3(ext4_0_conv3);  ext4_0_conv3 = None\\n        add_13 = ext4_0_norm3 + ext4_0_residual_norm;  ext4_0_norm3 = ext4_0_residual_norm = None\\n        relu_42 = torch.nn.functional.relu(add_13, inplace = True);  add_13 = None\\n        ext4_1_residual = getattr(self.ext4, \"1\").residual(relu_42)\\n        ext4_1_conv1 = getattr(self.ext4, \"1\").conv1(relu_42);  relu_42 = None\\n        ext4_1_norm1 = getattr(self.ext4, \"1\").norm1(ext4_1_conv1);  ext4_1_conv1 = None\\n        relu_43 = torch.nn.functional.relu(ext4_1_norm1, inplace = True);  ext4_1_norm1 = None\\n        ext4_1_conv2 = getattr(self.ext4, \"1\").conv2(relu_43);  relu_43 = None\\n        ext4_1_norm2 = getattr(self.ext4, \"1\").norm2(ext4_1_conv2);  ext4_1_conv2 = None\\n        relu_44 = torch.nn.functional.relu(ext4_1_norm2, inplace = True);  ext4_1_norm2 = None\\n        ext4_1_conv3 = getattr(self.ext4, \"1\").conv3(relu_44);  relu_44 = None\\n        ext4_1_norm3 = getattr(self.ext4, \"1\").norm3(ext4_1_conv3);  ext4_1_conv3 = None\\n        add_14 = ext4_1_norm3 + ext4_1_residual;  ext4_1_norm3 = ext4_1_residual = None\\n        relu_45 = torch.nn.functional.relu(add_14, inplace = True);  add_14 = None\\n        ext4_2_residual = getattr(self.ext4, \"2\").residual(relu_45)\\n        ext4_2_conv1 = getattr(self.ext4, \"2\").conv1(relu_45);  relu_45 = None\\n        ext4_2_norm1 = getattr(self.ext4, \"2\").norm1(ext4_2_conv1);  ext4_2_conv1 = None\\n        relu_46 = torch.nn.functional.relu(ext4_2_norm1, inplace = True);  ext4_2_norm1 = None\\n        ext4_2_conv2 = getattr(self.ext4, \"2\").conv2(relu_46);  relu_46 = None\\n        ext4_2_norm2 = getattr(self.ext4, \"2\").norm2(ext4_2_conv2);  ext4_2_conv2 = None\\n        relu_47 = torch.nn.functional.relu(ext4_2_norm2, inplace = True);  ext4_2_norm2 = None\\n        ext4_2_conv3 = getattr(self.ext4, \"2\").conv3(relu_47);  relu_47 = None\\n        ext4_2_norm3 = getattr(self.ext4, \"2\").norm3(ext4_2_conv3);  ext4_2_conv3 = None\\n        add_15 = ext4_2_norm3 + ext4_2_residual;  ext4_2_norm3 = ext4_2_residual = None\\n        relu_48 = torch.nn.functional.relu(add_15, inplace = True);  add_15 = None\\n        return {\\'ext1\\': relu_9, \\'ext2\\': relu_21, \\'ext3\\': relu_39, \\'ext4\\': relu_48}\\n        '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn50_ft = bb.extract_features(rn50, features=[\"ext1\", \"ext2\", \"ext3\", \"ext4\"])\n",
    "rn50_ft.print_readable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, p_stem_conv_weight: \"f32[64, 3, 7, 7]\", p_stem_norm_weight: \"f32[64]\", p_stem_norm_bias: \"f32[64]\", p_getattr_l__self___ext1___0___residual_conv_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___residual_norm_weight: \"f32[256]\", p_getattr_l__self___ext1___0___residual_norm_bias: \"f32[256]\", p_getattr_l__self___ext1___0___conv1_weight: \"f32[64, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___0___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___0___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___1___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___1___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___1___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___1___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___1___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___2___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___2___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___2___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___2___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___2___norm3_bias: \"f32[256]\", p_getattr_l__self___ext2___0___residual_conv_weight: \"f32[512, 256, 1, 1]\", p_getattr_l__self___ext2___0___residual_norm_weight: \"f32[512]\", p_getattr_l__self___ext2___0___residual_norm_bias: \"f32[512]\", p_getattr_l__self___ext2___0___conv1_weight: \"f32[128, 256, 1, 1]\", p_getattr_l__self___ext2___0___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___0___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___0___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___0___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___1___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___1___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___1___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___1___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___1___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___2___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___2___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___2___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___2___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___2___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___3___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___3___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___3___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___3___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___3___norm3_bias: \"f32[512]\", p_getattr_l__self___ext3___0___residual_conv_weight: \"f32[1024, 512, 1, 1]\", p_getattr_l__self___ext3___0___residual_norm_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___residual_norm_bias: \"f32[1024]\", p_getattr_l__self___ext3___0___conv1_weight: \"f32[256, 512, 1, 1]\", p_getattr_l__self___ext3___0___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___0___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___0___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___1___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___1___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___1___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___1___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___1___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___2___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___2___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___2___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___2___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___2___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___3___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___3___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___3___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___3___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___3___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___4___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___4___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___4___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___4___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___4___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___5___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___5___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___5___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___5___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___5___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext4___0___residual_conv_weight: \"f32[2048, 1024, 1, 1]\", p_getattr_l__self___ext4___0___residual_norm_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___residual_norm_bias: \"f32[2048]\", p_getattr_l__self___ext4___0___conv1_weight: \"f32[512, 1024, 1, 1]\", p_getattr_l__self___ext4___0___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___0___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___0___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___1___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___1___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___1___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___1___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___1___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___2___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___2___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___2___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___2___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___2___norm3_bias: \"f32[2048]\", b_stem_norm_running_mean: \"f32[64]\", b_stem_norm_running_var: \"f32[64]\", b_stem_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___residual_norm_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___residual_norm_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___residual_norm_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___residual_norm_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_num_batches_tracked: \"i64[]\", x: \"f32[s0, 3, 2*s3, 2*s4]\"):\n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:5 in forward, code: stem_conv = self.stem.conv(x);  x = None\n",
      "        conv2d: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.conv2d.default(x, p_stem_conv_weight, None, [2, 2], [3, 3]);  x = p_stem_conv_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:6 in forward, code: stem_norm = self.stem.norm(stem_conv);  stem_conv = None\n",
      "        add_: \"i64[]\" = torch.ops.aten.add_.Tensor(b_stem_norm_num_batches_tracked, 1);  b_stem_norm_num_batches_tracked = add_ = None\n",
      "        batch_norm: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.batch_norm.default(conv2d, p_stem_norm_weight, p_stem_norm_bias, b_stem_norm_running_mean, b_stem_norm_running_var, True, 0.1, 1e-05, True);  conv2d = p_stem_norm_weight = p_stem_norm_bias = b_stem_norm_running_mean = b_stem_norm_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:7 in forward, code: relu = torch.nn.functional.relu(stem_norm, inplace = True);  stem_norm = None\n",
      "        relu_: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.relu_.default(batch_norm);  batch_norm = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:8 in forward, code: stem_pool = self.stem.pool(relu);  relu = None\n",
      "        max_pool2d: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.max_pool2d.default(relu_, [3, 3], [2, 2], [1, 1]);  relu_ = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:9 in forward, code: ext1_0_residual_conv = getattr(self.ext1, \"0\").residual.conv(stem_pool)\n",
      "        conv2d_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___residual_conv_weight);  p_getattr_l__self___ext1___0___residual_conv_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:10 in forward, code: ext1_0_residual_norm = getattr(self.ext1, \"0\").residual.norm(ext1_0_residual_conv);  ext1_0_residual_conv = None\n",
      "        add__1: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked = add__1 = None\n",
      "        batch_norm_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_1, p_getattr_l__self___ext1___0___residual_norm_weight, p_getattr_l__self___ext1___0___residual_norm_bias, b_getattr_l__self___ext1___0___residual_norm_running_mean, b_getattr_l__self___ext1___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_1 = p_getattr_l__self___ext1___0___residual_norm_weight = p_getattr_l__self___ext1___0___residual_norm_bias = b_getattr_l__self___ext1___0___residual_norm_running_mean = b_getattr_l__self___ext1___0___residual_norm_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:11 in forward, code: ext1_0_conv1 = getattr(self.ext1, \"0\").conv1(stem_pool);  stem_pool = None\n",
      "        conv2d_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___conv1_weight);  max_pool2d = p_getattr_l__self___ext1___0___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:12 in forward, code: ext1_0_norm1 = getattr(self.ext1, \"0\").norm1(ext1_0_conv1);  ext1_0_conv1 = None\n",
      "        add__2: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm1_num_batches_tracked = add__2 = None\n",
      "        batch_norm_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_2, p_getattr_l__self___ext1___0___norm1_weight, p_getattr_l__self___ext1___0___norm1_bias, b_getattr_l__self___ext1___0___norm1_running_mean, b_getattr_l__self___ext1___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_2 = p_getattr_l__self___ext1___0___norm1_weight = p_getattr_l__self___ext1___0___norm1_bias = b_getattr_l__self___ext1___0___norm1_running_mean = b_getattr_l__self___ext1___0___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:13 in forward, code: relu_1 = torch.nn.functional.relu(ext1_0_norm1, inplace = True);  ext1_0_norm1 = None\n",
      "        relu__1: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_2);  batch_norm_2 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:14 in forward, code: ext1_0_conv2 = getattr(self.ext1, \"0\").conv2(relu_1);  relu_1 = None\n",
      "        conv2d_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__1, p_getattr_l__self___ext1___0___conv2_weight, None, [1, 1], [1, 1]);  relu__1 = p_getattr_l__self___ext1___0___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:15 in forward, code: ext1_0_norm2 = getattr(self.ext1, \"0\").norm2(ext1_0_conv2);  ext1_0_conv2 = None\n",
      "        add__3: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm2_num_batches_tracked = add__3 = None\n",
      "        batch_norm_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_3, p_getattr_l__self___ext1___0___norm2_weight, p_getattr_l__self___ext1___0___norm2_bias, b_getattr_l__self___ext1___0___norm2_running_mean, b_getattr_l__self___ext1___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_3 = p_getattr_l__self___ext1___0___norm2_weight = p_getattr_l__self___ext1___0___norm2_bias = b_getattr_l__self___ext1___0___norm2_running_mean = b_getattr_l__self___ext1___0___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:16 in forward, code: relu_2 = torch.nn.functional.relu(ext1_0_norm2, inplace = True);  ext1_0_norm2 = None\n",
      "        relu__2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_3);  batch_norm_3 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:17 in forward, code: ext1_0_conv3 = getattr(self.ext1, \"0\").conv3(relu_2);  relu_2 = None\n",
      "        conv2d_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__2, p_getattr_l__self___ext1___0___conv3_weight);  relu__2 = p_getattr_l__self___ext1___0___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:18 in forward, code: ext1_0_norm3 = getattr(self.ext1, \"0\").norm3(ext1_0_conv3);  ext1_0_conv3 = None\n",
      "        add__4: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm3_num_batches_tracked = add__4 = None\n",
      "        batch_norm_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_4, p_getattr_l__self___ext1___0___norm3_weight, p_getattr_l__self___ext1___0___norm3_bias, b_getattr_l__self___ext1___0___norm3_running_mean, b_getattr_l__self___ext1___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_4 = p_getattr_l__self___ext1___0___norm3_weight = p_getattr_l__self___ext1___0___norm3_bias = b_getattr_l__self___ext1___0___norm3_running_mean = b_getattr_l__self___ext1___0___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:19 in forward, code: add = ext1_0_norm3 + ext1_0_residual_norm;  ext1_0_norm3 = ext1_0_residual_norm = None\n",
      "        add: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_4, batch_norm_1);  batch_norm_4 = batch_norm_1 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:20 in forward, code: relu_3 = torch.nn.functional.relu(add, inplace = True);  add = None\n",
      "        relu__3: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add);  add = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:22 in forward, code: ext1_1_conv1 = getattr(self.ext1, \"1\").conv1(relu_3);  relu_3 = None\n",
      "        conv2d_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__3, p_getattr_l__self___ext1___1___conv1_weight);  p_getattr_l__self___ext1___1___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:23 in forward, code: ext1_1_norm1 = getattr(self.ext1, \"1\").norm1(ext1_1_conv1);  ext1_1_conv1 = None\n",
      "        add__5: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm1_num_batches_tracked = add__5 = None\n",
      "        batch_norm_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_5, p_getattr_l__self___ext1___1___norm1_weight, p_getattr_l__self___ext1___1___norm1_bias, b_getattr_l__self___ext1___1___norm1_running_mean, b_getattr_l__self___ext1___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_5 = p_getattr_l__self___ext1___1___norm1_weight = p_getattr_l__self___ext1___1___norm1_bias = b_getattr_l__self___ext1___1___norm1_running_mean = b_getattr_l__self___ext1___1___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:24 in forward, code: relu_4 = torch.nn.functional.relu(ext1_1_norm1, inplace = True);  ext1_1_norm1 = None\n",
      "        relu__4: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_5);  batch_norm_5 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:25 in forward, code: ext1_1_conv2 = getattr(self.ext1, \"1\").conv2(relu_4);  relu_4 = None\n",
      "        conv2d_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__4, p_getattr_l__self___ext1___1___conv2_weight, None, [1, 1], [1, 1]);  relu__4 = p_getattr_l__self___ext1___1___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:26 in forward, code: ext1_1_norm2 = getattr(self.ext1, \"1\").norm2(ext1_1_conv2);  ext1_1_conv2 = None\n",
      "        add__6: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm2_num_batches_tracked = add__6 = None\n",
      "        batch_norm_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_6, p_getattr_l__self___ext1___1___norm2_weight, p_getattr_l__self___ext1___1___norm2_bias, b_getattr_l__self___ext1___1___norm2_running_mean, b_getattr_l__self___ext1___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_6 = p_getattr_l__self___ext1___1___norm2_weight = p_getattr_l__self___ext1___1___norm2_bias = b_getattr_l__self___ext1___1___norm2_running_mean = b_getattr_l__self___ext1___1___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:27 in forward, code: relu_5 = torch.nn.functional.relu(ext1_1_norm2, inplace = True);  ext1_1_norm2 = None\n",
      "        relu__5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_6);  batch_norm_6 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:28 in forward, code: ext1_1_conv3 = getattr(self.ext1, \"1\").conv3(relu_5);  relu_5 = None\n",
      "        conv2d_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__5, p_getattr_l__self___ext1___1___conv3_weight);  relu__5 = p_getattr_l__self___ext1___1___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:29 in forward, code: ext1_1_norm3 = getattr(self.ext1, \"1\").norm3(ext1_1_conv3);  ext1_1_conv3 = None\n",
      "        add__7: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm3_num_batches_tracked = add__7 = None\n",
      "        batch_norm_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_7, p_getattr_l__self___ext1___1___norm3_weight, p_getattr_l__self___ext1___1___norm3_bias, b_getattr_l__self___ext1___1___norm3_running_mean, b_getattr_l__self___ext1___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_7 = p_getattr_l__self___ext1___1___norm3_weight = p_getattr_l__self___ext1___1___norm3_bias = b_getattr_l__self___ext1___1___norm3_running_mean = b_getattr_l__self___ext1___1___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:30 in forward, code: add_1 = ext1_1_norm3 + ext1_1_residual;  ext1_1_norm3 = ext1_1_residual = None\n",
      "        add_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_7, relu__3);  batch_norm_7 = relu__3 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:31 in forward, code: relu_6 = torch.nn.functional.relu(add_1, inplace = True);  add_1 = None\n",
      "        relu__6: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_1);  add_1 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:33 in forward, code: ext1_2_conv1 = getattr(self.ext1, \"2\").conv1(relu_6);  relu_6 = None\n",
      "        conv2d_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__6, p_getattr_l__self___ext1___2___conv1_weight);  p_getattr_l__self___ext1___2___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:34 in forward, code: ext1_2_norm1 = getattr(self.ext1, \"2\").norm1(ext1_2_conv1);  ext1_2_conv1 = None\n",
      "        add__8: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm1_num_batches_tracked = add__8 = None\n",
      "        batch_norm_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_8, p_getattr_l__self___ext1___2___norm1_weight, p_getattr_l__self___ext1___2___norm1_bias, b_getattr_l__self___ext1___2___norm1_running_mean, b_getattr_l__self___ext1___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_8 = p_getattr_l__self___ext1___2___norm1_weight = p_getattr_l__self___ext1___2___norm1_bias = b_getattr_l__self___ext1___2___norm1_running_mean = b_getattr_l__self___ext1___2___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:35 in forward, code: relu_7 = torch.nn.functional.relu(ext1_2_norm1, inplace = True);  ext1_2_norm1 = None\n",
      "        relu__7: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_8);  batch_norm_8 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:36 in forward, code: ext1_2_conv2 = getattr(self.ext1, \"2\").conv2(relu_7);  relu_7 = None\n",
      "        conv2d_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__7, p_getattr_l__self___ext1___2___conv2_weight, None, [1, 1], [1, 1]);  relu__7 = p_getattr_l__self___ext1___2___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:37 in forward, code: ext1_2_norm2 = getattr(self.ext1, \"2\").norm2(ext1_2_conv2);  ext1_2_conv2 = None\n",
      "        add__9: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm2_num_batches_tracked = add__9 = None\n",
      "        batch_norm_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_9, p_getattr_l__self___ext1___2___norm2_weight, p_getattr_l__self___ext1___2___norm2_bias, b_getattr_l__self___ext1___2___norm2_running_mean, b_getattr_l__self___ext1___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_9 = p_getattr_l__self___ext1___2___norm2_weight = p_getattr_l__self___ext1___2___norm2_bias = b_getattr_l__self___ext1___2___norm2_running_mean = b_getattr_l__self___ext1___2___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:38 in forward, code: relu_8 = torch.nn.functional.relu(ext1_2_norm2, inplace = True);  ext1_2_norm2 = None\n",
      "        relu__8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_9);  batch_norm_9 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:39 in forward, code: ext1_2_conv3 = getattr(self.ext1, \"2\").conv3(relu_8);  relu_8 = None\n",
      "        conv2d_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__8, p_getattr_l__self___ext1___2___conv3_weight);  relu__8 = p_getattr_l__self___ext1___2___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:40 in forward, code: ext1_2_norm3 = getattr(self.ext1, \"2\").norm3(ext1_2_conv3);  ext1_2_conv3 = None\n",
      "        add__10: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm3_num_batches_tracked = add__10 = None\n",
      "        batch_norm_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_10, p_getattr_l__self___ext1___2___norm3_weight, p_getattr_l__self___ext1___2___norm3_bias, b_getattr_l__self___ext1___2___norm3_running_mean, b_getattr_l__self___ext1___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_10 = p_getattr_l__self___ext1___2___norm3_weight = p_getattr_l__self___ext1___2___norm3_bias = b_getattr_l__self___ext1___2___norm3_running_mean = b_getattr_l__self___ext1___2___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:41 in forward, code: add_2 = ext1_2_norm3 + ext1_2_residual;  ext1_2_norm3 = ext1_2_residual = None\n",
      "        add_2: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_10, relu__6);  batch_norm_10 = relu__6 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:42 in forward, code: relu_9 = torch.nn.functional.relu(add_2, inplace = True);  add_2 = None\n",
      "        relu__9: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_2);  add_2 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:43 in forward, code: ext2_0_residual_conv = getattr(self.ext2, \"0\").residual.conv(relu_9)\n",
      "        conv2d_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext2___0___residual_conv_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:44 in forward, code: ext2_0_residual_norm = getattr(self.ext2, \"0\").residual.norm(ext2_0_residual_conv);  ext2_0_residual_conv = None\n",
      "        add__11: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked = add__11 = None\n",
      "        batch_norm_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_11, p_getattr_l__self___ext2___0___residual_norm_weight, p_getattr_l__self___ext2___0___residual_norm_bias, b_getattr_l__self___ext2___0___residual_norm_running_mean, b_getattr_l__self___ext2___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_11 = p_getattr_l__self___ext2___0___residual_norm_weight = p_getattr_l__self___ext2___0___residual_norm_bias = b_getattr_l__self___ext2___0___residual_norm_running_mean = b_getattr_l__self___ext2___0___residual_norm_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:45 in forward, code: ext2_0_conv1 = getattr(self.ext2, \"0\").conv1(relu_9)\n",
      "        conv2d_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___conv1_weight);  p_getattr_l__self___ext2___0___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:46 in forward, code: ext2_0_norm1 = getattr(self.ext2, \"0\").norm1(ext2_0_conv1);  ext2_0_conv1 = None\n",
      "        add__12: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm1_num_batches_tracked = add__12 = None\n",
      "        batch_norm_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_12, p_getattr_l__self___ext2___0___norm1_weight, p_getattr_l__self___ext2___0___norm1_bias, b_getattr_l__self___ext2___0___norm1_running_mean, b_getattr_l__self___ext2___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_12 = p_getattr_l__self___ext2___0___norm1_weight = p_getattr_l__self___ext2___0___norm1_bias = b_getattr_l__self___ext2___0___norm1_running_mean = b_getattr_l__self___ext2___0___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:47 in forward, code: relu_10 = torch.nn.functional.relu(ext2_0_norm1, inplace = True);  ext2_0_norm1 = None\n",
      "        relu__10: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_12);  batch_norm_12 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:48 in forward, code: ext2_0_conv2 = getattr(self.ext2, \"0\").conv2(relu_10);  relu_10 = None\n",
      "        conv2d_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__10, p_getattr_l__self___ext2___0___conv2_weight, None, [2, 2], [1, 1]);  relu__10 = p_getattr_l__self___ext2___0___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:49 in forward, code: ext2_0_norm2 = getattr(self.ext2, \"0\").norm2(ext2_0_conv2);  ext2_0_conv2 = None\n",
      "        add__13: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm2_num_batches_tracked = add__13 = None\n",
      "        batch_norm_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_13, p_getattr_l__self___ext2___0___norm2_weight, p_getattr_l__self___ext2___0___norm2_bias, b_getattr_l__self___ext2___0___norm2_running_mean, b_getattr_l__self___ext2___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_13 = p_getattr_l__self___ext2___0___norm2_weight = p_getattr_l__self___ext2___0___norm2_bias = b_getattr_l__self___ext2___0___norm2_running_mean = b_getattr_l__self___ext2___0___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:50 in forward, code: relu_11 = torch.nn.functional.relu(ext2_0_norm2, inplace = True);  ext2_0_norm2 = None\n",
      "        relu__11: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_13);  batch_norm_13 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:51 in forward, code: ext2_0_conv3 = getattr(self.ext2, \"0\").conv3(relu_11);  relu_11 = None\n",
      "        conv2d_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__11, p_getattr_l__self___ext2___0___conv3_weight);  relu__11 = p_getattr_l__self___ext2___0___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:52 in forward, code: ext2_0_norm3 = getattr(self.ext2, \"0\").norm3(ext2_0_conv3);  ext2_0_conv3 = None\n",
      "        add__14: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm3_num_batches_tracked = add__14 = None\n",
      "        batch_norm_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_14, p_getattr_l__self___ext2___0___norm3_weight, p_getattr_l__self___ext2___0___norm3_bias, b_getattr_l__self___ext2___0___norm3_running_mean, b_getattr_l__self___ext2___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_14 = p_getattr_l__self___ext2___0___norm3_weight = p_getattr_l__self___ext2___0___norm3_bias = b_getattr_l__self___ext2___0___norm3_running_mean = b_getattr_l__self___ext2___0___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:53 in forward, code: add_3 = ext2_0_norm3 + ext2_0_residual_norm;  ext2_0_norm3 = ext2_0_residual_norm = None\n",
      "        add_3: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_14, batch_norm_11);  batch_norm_14 = batch_norm_11 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:54 in forward, code: relu_12 = torch.nn.functional.relu(add_3, inplace = True);  add_3 = None\n",
      "        relu__12: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_3);  add_3 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:56 in forward, code: ext2_1_conv1 = getattr(self.ext2, \"1\").conv1(relu_12);  relu_12 = None\n",
      "        conv2d_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__12, p_getattr_l__self___ext2___1___conv1_weight);  p_getattr_l__self___ext2___1___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:57 in forward, code: ext2_1_norm1 = getattr(self.ext2, \"1\").norm1(ext2_1_conv1);  ext2_1_conv1 = None\n",
      "        add__15: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm1_num_batches_tracked = add__15 = None\n",
      "        batch_norm_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_15, p_getattr_l__self___ext2___1___norm1_weight, p_getattr_l__self___ext2___1___norm1_bias, b_getattr_l__self___ext2___1___norm1_running_mean, b_getattr_l__self___ext2___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_15 = p_getattr_l__self___ext2___1___norm1_weight = p_getattr_l__self___ext2___1___norm1_bias = b_getattr_l__self___ext2___1___norm1_running_mean = b_getattr_l__self___ext2___1___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:58 in forward, code: relu_13 = torch.nn.functional.relu(ext2_1_norm1, inplace = True);  ext2_1_norm1 = None\n",
      "        relu__13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_15);  batch_norm_15 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:59 in forward, code: ext2_1_conv2 = getattr(self.ext2, \"1\").conv2(relu_13);  relu_13 = None\n",
      "        conv2d_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__13, p_getattr_l__self___ext2___1___conv2_weight, None, [1, 1], [1, 1]);  relu__13 = p_getattr_l__self___ext2___1___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:60 in forward, code: ext2_1_norm2 = getattr(self.ext2, \"1\").norm2(ext2_1_conv2);  ext2_1_conv2 = None\n",
      "        add__16: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm2_num_batches_tracked = add__16 = None\n",
      "        batch_norm_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_16, p_getattr_l__self___ext2___1___norm2_weight, p_getattr_l__self___ext2___1___norm2_bias, b_getattr_l__self___ext2___1___norm2_running_mean, b_getattr_l__self___ext2___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_16 = p_getattr_l__self___ext2___1___norm2_weight = p_getattr_l__self___ext2___1___norm2_bias = b_getattr_l__self___ext2___1___norm2_running_mean = b_getattr_l__self___ext2___1___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:61 in forward, code: relu_14 = torch.nn.functional.relu(ext2_1_norm2, inplace = True);  ext2_1_norm2 = None\n",
      "        relu__14: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_16);  batch_norm_16 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:62 in forward, code: ext2_1_conv3 = getattr(self.ext2, \"1\").conv3(relu_14);  relu_14 = None\n",
      "        conv2d_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__14, p_getattr_l__self___ext2___1___conv3_weight);  relu__14 = p_getattr_l__self___ext2___1___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:63 in forward, code: ext2_1_norm3 = getattr(self.ext2, \"1\").norm3(ext2_1_conv3);  ext2_1_conv3 = None\n",
      "        add__17: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm3_num_batches_tracked = add__17 = None\n",
      "        batch_norm_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_17, p_getattr_l__self___ext2___1___norm3_weight, p_getattr_l__self___ext2___1___norm3_bias, b_getattr_l__self___ext2___1___norm3_running_mean, b_getattr_l__self___ext2___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_17 = p_getattr_l__self___ext2___1___norm3_weight = p_getattr_l__self___ext2___1___norm3_bias = b_getattr_l__self___ext2___1___norm3_running_mean = b_getattr_l__self___ext2___1___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:64 in forward, code: add_4 = ext2_1_norm3 + ext2_1_residual;  ext2_1_norm3 = ext2_1_residual = None\n",
      "        add_4: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_17, relu__12);  batch_norm_17 = relu__12 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:65 in forward, code: relu_15 = torch.nn.functional.relu(add_4, inplace = True);  add_4 = None\n",
      "        relu__15: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_4);  add_4 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:67 in forward, code: ext2_2_conv1 = getattr(self.ext2, \"2\").conv1(relu_15);  relu_15 = None\n",
      "        conv2d_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__15, p_getattr_l__self___ext2___2___conv1_weight);  p_getattr_l__self___ext2___2___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:68 in forward, code: ext2_2_norm1 = getattr(self.ext2, \"2\").norm1(ext2_2_conv1);  ext2_2_conv1 = None\n",
      "        add__18: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm1_num_batches_tracked = add__18 = None\n",
      "        batch_norm_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_18, p_getattr_l__self___ext2___2___norm1_weight, p_getattr_l__self___ext2___2___norm1_bias, b_getattr_l__self___ext2___2___norm1_running_mean, b_getattr_l__self___ext2___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_18 = p_getattr_l__self___ext2___2___norm1_weight = p_getattr_l__self___ext2___2___norm1_bias = b_getattr_l__self___ext2___2___norm1_running_mean = b_getattr_l__self___ext2___2___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:69 in forward, code: relu_16 = torch.nn.functional.relu(ext2_2_norm1, inplace = True);  ext2_2_norm1 = None\n",
      "        relu__16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_18);  batch_norm_18 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:70 in forward, code: ext2_2_conv2 = getattr(self.ext2, \"2\").conv2(relu_16);  relu_16 = None\n",
      "        conv2d_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__16, p_getattr_l__self___ext2___2___conv2_weight, None, [1, 1], [1, 1]);  relu__16 = p_getattr_l__self___ext2___2___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:71 in forward, code: ext2_2_norm2 = getattr(self.ext2, \"2\").norm2(ext2_2_conv2);  ext2_2_conv2 = None\n",
      "        add__19: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm2_num_batches_tracked = add__19 = None\n",
      "        batch_norm_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_19, p_getattr_l__self___ext2___2___norm2_weight, p_getattr_l__self___ext2___2___norm2_bias, b_getattr_l__self___ext2___2___norm2_running_mean, b_getattr_l__self___ext2___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_19 = p_getattr_l__self___ext2___2___norm2_weight = p_getattr_l__self___ext2___2___norm2_bias = b_getattr_l__self___ext2___2___norm2_running_mean = b_getattr_l__self___ext2___2___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:72 in forward, code: relu_17 = torch.nn.functional.relu(ext2_2_norm2, inplace = True);  ext2_2_norm2 = None\n",
      "        relu__17: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_19);  batch_norm_19 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:73 in forward, code: ext2_2_conv3 = getattr(self.ext2, \"2\").conv3(relu_17);  relu_17 = None\n",
      "        conv2d_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__17, p_getattr_l__self___ext2___2___conv3_weight);  relu__17 = p_getattr_l__self___ext2___2___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:74 in forward, code: ext2_2_norm3 = getattr(self.ext2, \"2\").norm3(ext2_2_conv3);  ext2_2_conv3 = None\n",
      "        add__20: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm3_num_batches_tracked = add__20 = None\n",
      "        batch_norm_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_20, p_getattr_l__self___ext2___2___norm3_weight, p_getattr_l__self___ext2___2___norm3_bias, b_getattr_l__self___ext2___2___norm3_running_mean, b_getattr_l__self___ext2___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_20 = p_getattr_l__self___ext2___2___norm3_weight = p_getattr_l__self___ext2___2___norm3_bias = b_getattr_l__self___ext2___2___norm3_running_mean = b_getattr_l__self___ext2___2___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:75 in forward, code: add_5 = ext2_2_norm3 + ext2_2_residual;  ext2_2_norm3 = ext2_2_residual = None\n",
      "        add_5: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_20, relu__15);  batch_norm_20 = relu__15 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:76 in forward, code: relu_18 = torch.nn.functional.relu(add_5, inplace = True);  add_5 = None\n",
      "        relu__18: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_5);  add_5 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:78 in forward, code: ext2_3_conv1 = getattr(self.ext2, \"3\").conv1(relu_18);  relu_18 = None\n",
      "        conv2d_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__18, p_getattr_l__self___ext2___3___conv1_weight);  p_getattr_l__self___ext2___3___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:79 in forward, code: ext2_3_norm1 = getattr(self.ext2, \"3\").norm1(ext2_3_conv1);  ext2_3_conv1 = None\n",
      "        add__21: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm1_num_batches_tracked = add__21 = None\n",
      "        batch_norm_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_21, p_getattr_l__self___ext2___3___norm1_weight, p_getattr_l__self___ext2___3___norm1_bias, b_getattr_l__self___ext2___3___norm1_running_mean, b_getattr_l__self___ext2___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_21 = p_getattr_l__self___ext2___3___norm1_weight = p_getattr_l__self___ext2___3___norm1_bias = b_getattr_l__self___ext2___3___norm1_running_mean = b_getattr_l__self___ext2___3___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:80 in forward, code: relu_19 = torch.nn.functional.relu(ext2_3_norm1, inplace = True);  ext2_3_norm1 = None\n",
      "        relu__19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_21);  batch_norm_21 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:81 in forward, code: ext2_3_conv2 = getattr(self.ext2, \"3\").conv2(relu_19);  relu_19 = None\n",
      "        conv2d_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__19, p_getattr_l__self___ext2___3___conv2_weight, None, [1, 1], [1, 1]);  relu__19 = p_getattr_l__self___ext2___3___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:82 in forward, code: ext2_3_norm2 = getattr(self.ext2, \"3\").norm2(ext2_3_conv2);  ext2_3_conv2 = None\n",
      "        add__22: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm2_num_batches_tracked = add__22 = None\n",
      "        batch_norm_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_22, p_getattr_l__self___ext2___3___norm2_weight, p_getattr_l__self___ext2___3___norm2_bias, b_getattr_l__self___ext2___3___norm2_running_mean, b_getattr_l__self___ext2___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_22 = p_getattr_l__self___ext2___3___norm2_weight = p_getattr_l__self___ext2___3___norm2_bias = b_getattr_l__self___ext2___3___norm2_running_mean = b_getattr_l__self___ext2___3___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:83 in forward, code: relu_20 = torch.nn.functional.relu(ext2_3_norm2, inplace = True);  ext2_3_norm2 = None\n",
      "        relu__20: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_22);  batch_norm_22 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:84 in forward, code: ext2_3_conv3 = getattr(self.ext2, \"3\").conv3(relu_20);  relu_20 = None\n",
      "        conv2d_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__20, p_getattr_l__self___ext2___3___conv3_weight);  relu__20 = p_getattr_l__self___ext2___3___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:85 in forward, code: ext2_3_norm3 = getattr(self.ext2, \"3\").norm3(ext2_3_conv3);  ext2_3_conv3 = None\n",
      "        add__23: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm3_num_batches_tracked = add__23 = None\n",
      "        batch_norm_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_23, p_getattr_l__self___ext2___3___norm3_weight, p_getattr_l__self___ext2___3___norm3_bias, b_getattr_l__self___ext2___3___norm3_running_mean, b_getattr_l__self___ext2___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_23 = p_getattr_l__self___ext2___3___norm3_weight = p_getattr_l__self___ext2___3___norm3_bias = b_getattr_l__self___ext2___3___norm3_running_mean = b_getattr_l__self___ext2___3___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:86 in forward, code: add_6 = ext2_3_norm3 + ext2_3_residual;  ext2_3_norm3 = ext2_3_residual = None\n",
      "        add_6: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_23, relu__18);  batch_norm_23 = relu__18 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:87 in forward, code: relu_21 = torch.nn.functional.relu(add_6, inplace = True);  add_6 = None\n",
      "        relu__21: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_6);  add_6 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:88 in forward, code: ext3_0_residual_conv = getattr(self.ext3, \"0\").residual.conv(relu_21)\n",
      "        conv2d_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext3___0___residual_conv_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:89 in forward, code: ext3_0_residual_norm = getattr(self.ext3, \"0\").residual.norm(ext3_0_residual_conv);  ext3_0_residual_conv = None\n",
      "        add__24: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked = add__24 = None\n",
      "        batch_norm_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_24, p_getattr_l__self___ext3___0___residual_norm_weight, p_getattr_l__self___ext3___0___residual_norm_bias, b_getattr_l__self___ext3___0___residual_norm_running_mean, b_getattr_l__self___ext3___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_24 = p_getattr_l__self___ext3___0___residual_norm_weight = p_getattr_l__self___ext3___0___residual_norm_bias = b_getattr_l__self___ext3___0___residual_norm_running_mean = b_getattr_l__self___ext3___0___residual_norm_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:90 in forward, code: ext3_0_conv1 = getattr(self.ext3, \"0\").conv1(relu_21)\n",
      "        conv2d_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___conv1_weight);  p_getattr_l__self___ext3___0___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:91 in forward, code: ext3_0_norm1 = getattr(self.ext3, \"0\").norm1(ext3_0_conv1);  ext3_0_conv1 = None\n",
      "        add__25: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm1_num_batches_tracked = add__25 = None\n",
      "        batch_norm_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_25, p_getattr_l__self___ext3___0___norm1_weight, p_getattr_l__self___ext3___0___norm1_bias, b_getattr_l__self___ext3___0___norm1_running_mean, b_getattr_l__self___ext3___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_25 = p_getattr_l__self___ext3___0___norm1_weight = p_getattr_l__self___ext3___0___norm1_bias = b_getattr_l__self___ext3___0___norm1_running_mean = b_getattr_l__self___ext3___0___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:92 in forward, code: relu_22 = torch.nn.functional.relu(ext3_0_norm1, inplace = True);  ext3_0_norm1 = None\n",
      "        relu__22: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_25);  batch_norm_25 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:93 in forward, code: ext3_0_conv2 = getattr(self.ext3, \"0\").conv2(relu_22);  relu_22 = None\n",
      "        conv2d_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__22, p_getattr_l__self___ext3___0___conv2_weight, None, [2, 2], [1, 1]);  relu__22 = p_getattr_l__self___ext3___0___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:94 in forward, code: ext3_0_norm2 = getattr(self.ext3, \"0\").norm2(ext3_0_conv2);  ext3_0_conv2 = None\n",
      "        add__26: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm2_num_batches_tracked = add__26 = None\n",
      "        batch_norm_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_26, p_getattr_l__self___ext3___0___norm2_weight, p_getattr_l__self___ext3___0___norm2_bias, b_getattr_l__self___ext3___0___norm2_running_mean, b_getattr_l__self___ext3___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_26 = p_getattr_l__self___ext3___0___norm2_weight = p_getattr_l__self___ext3___0___norm2_bias = b_getattr_l__self___ext3___0___norm2_running_mean = b_getattr_l__self___ext3___0___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:95 in forward, code: relu_23 = torch.nn.functional.relu(ext3_0_norm2, inplace = True);  ext3_0_norm2 = None\n",
      "        relu__23: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_26);  batch_norm_26 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:96 in forward, code: ext3_0_conv3 = getattr(self.ext3, \"0\").conv3(relu_23);  relu_23 = None\n",
      "        conv2d_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__23, p_getattr_l__self___ext3___0___conv3_weight);  relu__23 = p_getattr_l__self___ext3___0___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:97 in forward, code: ext3_0_norm3 = getattr(self.ext3, \"0\").norm3(ext3_0_conv3);  ext3_0_conv3 = None\n",
      "        add__27: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm3_num_batches_tracked = add__27 = None\n",
      "        batch_norm_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_27, p_getattr_l__self___ext3___0___norm3_weight, p_getattr_l__self___ext3___0___norm3_bias, b_getattr_l__self___ext3___0___norm3_running_mean, b_getattr_l__self___ext3___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_27 = p_getattr_l__self___ext3___0___norm3_weight = p_getattr_l__self___ext3___0___norm3_bias = b_getattr_l__self___ext3___0___norm3_running_mean = b_getattr_l__self___ext3___0___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:98 in forward, code: add_7 = ext3_0_norm3 + ext3_0_residual_norm;  ext3_0_norm3 = ext3_0_residual_norm = None\n",
      "        add_7: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_27, batch_norm_24);  batch_norm_27 = batch_norm_24 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:99 in forward, code: relu_24 = torch.nn.functional.relu(add_7, inplace = True);  add_7 = None\n",
      "        relu__24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_7);  add_7 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:101 in forward, code: ext3_1_conv1 = getattr(self.ext3, \"1\").conv1(relu_24);  relu_24 = None\n",
      "        conv2d_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__24, p_getattr_l__self___ext3___1___conv1_weight);  p_getattr_l__self___ext3___1___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:102 in forward, code: ext3_1_norm1 = getattr(self.ext3, \"1\").norm1(ext3_1_conv1);  ext3_1_conv1 = None\n",
      "        add__28: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm1_num_batches_tracked = add__28 = None\n",
      "        batch_norm_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_28, p_getattr_l__self___ext3___1___norm1_weight, p_getattr_l__self___ext3___1___norm1_bias, b_getattr_l__self___ext3___1___norm1_running_mean, b_getattr_l__self___ext3___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_28 = p_getattr_l__self___ext3___1___norm1_weight = p_getattr_l__self___ext3___1___norm1_bias = b_getattr_l__self___ext3___1___norm1_running_mean = b_getattr_l__self___ext3___1___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:103 in forward, code: relu_25 = torch.nn.functional.relu(ext3_1_norm1, inplace = True);  ext3_1_norm1 = None\n",
      "        relu__25: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_28);  batch_norm_28 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:104 in forward, code: ext3_1_conv2 = getattr(self.ext3, \"1\").conv2(relu_25);  relu_25 = None\n",
      "        conv2d_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__25, p_getattr_l__self___ext3___1___conv2_weight, None, [1, 1], [1, 1]);  relu__25 = p_getattr_l__self___ext3___1___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:105 in forward, code: ext3_1_norm2 = getattr(self.ext3, \"1\").norm2(ext3_1_conv2);  ext3_1_conv2 = None\n",
      "        add__29: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm2_num_batches_tracked = add__29 = None\n",
      "        batch_norm_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_29, p_getattr_l__self___ext3___1___norm2_weight, p_getattr_l__self___ext3___1___norm2_bias, b_getattr_l__self___ext3___1___norm2_running_mean, b_getattr_l__self___ext3___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_29 = p_getattr_l__self___ext3___1___norm2_weight = p_getattr_l__self___ext3___1___norm2_bias = b_getattr_l__self___ext3___1___norm2_running_mean = b_getattr_l__self___ext3___1___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:106 in forward, code: relu_26 = torch.nn.functional.relu(ext3_1_norm2, inplace = True);  ext3_1_norm2 = None\n",
      "        relu__26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_29);  batch_norm_29 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:107 in forward, code: ext3_1_conv3 = getattr(self.ext3, \"1\").conv3(relu_26);  relu_26 = None\n",
      "        conv2d_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__26, p_getattr_l__self___ext3___1___conv3_weight);  relu__26 = p_getattr_l__self___ext3___1___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:108 in forward, code: ext3_1_norm3 = getattr(self.ext3, \"1\").norm3(ext3_1_conv3);  ext3_1_conv3 = None\n",
      "        add__30: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm3_num_batches_tracked = add__30 = None\n",
      "        batch_norm_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_30, p_getattr_l__self___ext3___1___norm3_weight, p_getattr_l__self___ext3___1___norm3_bias, b_getattr_l__self___ext3___1___norm3_running_mean, b_getattr_l__self___ext3___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_30 = p_getattr_l__self___ext3___1___norm3_weight = p_getattr_l__self___ext3___1___norm3_bias = b_getattr_l__self___ext3___1___norm3_running_mean = b_getattr_l__self___ext3___1___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:109 in forward, code: add_8 = ext3_1_norm3 + ext3_1_residual;  ext3_1_norm3 = ext3_1_residual = None\n",
      "        add_8: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_30, relu__24);  batch_norm_30 = relu__24 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:110 in forward, code: relu_27 = torch.nn.functional.relu(add_8, inplace = True);  add_8 = None\n",
      "        relu__27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_8);  add_8 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:112 in forward, code: ext3_2_conv1 = getattr(self.ext3, \"2\").conv1(relu_27);  relu_27 = None\n",
      "        conv2d_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__27, p_getattr_l__self___ext3___2___conv1_weight);  p_getattr_l__self___ext3___2___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:113 in forward, code: ext3_2_norm1 = getattr(self.ext3, \"2\").norm1(ext3_2_conv1);  ext3_2_conv1 = None\n",
      "        add__31: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm1_num_batches_tracked = add__31 = None\n",
      "        batch_norm_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_31, p_getattr_l__self___ext3___2___norm1_weight, p_getattr_l__self___ext3___2___norm1_bias, b_getattr_l__self___ext3___2___norm1_running_mean, b_getattr_l__self___ext3___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_31 = p_getattr_l__self___ext3___2___norm1_weight = p_getattr_l__self___ext3___2___norm1_bias = b_getattr_l__self___ext3___2___norm1_running_mean = b_getattr_l__self___ext3___2___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:114 in forward, code: relu_28 = torch.nn.functional.relu(ext3_2_norm1, inplace = True);  ext3_2_norm1 = None\n",
      "        relu__28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_31);  batch_norm_31 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:115 in forward, code: ext3_2_conv2 = getattr(self.ext3, \"2\").conv2(relu_28);  relu_28 = None\n",
      "        conv2d_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__28, p_getattr_l__self___ext3___2___conv2_weight, None, [1, 1], [1, 1]);  relu__28 = p_getattr_l__self___ext3___2___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:116 in forward, code: ext3_2_norm2 = getattr(self.ext3, \"2\").norm2(ext3_2_conv2);  ext3_2_conv2 = None\n",
      "        add__32: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm2_num_batches_tracked = add__32 = None\n",
      "        batch_norm_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_32, p_getattr_l__self___ext3___2___norm2_weight, p_getattr_l__self___ext3___2___norm2_bias, b_getattr_l__self___ext3___2___norm2_running_mean, b_getattr_l__self___ext3___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_32 = p_getattr_l__self___ext3___2___norm2_weight = p_getattr_l__self___ext3___2___norm2_bias = b_getattr_l__self___ext3___2___norm2_running_mean = b_getattr_l__self___ext3___2___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:117 in forward, code: relu_29 = torch.nn.functional.relu(ext3_2_norm2, inplace = True);  ext3_2_norm2 = None\n",
      "        relu__29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_32);  batch_norm_32 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:118 in forward, code: ext3_2_conv3 = getattr(self.ext3, \"2\").conv3(relu_29);  relu_29 = None\n",
      "        conv2d_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__29, p_getattr_l__self___ext3___2___conv3_weight);  relu__29 = p_getattr_l__self___ext3___2___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:119 in forward, code: ext3_2_norm3 = getattr(self.ext3, \"2\").norm3(ext3_2_conv3);  ext3_2_conv3 = None\n",
      "        add__33: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm3_num_batches_tracked = add__33 = None\n",
      "        batch_norm_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_33, p_getattr_l__self___ext3___2___norm3_weight, p_getattr_l__self___ext3___2___norm3_bias, b_getattr_l__self___ext3___2___norm3_running_mean, b_getattr_l__self___ext3___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_33 = p_getattr_l__self___ext3___2___norm3_weight = p_getattr_l__self___ext3___2___norm3_bias = b_getattr_l__self___ext3___2___norm3_running_mean = b_getattr_l__self___ext3___2___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:120 in forward, code: add_9 = ext3_2_norm3 + ext3_2_residual;  ext3_2_norm3 = ext3_2_residual = None\n",
      "        add_9: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_33, relu__27);  batch_norm_33 = relu__27 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:121 in forward, code: relu_30 = torch.nn.functional.relu(add_9, inplace = True);  add_9 = None\n",
      "        relu__30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_9);  add_9 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:123 in forward, code: ext3_3_conv1 = getattr(self.ext3, \"3\").conv1(relu_30);  relu_30 = None\n",
      "        conv2d_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__30, p_getattr_l__self___ext3___3___conv1_weight);  p_getattr_l__self___ext3___3___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:124 in forward, code: ext3_3_norm1 = getattr(self.ext3, \"3\").norm1(ext3_3_conv1);  ext3_3_conv1 = None\n",
      "        add__34: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm1_num_batches_tracked = add__34 = None\n",
      "        batch_norm_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_34, p_getattr_l__self___ext3___3___norm1_weight, p_getattr_l__self___ext3___3___norm1_bias, b_getattr_l__self___ext3___3___norm1_running_mean, b_getattr_l__self___ext3___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_34 = p_getattr_l__self___ext3___3___norm1_weight = p_getattr_l__self___ext3___3___norm1_bias = b_getattr_l__self___ext3___3___norm1_running_mean = b_getattr_l__self___ext3___3___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:125 in forward, code: relu_31 = torch.nn.functional.relu(ext3_3_norm1, inplace = True);  ext3_3_norm1 = None\n",
      "        relu__31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_34);  batch_norm_34 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:126 in forward, code: ext3_3_conv2 = getattr(self.ext3, \"3\").conv2(relu_31);  relu_31 = None\n",
      "        conv2d_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__31, p_getattr_l__self___ext3___3___conv2_weight, None, [1, 1], [1, 1]);  relu__31 = p_getattr_l__self___ext3___3___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:127 in forward, code: ext3_3_norm2 = getattr(self.ext3, \"3\").norm2(ext3_3_conv2);  ext3_3_conv2 = None\n",
      "        add__35: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm2_num_batches_tracked = add__35 = None\n",
      "        batch_norm_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_35, p_getattr_l__self___ext3___3___norm2_weight, p_getattr_l__self___ext3___3___norm2_bias, b_getattr_l__self___ext3___3___norm2_running_mean, b_getattr_l__self___ext3___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_35 = p_getattr_l__self___ext3___3___norm2_weight = p_getattr_l__self___ext3___3___norm2_bias = b_getattr_l__self___ext3___3___norm2_running_mean = b_getattr_l__self___ext3___3___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:128 in forward, code: relu_32 = torch.nn.functional.relu(ext3_3_norm2, inplace = True);  ext3_3_norm2 = None\n",
      "        relu__32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_35);  batch_norm_35 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:129 in forward, code: ext3_3_conv3 = getattr(self.ext3, \"3\").conv3(relu_32);  relu_32 = None\n",
      "        conv2d_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__32, p_getattr_l__self___ext3___3___conv3_weight);  relu__32 = p_getattr_l__self___ext3___3___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:130 in forward, code: ext3_3_norm3 = getattr(self.ext3, \"3\").norm3(ext3_3_conv3);  ext3_3_conv3 = None\n",
      "        add__36: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm3_num_batches_tracked = add__36 = None\n",
      "        batch_norm_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_36, p_getattr_l__self___ext3___3___norm3_weight, p_getattr_l__self___ext3___3___norm3_bias, b_getattr_l__self___ext3___3___norm3_running_mean, b_getattr_l__self___ext3___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_36 = p_getattr_l__self___ext3___3___norm3_weight = p_getattr_l__self___ext3___3___norm3_bias = b_getattr_l__self___ext3___3___norm3_running_mean = b_getattr_l__self___ext3___3___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:131 in forward, code: add_10 = ext3_3_norm3 + ext3_3_residual;  ext3_3_norm3 = ext3_3_residual = None\n",
      "        add_10: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_36, relu__30);  batch_norm_36 = relu__30 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:132 in forward, code: relu_33 = torch.nn.functional.relu(add_10, inplace = True);  add_10 = None\n",
      "        relu__33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_10);  add_10 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:134 in forward, code: ext3_4_conv1 = getattr(self.ext3, \"4\").conv1(relu_33);  relu_33 = None\n",
      "        conv2d_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__33, p_getattr_l__self___ext3___4___conv1_weight);  p_getattr_l__self___ext3___4___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:135 in forward, code: ext3_4_norm1 = getattr(self.ext3, \"4\").norm1(ext3_4_conv1);  ext3_4_conv1 = None\n",
      "        add__37: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm1_num_batches_tracked = add__37 = None\n",
      "        batch_norm_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_37, p_getattr_l__self___ext3___4___norm1_weight, p_getattr_l__self___ext3___4___norm1_bias, b_getattr_l__self___ext3___4___norm1_running_mean, b_getattr_l__self___ext3___4___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_37 = p_getattr_l__self___ext3___4___norm1_weight = p_getattr_l__self___ext3___4___norm1_bias = b_getattr_l__self___ext3___4___norm1_running_mean = b_getattr_l__self___ext3___4___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:136 in forward, code: relu_34 = torch.nn.functional.relu(ext3_4_norm1, inplace = True);  ext3_4_norm1 = None\n",
      "        relu__34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_37);  batch_norm_37 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:137 in forward, code: ext3_4_conv2 = getattr(self.ext3, \"4\").conv2(relu_34);  relu_34 = None\n",
      "        conv2d_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__34, p_getattr_l__self___ext3___4___conv2_weight, None, [1, 1], [1, 1]);  relu__34 = p_getattr_l__self___ext3___4___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:138 in forward, code: ext3_4_norm2 = getattr(self.ext3, \"4\").norm2(ext3_4_conv2);  ext3_4_conv2 = None\n",
      "        add__38: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm2_num_batches_tracked = add__38 = None\n",
      "        batch_norm_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_38, p_getattr_l__self___ext3___4___norm2_weight, p_getattr_l__self___ext3___4___norm2_bias, b_getattr_l__self___ext3___4___norm2_running_mean, b_getattr_l__self___ext3___4___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_38 = p_getattr_l__self___ext3___4___norm2_weight = p_getattr_l__self___ext3___4___norm2_bias = b_getattr_l__self___ext3___4___norm2_running_mean = b_getattr_l__self___ext3___4___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:139 in forward, code: relu_35 = torch.nn.functional.relu(ext3_4_norm2, inplace = True);  ext3_4_norm2 = None\n",
      "        relu__35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_38);  batch_norm_38 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:140 in forward, code: ext3_4_conv3 = getattr(self.ext3, \"4\").conv3(relu_35);  relu_35 = None\n",
      "        conv2d_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__35, p_getattr_l__self___ext3___4___conv3_weight);  relu__35 = p_getattr_l__self___ext3___4___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:141 in forward, code: ext3_4_norm3 = getattr(self.ext3, \"4\").norm3(ext3_4_conv3);  ext3_4_conv3 = None\n",
      "        add__39: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm3_num_batches_tracked = add__39 = None\n",
      "        batch_norm_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_39, p_getattr_l__self___ext3___4___norm3_weight, p_getattr_l__self___ext3___4___norm3_bias, b_getattr_l__self___ext3___4___norm3_running_mean, b_getattr_l__self___ext3___4___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_39 = p_getattr_l__self___ext3___4___norm3_weight = p_getattr_l__self___ext3___4___norm3_bias = b_getattr_l__self___ext3___4___norm3_running_mean = b_getattr_l__self___ext3___4___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:142 in forward, code: add_11 = ext3_4_norm3 + ext3_4_residual;  ext3_4_norm3 = ext3_4_residual = None\n",
      "        add_11: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_39, relu__33);  batch_norm_39 = relu__33 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:143 in forward, code: relu_36 = torch.nn.functional.relu(add_11, inplace = True);  add_11 = None\n",
      "        relu__36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_11);  add_11 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:145 in forward, code: ext3_5_conv1 = getattr(self.ext3, \"5\").conv1(relu_36);  relu_36 = None\n",
      "        conv2d_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__36, p_getattr_l__self___ext3___5___conv1_weight);  p_getattr_l__self___ext3___5___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:146 in forward, code: ext3_5_norm1 = getattr(self.ext3, \"5\").norm1(ext3_5_conv1);  ext3_5_conv1 = None\n",
      "        add__40: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm1_num_batches_tracked = add__40 = None\n",
      "        batch_norm_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_40, p_getattr_l__self___ext3___5___norm1_weight, p_getattr_l__self___ext3___5___norm1_bias, b_getattr_l__self___ext3___5___norm1_running_mean, b_getattr_l__self___ext3___5___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_40 = p_getattr_l__self___ext3___5___norm1_weight = p_getattr_l__self___ext3___5___norm1_bias = b_getattr_l__self___ext3___5___norm1_running_mean = b_getattr_l__self___ext3___5___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:147 in forward, code: relu_37 = torch.nn.functional.relu(ext3_5_norm1, inplace = True);  ext3_5_norm1 = None\n",
      "        relu__37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_40);  batch_norm_40 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:148 in forward, code: ext3_5_conv2 = getattr(self.ext3, \"5\").conv2(relu_37);  relu_37 = None\n",
      "        conv2d_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__37, p_getattr_l__self___ext3___5___conv2_weight, None, [1, 1], [1, 1]);  relu__37 = p_getattr_l__self___ext3___5___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:149 in forward, code: ext3_5_norm2 = getattr(self.ext3, \"5\").norm2(ext3_5_conv2);  ext3_5_conv2 = None\n",
      "        add__41: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm2_num_batches_tracked = add__41 = None\n",
      "        batch_norm_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_41, p_getattr_l__self___ext3___5___norm2_weight, p_getattr_l__self___ext3___5___norm2_bias, b_getattr_l__self___ext3___5___norm2_running_mean, b_getattr_l__self___ext3___5___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_41 = p_getattr_l__self___ext3___5___norm2_weight = p_getattr_l__self___ext3___5___norm2_bias = b_getattr_l__self___ext3___5___norm2_running_mean = b_getattr_l__self___ext3___5___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:150 in forward, code: relu_38 = torch.nn.functional.relu(ext3_5_norm2, inplace = True);  ext3_5_norm2 = None\n",
      "        relu__38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_41);  batch_norm_41 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:151 in forward, code: ext3_5_conv3 = getattr(self.ext3, \"5\").conv3(relu_38);  relu_38 = None\n",
      "        conv2d_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__38, p_getattr_l__self___ext3___5___conv3_weight);  relu__38 = p_getattr_l__self___ext3___5___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:152 in forward, code: ext3_5_norm3 = getattr(self.ext3, \"5\").norm3(ext3_5_conv3);  ext3_5_conv3 = None\n",
      "        add__42: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm3_num_batches_tracked = add__42 = None\n",
      "        batch_norm_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_42, p_getattr_l__self___ext3___5___norm3_weight, p_getattr_l__self___ext3___5___norm3_bias, b_getattr_l__self___ext3___5___norm3_running_mean, b_getattr_l__self___ext3___5___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_42 = p_getattr_l__self___ext3___5___norm3_weight = p_getattr_l__self___ext3___5___norm3_bias = b_getattr_l__self___ext3___5___norm3_running_mean = b_getattr_l__self___ext3___5___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:153 in forward, code: add_12 = ext3_5_norm3 + ext3_5_residual;  ext3_5_norm3 = ext3_5_residual = None\n",
      "        add_12: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_42, relu__36);  batch_norm_42 = relu__36 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:154 in forward, code: relu_39 = torch.nn.functional.relu(add_12, inplace = True);  add_12 = None\n",
      "        relu__39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_12);  add_12 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:155 in forward, code: ext4_0_residual_conv = getattr(self.ext4, \"0\").residual.conv(relu_39)\n",
      "        conv2d_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext4___0___residual_conv_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:156 in forward, code: ext4_0_residual_norm = getattr(self.ext4, \"0\").residual.norm(ext4_0_residual_conv);  ext4_0_residual_conv = None\n",
      "        add__43: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked = add__43 = None\n",
      "        batch_norm_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_43, p_getattr_l__self___ext4___0___residual_norm_weight, p_getattr_l__self___ext4___0___residual_norm_bias, b_getattr_l__self___ext4___0___residual_norm_running_mean, b_getattr_l__self___ext4___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_43 = p_getattr_l__self___ext4___0___residual_norm_weight = p_getattr_l__self___ext4___0___residual_norm_bias = b_getattr_l__self___ext4___0___residual_norm_running_mean = b_getattr_l__self___ext4___0___residual_norm_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:157 in forward, code: ext4_0_conv1 = getattr(self.ext4, \"0\").conv1(relu_39)\n",
      "        conv2d_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___conv1_weight);  p_getattr_l__self___ext4___0___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:158 in forward, code: ext4_0_norm1 = getattr(self.ext4, \"0\").norm1(ext4_0_conv1);  ext4_0_conv1 = None\n",
      "        add__44: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm1_num_batches_tracked = add__44 = None\n",
      "        batch_norm_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_44, p_getattr_l__self___ext4___0___norm1_weight, p_getattr_l__self___ext4___0___norm1_bias, b_getattr_l__self___ext4___0___norm1_running_mean, b_getattr_l__self___ext4___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_44 = p_getattr_l__self___ext4___0___norm1_weight = p_getattr_l__self___ext4___0___norm1_bias = b_getattr_l__self___ext4___0___norm1_running_mean = b_getattr_l__self___ext4___0___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:159 in forward, code: relu_40 = torch.nn.functional.relu(ext4_0_norm1, inplace = True);  ext4_0_norm1 = None\n",
      "        relu__40: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_44);  batch_norm_44 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:160 in forward, code: ext4_0_conv2 = getattr(self.ext4, \"0\").conv2(relu_40);  relu_40 = None\n",
      "        conv2d_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__40, p_getattr_l__self___ext4___0___conv2_weight, None, [2, 2], [1, 1]);  relu__40 = p_getattr_l__self___ext4___0___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:161 in forward, code: ext4_0_norm2 = getattr(self.ext4, \"0\").norm2(ext4_0_conv2);  ext4_0_conv2 = None\n",
      "        add__45: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm2_num_batches_tracked = add__45 = None\n",
      "        batch_norm_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_45, p_getattr_l__self___ext4___0___norm2_weight, p_getattr_l__self___ext4___0___norm2_bias, b_getattr_l__self___ext4___0___norm2_running_mean, b_getattr_l__self___ext4___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_45 = p_getattr_l__self___ext4___0___norm2_weight = p_getattr_l__self___ext4___0___norm2_bias = b_getattr_l__self___ext4___0___norm2_running_mean = b_getattr_l__self___ext4___0___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:162 in forward, code: relu_41 = torch.nn.functional.relu(ext4_0_norm2, inplace = True);  ext4_0_norm2 = None\n",
      "        relu__41: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_45);  batch_norm_45 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:163 in forward, code: ext4_0_conv3 = getattr(self.ext4, \"0\").conv3(relu_41);  relu_41 = None\n",
      "        conv2d_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__41, p_getattr_l__self___ext4___0___conv3_weight);  relu__41 = p_getattr_l__self___ext4___0___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:164 in forward, code: ext4_0_norm3 = getattr(self.ext4, \"0\").norm3(ext4_0_conv3);  ext4_0_conv3 = None\n",
      "        add__46: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm3_num_batches_tracked = add__46 = None\n",
      "        batch_norm_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_46, p_getattr_l__self___ext4___0___norm3_weight, p_getattr_l__self___ext4___0___norm3_bias, b_getattr_l__self___ext4___0___norm3_running_mean, b_getattr_l__self___ext4___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_46 = p_getattr_l__self___ext4___0___norm3_weight = p_getattr_l__self___ext4___0___norm3_bias = b_getattr_l__self___ext4___0___norm3_running_mean = b_getattr_l__self___ext4___0___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:165 in forward, code: add_13 = ext4_0_norm3 + ext4_0_residual_norm;  ext4_0_norm3 = ext4_0_residual_norm = None\n",
      "        add_13: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_46, batch_norm_43);  batch_norm_46 = batch_norm_43 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:166 in forward, code: relu_42 = torch.nn.functional.relu(add_13, inplace = True);  add_13 = None\n",
      "        relu__42: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_13);  add_13 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:168 in forward, code: ext4_1_conv1 = getattr(self.ext4, \"1\").conv1(relu_42);  relu_42 = None\n",
      "        conv2d_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__42, p_getattr_l__self___ext4___1___conv1_weight);  p_getattr_l__self___ext4___1___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:169 in forward, code: ext4_1_norm1 = getattr(self.ext4, \"1\").norm1(ext4_1_conv1);  ext4_1_conv1 = None\n",
      "        add__47: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm1_num_batches_tracked = add__47 = None\n",
      "        batch_norm_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_47, p_getattr_l__self___ext4___1___norm1_weight, p_getattr_l__self___ext4___1___norm1_bias, b_getattr_l__self___ext4___1___norm1_running_mean, b_getattr_l__self___ext4___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_47 = p_getattr_l__self___ext4___1___norm1_weight = p_getattr_l__self___ext4___1___norm1_bias = b_getattr_l__self___ext4___1___norm1_running_mean = b_getattr_l__self___ext4___1___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:170 in forward, code: relu_43 = torch.nn.functional.relu(ext4_1_norm1, inplace = True);  ext4_1_norm1 = None\n",
      "        relu__43: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_47);  batch_norm_47 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:171 in forward, code: ext4_1_conv2 = getattr(self.ext4, \"1\").conv2(relu_43);  relu_43 = None\n",
      "        conv2d_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__43, p_getattr_l__self___ext4___1___conv2_weight, None, [1, 1], [1, 1]);  relu__43 = p_getattr_l__self___ext4___1___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:172 in forward, code: ext4_1_norm2 = getattr(self.ext4, \"1\").norm2(ext4_1_conv2);  ext4_1_conv2 = None\n",
      "        add__48: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm2_num_batches_tracked = add__48 = None\n",
      "        batch_norm_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_48, p_getattr_l__self___ext4___1___norm2_weight, p_getattr_l__self___ext4___1___norm2_bias, b_getattr_l__self___ext4___1___norm2_running_mean, b_getattr_l__self___ext4___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_48 = p_getattr_l__self___ext4___1___norm2_weight = p_getattr_l__self___ext4___1___norm2_bias = b_getattr_l__self___ext4___1___norm2_running_mean = b_getattr_l__self___ext4___1___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:173 in forward, code: relu_44 = torch.nn.functional.relu(ext4_1_norm2, inplace = True);  ext4_1_norm2 = None\n",
      "        relu__44: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_48);  batch_norm_48 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:174 in forward, code: ext4_1_conv3 = getattr(self.ext4, \"1\").conv3(relu_44);  relu_44 = None\n",
      "        conv2d_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__44, p_getattr_l__self___ext4___1___conv3_weight);  relu__44 = p_getattr_l__self___ext4___1___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:175 in forward, code: ext4_1_norm3 = getattr(self.ext4, \"1\").norm3(ext4_1_conv3);  ext4_1_conv3 = None\n",
      "        add__49: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm3_num_batches_tracked = add__49 = None\n",
      "        batch_norm_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_49, p_getattr_l__self___ext4___1___norm3_weight, p_getattr_l__self___ext4___1___norm3_bias, b_getattr_l__self___ext4___1___norm3_running_mean, b_getattr_l__self___ext4___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_49 = p_getattr_l__self___ext4___1___norm3_weight = p_getattr_l__self___ext4___1___norm3_bias = b_getattr_l__self___ext4___1___norm3_running_mean = b_getattr_l__self___ext4___1___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:176 in forward, code: add_14 = ext4_1_norm3 + ext4_1_residual;  ext4_1_norm3 = ext4_1_residual = None\n",
      "        add_14: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_49, relu__42);  batch_norm_49 = relu__42 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:177 in forward, code: relu_45 = torch.nn.functional.relu(add_14, inplace = True);  add_14 = None\n",
      "        relu__45: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_14);  add_14 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:179 in forward, code: ext4_2_conv1 = getattr(self.ext4, \"2\").conv1(relu_45);  relu_45 = None\n",
      "        conv2d_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__45, p_getattr_l__self___ext4___2___conv1_weight);  p_getattr_l__self___ext4___2___conv1_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:180 in forward, code: ext4_2_norm1 = getattr(self.ext4, \"2\").norm1(ext4_2_conv1);  ext4_2_conv1 = None\n",
      "        add__50: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm1_num_batches_tracked = add__50 = None\n",
      "        batch_norm_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_50, p_getattr_l__self___ext4___2___norm1_weight, p_getattr_l__self___ext4___2___norm1_bias, b_getattr_l__self___ext4___2___norm1_running_mean, b_getattr_l__self___ext4___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_50 = p_getattr_l__self___ext4___2___norm1_weight = p_getattr_l__self___ext4___2___norm1_bias = b_getattr_l__self___ext4___2___norm1_running_mean = b_getattr_l__self___ext4___2___norm1_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:181 in forward, code: relu_46 = torch.nn.functional.relu(ext4_2_norm1, inplace = True);  ext4_2_norm1 = None\n",
      "        relu__46: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_50);  batch_norm_50 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:182 in forward, code: ext4_2_conv2 = getattr(self.ext4, \"2\").conv2(relu_46);  relu_46 = None\n",
      "        conv2d_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__46, p_getattr_l__self___ext4___2___conv2_weight, None, [1, 1], [1, 1]);  relu__46 = p_getattr_l__self___ext4___2___conv2_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:183 in forward, code: ext4_2_norm2 = getattr(self.ext4, \"2\").norm2(ext4_2_conv2);  ext4_2_conv2 = None\n",
      "        add__51: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm2_num_batches_tracked = add__51 = None\n",
      "        batch_norm_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_51, p_getattr_l__self___ext4___2___norm2_weight, p_getattr_l__self___ext4___2___norm2_bias, b_getattr_l__self___ext4___2___norm2_running_mean, b_getattr_l__self___ext4___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_51 = p_getattr_l__self___ext4___2___norm2_weight = p_getattr_l__self___ext4___2___norm2_bias = b_getattr_l__self___ext4___2___norm2_running_mean = b_getattr_l__self___ext4___2___norm2_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:184 in forward, code: relu_47 = torch.nn.functional.relu(ext4_2_norm2, inplace = True);  ext4_2_norm2 = None\n",
      "        relu__47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_51);  batch_norm_51 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:185 in forward, code: ext4_2_conv3 = getattr(self.ext4, \"2\").conv3(relu_47);  relu_47 = None\n",
      "        conv2d_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__47, p_getattr_l__self___ext4___2___conv3_weight);  relu__47 = p_getattr_l__self___ext4___2___conv3_weight = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:186 in forward, code: ext4_2_norm3 = getattr(self.ext4, \"2\").norm3(ext4_2_conv3);  ext4_2_conv3 = None\n",
      "        add__52: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm3_num_batches_tracked = add__52 = None\n",
      "        batch_norm_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_52, p_getattr_l__self___ext4___2___norm3_weight, p_getattr_l__self___ext4___2___norm3_bias, b_getattr_l__self___ext4___2___norm3_running_mean, b_getattr_l__self___ext4___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_52 = p_getattr_l__self___ext4___2___norm3_weight = p_getattr_l__self___ext4___2___norm3_bias = b_getattr_l__self___ext4___2___norm3_running_mean = b_getattr_l__self___ext4___2___norm3_running_var = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:187 in forward, code: add_15 = ext4_2_norm3 + ext4_2_residual;  ext4_2_norm3 = ext4_2_residual = None\n",
      "        add_15: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_52, relu__45);  batch_norm_52 = relu__45 = None\n",
      "        \n",
      "         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:188 in forward, code: relu_48 = torch.nn.functional.relu(add_15, inplace = True);  add_15 = None\n",
      "        relu__48: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_15);  add_15 = None\n",
      "        return (relu__9, relu__21, relu__39, relu__48)\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class GraphModule(torch.nn.Module):\\n    def forward(self, p_stem_conv_weight: \"f32[64, 3, 7, 7]\", p_stem_norm_weight: \"f32[64]\", p_stem_norm_bias: \"f32[64]\", p_getattr_l__self___ext1___0___residual_conv_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___residual_norm_weight: \"f32[256]\", p_getattr_l__self___ext1___0___residual_norm_bias: \"f32[256]\", p_getattr_l__self___ext1___0___conv1_weight: \"f32[64, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___0___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___0___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___0___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___0___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___0___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___1___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___1___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___1___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___1___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___1___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___1___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___1___norm3_bias: \"f32[256]\", p_getattr_l__self___ext1___2___conv1_weight: \"f32[64, 256, 1, 1]\", p_getattr_l__self___ext1___2___norm1_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm1_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv2_weight: \"f32[64, 64, 3, 3]\", p_getattr_l__self___ext1___2___norm2_weight: \"f32[64]\", p_getattr_l__self___ext1___2___norm2_bias: \"f32[64]\", p_getattr_l__self___ext1___2___conv3_weight: \"f32[256, 64, 1, 1]\", p_getattr_l__self___ext1___2___norm3_weight: \"f32[256]\", p_getattr_l__self___ext1___2___norm3_bias: \"f32[256]\", p_getattr_l__self___ext2___0___residual_conv_weight: \"f32[512, 256, 1, 1]\", p_getattr_l__self___ext2___0___residual_norm_weight: \"f32[512]\", p_getattr_l__self___ext2___0___residual_norm_bias: \"f32[512]\", p_getattr_l__self___ext2___0___conv1_weight: \"f32[128, 256, 1, 1]\", p_getattr_l__self___ext2___0___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___0___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___0___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___0___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___0___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___0___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___1___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___1___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___1___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___1___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___1___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___1___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___1___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___2___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___2___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___2___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___2___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___2___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___2___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___2___norm3_bias: \"f32[512]\", p_getattr_l__self___ext2___3___conv1_weight: \"f32[128, 512, 1, 1]\", p_getattr_l__self___ext2___3___norm1_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm1_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv2_weight: \"f32[128, 128, 3, 3]\", p_getattr_l__self___ext2___3___norm2_weight: \"f32[128]\", p_getattr_l__self___ext2___3___norm2_bias: \"f32[128]\", p_getattr_l__self___ext2___3___conv3_weight: \"f32[512, 128, 1, 1]\", p_getattr_l__self___ext2___3___norm3_weight: \"f32[512]\", p_getattr_l__self___ext2___3___norm3_bias: \"f32[512]\", p_getattr_l__self___ext3___0___residual_conv_weight: \"f32[1024, 512, 1, 1]\", p_getattr_l__self___ext3___0___residual_norm_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___residual_norm_bias: \"f32[1024]\", p_getattr_l__self___ext3___0___conv1_weight: \"f32[256, 512, 1, 1]\", p_getattr_l__self___ext3___0___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___0___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___0___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___0___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___0___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___0___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___1___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___1___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___1___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___1___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___1___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___1___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___1___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___2___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___2___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___2___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___2___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___2___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___2___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___2___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___3___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___3___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___3___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___3___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___3___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___3___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___3___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___4___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___4___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___4___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___4___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___4___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___4___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___4___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext3___5___conv1_weight: \"f32[256, 1024, 1, 1]\", p_getattr_l__self___ext3___5___norm1_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm1_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv2_weight: \"f32[256, 256, 3, 3]\", p_getattr_l__self___ext3___5___norm2_weight: \"f32[256]\", p_getattr_l__self___ext3___5___norm2_bias: \"f32[256]\", p_getattr_l__self___ext3___5___conv3_weight: \"f32[1024, 256, 1, 1]\", p_getattr_l__self___ext3___5___norm3_weight: \"f32[1024]\", p_getattr_l__self___ext3___5___norm3_bias: \"f32[1024]\", p_getattr_l__self___ext4___0___residual_conv_weight: \"f32[2048, 1024, 1, 1]\", p_getattr_l__self___ext4___0___residual_norm_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___residual_norm_bias: \"f32[2048]\", p_getattr_l__self___ext4___0___conv1_weight: \"f32[512, 1024, 1, 1]\", p_getattr_l__self___ext4___0___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___0___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___0___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___0___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___0___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___0___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___1___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___1___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___1___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___1___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___1___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___1___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___1___norm3_bias: \"f32[2048]\", p_getattr_l__self___ext4___2___conv1_weight: \"f32[512, 2048, 1, 1]\", p_getattr_l__self___ext4___2___norm1_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm1_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv2_weight: \"f32[512, 512, 3, 3]\", p_getattr_l__self___ext4___2___norm2_weight: \"f32[512]\", p_getattr_l__self___ext4___2___norm2_bias: \"f32[512]\", p_getattr_l__self___ext4___2___conv3_weight: \"f32[2048, 512, 1, 1]\", p_getattr_l__self___ext4___2___norm3_weight: \"f32[2048]\", p_getattr_l__self___ext4___2___norm3_bias: \"f32[2048]\", b_stem_norm_running_mean: \"f32[64]\", b_stem_norm_running_var: \"f32[64]\", b_stem_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___residual_norm_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___0___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___1___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm1_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm2_running_mean: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_running_var: \"f32[64]\", b_getattr_l__self___ext1___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext1___2___norm3_running_mean: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_running_var: \"f32[256]\", b_getattr_l__self___ext1___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___residual_norm_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___0___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___1___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___2___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm1_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm2_running_mean: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_running_var: \"f32[128]\", b_getattr_l__self___ext2___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext2___3___norm3_running_mean: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_running_var: \"f32[512]\", b_getattr_l__self___ext2___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___residual_norm_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___0___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___1___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___2___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___2___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___3___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___3___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___3___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___4___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___4___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___4___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm1_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm2_running_mean: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_running_var: \"f32[256]\", b_getattr_l__self___ext3___5___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext3___5___norm3_running_mean: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_running_var: \"f32[1024]\", b_getattr_l__self___ext3___5___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___residual_norm_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___0___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___0___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___0___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___1___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___1___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___1___norm3_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm1_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm1_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm2_running_mean: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_running_var: \"f32[512]\", b_getattr_l__self___ext4___2___norm2_num_batches_tracked: \"i64[]\", b_getattr_l__self___ext4___2___norm3_running_mean: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_running_var: \"f32[2048]\", b_getattr_l__self___ext4___2___norm3_num_batches_tracked: \"i64[]\", x: \"f32[s0, 3, 2*s3, 2*s4]\"):\\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:5 in forward, code: stem_conv = self.stem.conv(x);  x = None\\n        conv2d: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.conv2d.default(x, p_stem_conv_weight, None, [2, 2], [3, 3]);  x = p_stem_conv_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:6 in forward, code: stem_norm = self.stem.norm(stem_conv);  stem_conv = None\\n        add_: \"i64[]\" = torch.ops.aten.add_.Tensor(b_stem_norm_num_batches_tracked, 1);  b_stem_norm_num_batches_tracked = add_ = None\\n        batch_norm: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.batch_norm.default(conv2d, p_stem_norm_weight, p_stem_norm_bias, b_stem_norm_running_mean, b_stem_norm_running_var, True, 0.1, 1e-05, True);  conv2d = p_stem_norm_weight = p_stem_norm_bias = b_stem_norm_running_mean = b_stem_norm_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:7 in forward, code: relu = torch.nn.functional.relu(stem_norm, inplace = True);  stem_norm = None\\n        relu_: \"f32[s0, 64, s3, s4]\" = torch.ops.aten.relu_.default(batch_norm);  batch_norm = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:8 in forward, code: stem_pool = self.stem.pool(relu);  relu = None\\n        max_pool2d: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.max_pool2d.default(relu_, [3, 3], [2, 2], [1, 1]);  relu_ = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:9 in forward, code: ext1_0_residual_conv = getattr(self.ext1, \"0\").residual.conv(stem_pool)\\n        conv2d_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___residual_conv_weight);  p_getattr_l__self___ext1___0___residual_conv_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:10 in forward, code: ext1_0_residual_norm = getattr(self.ext1, \"0\").residual.norm(ext1_0_residual_conv);  ext1_0_residual_conv = None\\n        add__1: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___residual_norm_num_batches_tracked = add__1 = None\\n        batch_norm_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_1, p_getattr_l__self___ext1___0___residual_norm_weight, p_getattr_l__self___ext1___0___residual_norm_bias, b_getattr_l__self___ext1___0___residual_norm_running_mean, b_getattr_l__self___ext1___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_1 = p_getattr_l__self___ext1___0___residual_norm_weight = p_getattr_l__self___ext1___0___residual_norm_bias = b_getattr_l__self___ext1___0___residual_norm_running_mean = b_getattr_l__self___ext1___0___residual_norm_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:11 in forward, code: ext1_0_conv1 = getattr(self.ext1, \"0\").conv1(stem_pool);  stem_pool = None\\n        conv2d_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(max_pool2d, p_getattr_l__self___ext1___0___conv1_weight);  max_pool2d = p_getattr_l__self___ext1___0___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:12 in forward, code: ext1_0_norm1 = getattr(self.ext1, \"0\").norm1(ext1_0_conv1);  ext1_0_conv1 = None\\n        add__2: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm1_num_batches_tracked = add__2 = None\\n        batch_norm_2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_2, p_getattr_l__self___ext1___0___norm1_weight, p_getattr_l__self___ext1___0___norm1_bias, b_getattr_l__self___ext1___0___norm1_running_mean, b_getattr_l__self___ext1___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_2 = p_getattr_l__self___ext1___0___norm1_weight = p_getattr_l__self___ext1___0___norm1_bias = b_getattr_l__self___ext1___0___norm1_running_mean = b_getattr_l__self___ext1___0___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:13 in forward, code: relu_1 = torch.nn.functional.relu(ext1_0_norm1, inplace = True);  ext1_0_norm1 = None\\n        relu__1: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_2);  batch_norm_2 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:14 in forward, code: ext1_0_conv2 = getattr(self.ext1, \"0\").conv2(relu_1);  relu_1 = None\\n        conv2d_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__1, p_getattr_l__self___ext1___0___conv2_weight, None, [1, 1], [1, 1]);  relu__1 = p_getattr_l__self___ext1___0___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:15 in forward, code: ext1_0_norm2 = getattr(self.ext1, \"0\").norm2(ext1_0_conv2);  ext1_0_conv2 = None\\n        add__3: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm2_num_batches_tracked = add__3 = None\\n        batch_norm_3: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_3, p_getattr_l__self___ext1___0___norm2_weight, p_getattr_l__self___ext1___0___norm2_bias, b_getattr_l__self___ext1___0___norm2_running_mean, b_getattr_l__self___ext1___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_3 = p_getattr_l__self___ext1___0___norm2_weight = p_getattr_l__self___ext1___0___norm2_bias = b_getattr_l__self___ext1___0___norm2_running_mean = b_getattr_l__self___ext1___0___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:16 in forward, code: relu_2 = torch.nn.functional.relu(ext1_0_norm2, inplace = True);  ext1_0_norm2 = None\\n        relu__2: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_3);  batch_norm_3 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:17 in forward, code: ext1_0_conv3 = getattr(self.ext1, \"0\").conv3(relu_2);  relu_2 = None\\n        conv2d_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__2, p_getattr_l__self___ext1___0___conv3_weight);  relu__2 = p_getattr_l__self___ext1___0___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:18 in forward, code: ext1_0_norm3 = getattr(self.ext1, \"0\").norm3(ext1_0_conv3);  ext1_0_conv3 = None\\n        add__4: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___0___norm3_num_batches_tracked = add__4 = None\\n        batch_norm_4: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_4, p_getattr_l__self___ext1___0___norm3_weight, p_getattr_l__self___ext1___0___norm3_bias, b_getattr_l__self___ext1___0___norm3_running_mean, b_getattr_l__self___ext1___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_4 = p_getattr_l__self___ext1___0___norm3_weight = p_getattr_l__self___ext1___0___norm3_bias = b_getattr_l__self___ext1___0___norm3_running_mean = b_getattr_l__self___ext1___0___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:19 in forward, code: add = ext1_0_norm3 + ext1_0_residual_norm;  ext1_0_norm3 = ext1_0_residual_norm = None\\n        add: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_4, batch_norm_1);  batch_norm_4 = batch_norm_1 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:20 in forward, code: relu_3 = torch.nn.functional.relu(add, inplace = True);  add = None\\n        relu__3: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add);  add = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:22 in forward, code: ext1_1_conv1 = getattr(self.ext1, \"1\").conv1(relu_3);  relu_3 = None\\n        conv2d_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__3, p_getattr_l__self___ext1___1___conv1_weight);  p_getattr_l__self___ext1___1___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:23 in forward, code: ext1_1_norm1 = getattr(self.ext1, \"1\").norm1(ext1_1_conv1);  ext1_1_conv1 = None\\n        add__5: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm1_num_batches_tracked = add__5 = None\\n        batch_norm_5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_5, p_getattr_l__self___ext1___1___norm1_weight, p_getattr_l__self___ext1___1___norm1_bias, b_getattr_l__self___ext1___1___norm1_running_mean, b_getattr_l__self___ext1___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_5 = p_getattr_l__self___ext1___1___norm1_weight = p_getattr_l__self___ext1___1___norm1_bias = b_getattr_l__self___ext1___1___norm1_running_mean = b_getattr_l__self___ext1___1___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:24 in forward, code: relu_4 = torch.nn.functional.relu(ext1_1_norm1, inplace = True);  ext1_1_norm1 = None\\n        relu__4: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_5);  batch_norm_5 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:25 in forward, code: ext1_1_conv2 = getattr(self.ext1, \"1\").conv2(relu_4);  relu_4 = None\\n        conv2d_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__4, p_getattr_l__self___ext1___1___conv2_weight, None, [1, 1], [1, 1]);  relu__4 = p_getattr_l__self___ext1___1___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:26 in forward, code: ext1_1_norm2 = getattr(self.ext1, \"1\").norm2(ext1_1_conv2);  ext1_1_conv2 = None\\n        add__6: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm2_num_batches_tracked = add__6 = None\\n        batch_norm_6: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_6, p_getattr_l__self___ext1___1___norm2_weight, p_getattr_l__self___ext1___1___norm2_bias, b_getattr_l__self___ext1___1___norm2_running_mean, b_getattr_l__self___ext1___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_6 = p_getattr_l__self___ext1___1___norm2_weight = p_getattr_l__self___ext1___1___norm2_bias = b_getattr_l__self___ext1___1___norm2_running_mean = b_getattr_l__self___ext1___1___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:27 in forward, code: relu_5 = torch.nn.functional.relu(ext1_1_norm2, inplace = True);  ext1_1_norm2 = None\\n        relu__5: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_6);  batch_norm_6 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:28 in forward, code: ext1_1_conv3 = getattr(self.ext1, \"1\").conv3(relu_5);  relu_5 = None\\n        conv2d_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__5, p_getattr_l__self___ext1___1___conv3_weight);  relu__5 = p_getattr_l__self___ext1___1___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:29 in forward, code: ext1_1_norm3 = getattr(self.ext1, \"1\").norm3(ext1_1_conv3);  ext1_1_conv3 = None\\n        add__7: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___1___norm3_num_batches_tracked = add__7 = None\\n        batch_norm_7: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_7, p_getattr_l__self___ext1___1___norm3_weight, p_getattr_l__self___ext1___1___norm3_bias, b_getattr_l__self___ext1___1___norm3_running_mean, b_getattr_l__self___ext1___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_7 = p_getattr_l__self___ext1___1___norm3_weight = p_getattr_l__self___ext1___1___norm3_bias = b_getattr_l__self___ext1___1___norm3_running_mean = b_getattr_l__self___ext1___1___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:30 in forward, code: add_1 = ext1_1_norm3 + ext1_1_residual;  ext1_1_norm3 = ext1_1_residual = None\\n        add_1: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_7, relu__3);  batch_norm_7 = relu__3 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:31 in forward, code: relu_6 = torch.nn.functional.relu(add_1, inplace = True);  add_1 = None\\n        relu__6: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_1);  add_1 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:33 in forward, code: ext1_2_conv1 = getattr(self.ext1, \"2\").conv1(relu_6);  relu_6 = None\\n        conv2d_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__6, p_getattr_l__self___ext1___2___conv1_weight);  p_getattr_l__self___ext1___2___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:34 in forward, code: ext1_2_norm1 = getattr(self.ext1, \"2\").norm1(ext1_2_conv1);  ext1_2_conv1 = None\\n        add__8: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm1_num_batches_tracked = add__8 = None\\n        batch_norm_8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_8, p_getattr_l__self___ext1___2___norm1_weight, p_getattr_l__self___ext1___2___norm1_bias, b_getattr_l__self___ext1___2___norm1_running_mean, b_getattr_l__self___ext1___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_8 = p_getattr_l__self___ext1___2___norm1_weight = p_getattr_l__self___ext1___2___norm1_bias = b_getattr_l__self___ext1___2___norm1_running_mean = b_getattr_l__self___ext1___2___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:35 in forward, code: relu_7 = torch.nn.functional.relu(ext1_2_norm1, inplace = True);  ext1_2_norm1 = None\\n        relu__7: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_8);  batch_norm_8 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:36 in forward, code: ext1_2_conv2 = getattr(self.ext1, \"2\").conv2(relu_7);  relu_7 = None\\n        conv2d_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__7, p_getattr_l__self___ext1___2___conv2_weight, None, [1, 1], [1, 1]);  relu__7 = p_getattr_l__self___ext1___2___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:37 in forward, code: ext1_2_norm2 = getattr(self.ext1, \"2\").norm2(ext1_2_conv2);  ext1_2_conv2 = None\\n        add__9: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm2_num_batches_tracked = add__9 = None\\n        batch_norm_9: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_9, p_getattr_l__self___ext1___2___norm2_weight, p_getattr_l__self___ext1___2___norm2_bias, b_getattr_l__self___ext1___2___norm2_running_mean, b_getattr_l__self___ext1___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_9 = p_getattr_l__self___ext1___2___norm2_weight = p_getattr_l__self___ext1___2___norm2_bias = b_getattr_l__self___ext1___2___norm2_running_mean = b_getattr_l__self___ext1___2___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:38 in forward, code: relu_8 = torch.nn.functional.relu(ext1_2_norm2, inplace = True);  ext1_2_norm2 = None\\n        relu__8: \"f32[s0, 64, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_9);  batch_norm_9 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:39 in forward, code: ext1_2_conv3 = getattr(self.ext1, \"2\").conv3(relu_8);  relu_8 = None\\n        conv2d_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__8, p_getattr_l__self___ext1___2___conv3_weight);  relu__8 = p_getattr_l__self___ext1___2___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:40 in forward, code: ext1_2_norm3 = getattr(self.ext1, \"2\").norm3(ext1_2_conv3);  ext1_2_conv3 = None\\n        add__10: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext1___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext1___2___norm3_num_batches_tracked = add__10 = None\\n        batch_norm_10: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_10, p_getattr_l__self___ext1___2___norm3_weight, p_getattr_l__self___ext1___2___norm3_bias, b_getattr_l__self___ext1___2___norm3_running_mean, b_getattr_l__self___ext1___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_10 = p_getattr_l__self___ext1___2___norm3_weight = p_getattr_l__self___ext1___2___norm3_bias = b_getattr_l__self___ext1___2___norm3_running_mean = b_getattr_l__self___ext1___2___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:41 in forward, code: add_2 = ext1_2_norm3 + ext1_2_residual;  ext1_2_norm3 = ext1_2_residual = None\\n        add_2: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_10, relu__6);  batch_norm_10 = relu__6 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:42 in forward, code: relu_9 = torch.nn.functional.relu(add_2, inplace = True);  add_2 = None\\n        relu__9: \"f32[s0, 256, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(add_2);  add_2 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:43 in forward, code: ext2_0_residual_conv = getattr(self.ext2, \"0\").residual.conv(relu_9)\\n        conv2d_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext2___0___residual_conv_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:44 in forward, code: ext2_0_residual_norm = getattr(self.ext2, \"0\").residual.norm(ext2_0_residual_conv);  ext2_0_residual_conv = None\\n        add__11: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___residual_norm_num_batches_tracked = add__11 = None\\n        batch_norm_11: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_11, p_getattr_l__self___ext2___0___residual_norm_weight, p_getattr_l__self___ext2___0___residual_norm_bias, b_getattr_l__self___ext2___0___residual_norm_running_mean, b_getattr_l__self___ext2___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_11 = p_getattr_l__self___ext2___0___residual_norm_weight = p_getattr_l__self___ext2___0___residual_norm_bias = b_getattr_l__self___ext2___0___residual_norm_running_mean = b_getattr_l__self___ext2___0___residual_norm_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:45 in forward, code: ext2_0_conv1 = getattr(self.ext2, \"0\").conv1(relu_9)\\n        conv2d_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.conv2d.default(relu__9, p_getattr_l__self___ext2___0___conv1_weight);  p_getattr_l__self___ext2___0___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:46 in forward, code: ext2_0_norm1 = getattr(self.ext2, \"0\").norm1(ext2_0_conv1);  ext2_0_conv1 = None\\n        add__12: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm1_num_batches_tracked = add__12 = None\\n        batch_norm_12: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_12, p_getattr_l__self___ext2___0___norm1_weight, p_getattr_l__self___ext2___0___norm1_bias, b_getattr_l__self___ext2___0___norm1_running_mean, b_getattr_l__self___ext2___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_12 = p_getattr_l__self___ext2___0___norm1_weight = p_getattr_l__self___ext2___0___norm1_bias = b_getattr_l__self___ext2___0___norm1_running_mean = b_getattr_l__self___ext2___0___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:47 in forward, code: relu_10 = torch.nn.functional.relu(ext2_0_norm1, inplace = True);  ext2_0_norm1 = None\\n        relu__10: \"f32[s0, 128, (((s3 - 1)//2)) + 1, (((s4 - 1)//2)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_12);  batch_norm_12 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:48 in forward, code: ext2_0_conv2 = getattr(self.ext2, \"0\").conv2(relu_10);  relu_10 = None\\n        conv2d_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__10, p_getattr_l__self___ext2___0___conv2_weight, None, [2, 2], [1, 1]);  relu__10 = p_getattr_l__self___ext2___0___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:49 in forward, code: ext2_0_norm2 = getattr(self.ext2, \"0\").norm2(ext2_0_conv2);  ext2_0_conv2 = None\\n        add__13: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm2_num_batches_tracked = add__13 = None\\n        batch_norm_13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_13, p_getattr_l__self___ext2___0___norm2_weight, p_getattr_l__self___ext2___0___norm2_bias, b_getattr_l__self___ext2___0___norm2_running_mean, b_getattr_l__self___ext2___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_13 = p_getattr_l__self___ext2___0___norm2_weight = p_getattr_l__self___ext2___0___norm2_bias = b_getattr_l__self___ext2___0___norm2_running_mean = b_getattr_l__self___ext2___0___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:50 in forward, code: relu_11 = torch.nn.functional.relu(ext2_0_norm2, inplace = True);  ext2_0_norm2 = None\\n        relu__11: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_13);  batch_norm_13 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:51 in forward, code: ext2_0_conv3 = getattr(self.ext2, \"0\").conv3(relu_11);  relu_11 = None\\n        conv2d_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__11, p_getattr_l__self___ext2___0___conv3_weight);  relu__11 = p_getattr_l__self___ext2___0___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:52 in forward, code: ext2_0_norm3 = getattr(self.ext2, \"0\").norm3(ext2_0_conv3);  ext2_0_conv3 = None\\n        add__14: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___0___norm3_num_batches_tracked = add__14 = None\\n        batch_norm_14: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_14, p_getattr_l__self___ext2___0___norm3_weight, p_getattr_l__self___ext2___0___norm3_bias, b_getattr_l__self___ext2___0___norm3_running_mean, b_getattr_l__self___ext2___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_14 = p_getattr_l__self___ext2___0___norm3_weight = p_getattr_l__self___ext2___0___norm3_bias = b_getattr_l__self___ext2___0___norm3_running_mean = b_getattr_l__self___ext2___0___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:53 in forward, code: add_3 = ext2_0_norm3 + ext2_0_residual_norm;  ext2_0_norm3 = ext2_0_residual_norm = None\\n        add_3: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_14, batch_norm_11);  batch_norm_14 = batch_norm_11 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:54 in forward, code: relu_12 = torch.nn.functional.relu(add_3, inplace = True);  add_3 = None\\n        relu__12: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_3);  add_3 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:56 in forward, code: ext2_1_conv1 = getattr(self.ext2, \"1\").conv1(relu_12);  relu_12 = None\\n        conv2d_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__12, p_getattr_l__self___ext2___1___conv1_weight);  p_getattr_l__self___ext2___1___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:57 in forward, code: ext2_1_norm1 = getattr(self.ext2, \"1\").norm1(ext2_1_conv1);  ext2_1_conv1 = None\\n        add__15: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm1_num_batches_tracked = add__15 = None\\n        batch_norm_15: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_15, p_getattr_l__self___ext2___1___norm1_weight, p_getattr_l__self___ext2___1___norm1_bias, b_getattr_l__self___ext2___1___norm1_running_mean, b_getattr_l__self___ext2___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_15 = p_getattr_l__self___ext2___1___norm1_weight = p_getattr_l__self___ext2___1___norm1_bias = b_getattr_l__self___ext2___1___norm1_running_mean = b_getattr_l__self___ext2___1___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:58 in forward, code: relu_13 = torch.nn.functional.relu(ext2_1_norm1, inplace = True);  ext2_1_norm1 = None\\n        relu__13: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_15);  batch_norm_15 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:59 in forward, code: ext2_1_conv2 = getattr(self.ext2, \"1\").conv2(relu_13);  relu_13 = None\\n        conv2d_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__13, p_getattr_l__self___ext2___1___conv2_weight, None, [1, 1], [1, 1]);  relu__13 = p_getattr_l__self___ext2___1___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:60 in forward, code: ext2_1_norm2 = getattr(self.ext2, \"1\").norm2(ext2_1_conv2);  ext2_1_conv2 = None\\n        add__16: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm2_num_batches_tracked = add__16 = None\\n        batch_norm_16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_16, p_getattr_l__self___ext2___1___norm2_weight, p_getattr_l__self___ext2___1___norm2_bias, b_getattr_l__self___ext2___1___norm2_running_mean, b_getattr_l__self___ext2___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_16 = p_getattr_l__self___ext2___1___norm2_weight = p_getattr_l__self___ext2___1___norm2_bias = b_getattr_l__self___ext2___1___norm2_running_mean = b_getattr_l__self___ext2___1___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:61 in forward, code: relu_14 = torch.nn.functional.relu(ext2_1_norm2, inplace = True);  ext2_1_norm2 = None\\n        relu__14: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_16);  batch_norm_16 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:62 in forward, code: ext2_1_conv3 = getattr(self.ext2, \"1\").conv3(relu_14);  relu_14 = None\\n        conv2d_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__14, p_getattr_l__self___ext2___1___conv3_weight);  relu__14 = p_getattr_l__self___ext2___1___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:63 in forward, code: ext2_1_norm3 = getattr(self.ext2, \"1\").norm3(ext2_1_conv3);  ext2_1_conv3 = None\\n        add__17: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___1___norm3_num_batches_tracked = add__17 = None\\n        batch_norm_17: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_17, p_getattr_l__self___ext2___1___norm3_weight, p_getattr_l__self___ext2___1___norm3_bias, b_getattr_l__self___ext2___1___norm3_running_mean, b_getattr_l__self___ext2___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_17 = p_getattr_l__self___ext2___1___norm3_weight = p_getattr_l__self___ext2___1___norm3_bias = b_getattr_l__self___ext2___1___norm3_running_mean = b_getattr_l__self___ext2___1___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:64 in forward, code: add_4 = ext2_1_norm3 + ext2_1_residual;  ext2_1_norm3 = ext2_1_residual = None\\n        add_4: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_17, relu__12);  batch_norm_17 = relu__12 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:65 in forward, code: relu_15 = torch.nn.functional.relu(add_4, inplace = True);  add_4 = None\\n        relu__15: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_4);  add_4 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:67 in forward, code: ext2_2_conv1 = getattr(self.ext2, \"2\").conv1(relu_15);  relu_15 = None\\n        conv2d_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__15, p_getattr_l__self___ext2___2___conv1_weight);  p_getattr_l__self___ext2___2___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:68 in forward, code: ext2_2_norm1 = getattr(self.ext2, \"2\").norm1(ext2_2_conv1);  ext2_2_conv1 = None\\n        add__18: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm1_num_batches_tracked = add__18 = None\\n        batch_norm_18: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_18, p_getattr_l__self___ext2___2___norm1_weight, p_getattr_l__self___ext2___2___norm1_bias, b_getattr_l__self___ext2___2___norm1_running_mean, b_getattr_l__self___ext2___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_18 = p_getattr_l__self___ext2___2___norm1_weight = p_getattr_l__self___ext2___2___norm1_bias = b_getattr_l__self___ext2___2___norm1_running_mean = b_getattr_l__self___ext2___2___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:69 in forward, code: relu_16 = torch.nn.functional.relu(ext2_2_norm1, inplace = True);  ext2_2_norm1 = None\\n        relu__16: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_18);  batch_norm_18 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:70 in forward, code: ext2_2_conv2 = getattr(self.ext2, \"2\").conv2(relu_16);  relu_16 = None\\n        conv2d_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__16, p_getattr_l__self___ext2___2___conv2_weight, None, [1, 1], [1, 1]);  relu__16 = p_getattr_l__self___ext2___2___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:71 in forward, code: ext2_2_norm2 = getattr(self.ext2, \"2\").norm2(ext2_2_conv2);  ext2_2_conv2 = None\\n        add__19: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm2_num_batches_tracked = add__19 = None\\n        batch_norm_19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_19, p_getattr_l__self___ext2___2___norm2_weight, p_getattr_l__self___ext2___2___norm2_bias, b_getattr_l__self___ext2___2___norm2_running_mean, b_getattr_l__self___ext2___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_19 = p_getattr_l__self___ext2___2___norm2_weight = p_getattr_l__self___ext2___2___norm2_bias = b_getattr_l__self___ext2___2___norm2_running_mean = b_getattr_l__self___ext2___2___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:72 in forward, code: relu_17 = torch.nn.functional.relu(ext2_2_norm2, inplace = True);  ext2_2_norm2 = None\\n        relu__17: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_19);  batch_norm_19 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:73 in forward, code: ext2_2_conv3 = getattr(self.ext2, \"2\").conv3(relu_17);  relu_17 = None\\n        conv2d_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__17, p_getattr_l__self___ext2___2___conv3_weight);  relu__17 = p_getattr_l__self___ext2___2___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:74 in forward, code: ext2_2_norm3 = getattr(self.ext2, \"2\").norm3(ext2_2_conv3);  ext2_2_conv3 = None\\n        add__20: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___2___norm3_num_batches_tracked = add__20 = None\\n        batch_norm_20: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_20, p_getattr_l__self___ext2___2___norm3_weight, p_getattr_l__self___ext2___2___norm3_bias, b_getattr_l__self___ext2___2___norm3_running_mean, b_getattr_l__self___ext2___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_20 = p_getattr_l__self___ext2___2___norm3_weight = p_getattr_l__self___ext2___2___norm3_bias = b_getattr_l__self___ext2___2___norm3_running_mean = b_getattr_l__self___ext2___2___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:75 in forward, code: add_5 = ext2_2_norm3 + ext2_2_residual;  ext2_2_norm3 = ext2_2_residual = None\\n        add_5: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_20, relu__15);  batch_norm_20 = relu__15 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:76 in forward, code: relu_18 = torch.nn.functional.relu(add_5, inplace = True);  add_5 = None\\n        relu__18: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_5);  add_5 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:78 in forward, code: ext2_3_conv1 = getattr(self.ext2, \"3\").conv1(relu_18);  relu_18 = None\\n        conv2d_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__18, p_getattr_l__self___ext2___3___conv1_weight);  p_getattr_l__self___ext2___3___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:79 in forward, code: ext2_3_norm1 = getattr(self.ext2, \"3\").norm1(ext2_3_conv1);  ext2_3_conv1 = None\\n        add__21: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm1_num_batches_tracked = add__21 = None\\n        batch_norm_21: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_21, p_getattr_l__self___ext2___3___norm1_weight, p_getattr_l__self___ext2___3___norm1_bias, b_getattr_l__self___ext2___3___norm1_running_mean, b_getattr_l__self___ext2___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_21 = p_getattr_l__self___ext2___3___norm1_weight = p_getattr_l__self___ext2___3___norm1_bias = b_getattr_l__self___ext2___3___norm1_running_mean = b_getattr_l__self___ext2___3___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:80 in forward, code: relu_19 = torch.nn.functional.relu(ext2_3_norm1, inplace = True);  ext2_3_norm1 = None\\n        relu__19: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_21);  batch_norm_21 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:81 in forward, code: ext2_3_conv2 = getattr(self.ext2, \"3\").conv2(relu_19);  relu_19 = None\\n        conv2d_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__19, p_getattr_l__self___ext2___3___conv2_weight, None, [1, 1], [1, 1]);  relu__19 = p_getattr_l__self___ext2___3___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:82 in forward, code: ext2_3_norm2 = getattr(self.ext2, \"3\").norm2(ext2_3_conv2);  ext2_3_conv2 = None\\n        add__22: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm2_num_batches_tracked = add__22 = None\\n        batch_norm_22: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_22, p_getattr_l__self___ext2___3___norm2_weight, p_getattr_l__self___ext2___3___norm2_bias, b_getattr_l__self___ext2___3___norm2_running_mean, b_getattr_l__self___ext2___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_22 = p_getattr_l__self___ext2___3___norm2_weight = p_getattr_l__self___ext2___3___norm2_bias = b_getattr_l__self___ext2___3___norm2_running_mean = b_getattr_l__self___ext2___3___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:83 in forward, code: relu_20 = torch.nn.functional.relu(ext2_3_norm2, inplace = True);  ext2_3_norm2 = None\\n        relu__20: \"f32[s0, 128, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_22);  batch_norm_22 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:84 in forward, code: ext2_3_conv3 = getattr(self.ext2, \"3\").conv3(relu_20);  relu_20 = None\\n        conv2d_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__20, p_getattr_l__self___ext2___3___conv3_weight);  relu__20 = p_getattr_l__self___ext2___3___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:85 in forward, code: ext2_3_norm3 = getattr(self.ext2, \"3\").norm3(ext2_3_conv3);  ext2_3_conv3 = None\\n        add__23: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext2___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext2___3___norm3_num_batches_tracked = add__23 = None\\n        batch_norm_23: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_23, p_getattr_l__self___ext2___3___norm3_weight, p_getattr_l__self___ext2___3___norm3_bias, b_getattr_l__self___ext2___3___norm3_running_mean, b_getattr_l__self___ext2___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_23 = p_getattr_l__self___ext2___3___norm3_weight = p_getattr_l__self___ext2___3___norm3_bias = b_getattr_l__self___ext2___3___norm3_running_mean = b_getattr_l__self___ext2___3___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:86 in forward, code: add_6 = ext2_3_norm3 + ext2_3_residual;  ext2_3_norm3 = ext2_3_residual = None\\n        add_6: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_23, relu__18);  batch_norm_23 = relu__18 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:87 in forward, code: relu_21 = torch.nn.functional.relu(add_6, inplace = True);  add_6 = None\\n        relu__21: \"f32[s0, 512, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(add_6);  add_6 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:88 in forward, code: ext3_0_residual_conv = getattr(self.ext3, \"0\").residual.conv(relu_21)\\n        conv2d_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext3___0___residual_conv_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:89 in forward, code: ext3_0_residual_norm = getattr(self.ext3, \"0\").residual.norm(ext3_0_residual_conv);  ext3_0_residual_conv = None\\n        add__24: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___residual_norm_num_batches_tracked = add__24 = None\\n        batch_norm_24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_24, p_getattr_l__self___ext3___0___residual_norm_weight, p_getattr_l__self___ext3___0___residual_norm_bias, b_getattr_l__self___ext3___0___residual_norm_running_mean, b_getattr_l__self___ext3___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_24 = p_getattr_l__self___ext3___0___residual_norm_weight = p_getattr_l__self___ext3___0___residual_norm_bias = b_getattr_l__self___ext3___0___residual_norm_running_mean = b_getattr_l__self___ext3___0___residual_norm_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:90 in forward, code: ext3_0_conv1 = getattr(self.ext3, \"0\").conv1(relu_21)\\n        conv2d_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.conv2d.default(relu__21, p_getattr_l__self___ext3___0___conv1_weight);  p_getattr_l__self___ext3___0___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:91 in forward, code: ext3_0_norm1 = getattr(self.ext3, \"0\").norm1(ext3_0_conv1);  ext3_0_conv1 = None\\n        add__25: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm1_num_batches_tracked = add__25 = None\\n        batch_norm_25: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_25, p_getattr_l__self___ext3___0___norm1_weight, p_getattr_l__self___ext3___0___norm1_bias, b_getattr_l__self___ext3___0___norm1_running_mean, b_getattr_l__self___ext3___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_25 = p_getattr_l__self___ext3___0___norm1_weight = p_getattr_l__self___ext3___0___norm1_bias = b_getattr_l__self___ext3___0___norm1_running_mean = b_getattr_l__self___ext3___0___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:92 in forward, code: relu_22 = torch.nn.functional.relu(ext3_0_norm1, inplace = True);  ext3_0_norm1 = None\\n        relu__22: \"f32[s0, 256, (((s3 - 1)//4)) + 1, (((s4 - 1)//4)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_25);  batch_norm_25 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:93 in forward, code: ext3_0_conv2 = getattr(self.ext3, \"0\").conv2(relu_22);  relu_22 = None\\n        conv2d_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__22, p_getattr_l__self___ext3___0___conv2_weight, None, [2, 2], [1, 1]);  relu__22 = p_getattr_l__self___ext3___0___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:94 in forward, code: ext3_0_norm2 = getattr(self.ext3, \"0\").norm2(ext3_0_conv2);  ext3_0_conv2 = None\\n        add__26: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm2_num_batches_tracked = add__26 = None\\n        batch_norm_26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_26, p_getattr_l__self___ext3___0___norm2_weight, p_getattr_l__self___ext3___0___norm2_bias, b_getattr_l__self___ext3___0___norm2_running_mean, b_getattr_l__self___ext3___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_26 = p_getattr_l__self___ext3___0___norm2_weight = p_getattr_l__self___ext3___0___norm2_bias = b_getattr_l__self___ext3___0___norm2_running_mean = b_getattr_l__self___ext3___0___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:95 in forward, code: relu_23 = torch.nn.functional.relu(ext3_0_norm2, inplace = True);  ext3_0_norm2 = None\\n        relu__23: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_26);  batch_norm_26 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:96 in forward, code: ext3_0_conv3 = getattr(self.ext3, \"0\").conv3(relu_23);  relu_23 = None\\n        conv2d_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__23, p_getattr_l__self___ext3___0___conv3_weight);  relu__23 = p_getattr_l__self___ext3___0___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:97 in forward, code: ext3_0_norm3 = getattr(self.ext3, \"0\").norm3(ext3_0_conv3);  ext3_0_conv3 = None\\n        add__27: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___0___norm3_num_batches_tracked = add__27 = None\\n        batch_norm_27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_27, p_getattr_l__self___ext3___0___norm3_weight, p_getattr_l__self___ext3___0___norm3_bias, b_getattr_l__self___ext3___0___norm3_running_mean, b_getattr_l__self___ext3___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_27 = p_getattr_l__self___ext3___0___norm3_weight = p_getattr_l__self___ext3___0___norm3_bias = b_getattr_l__self___ext3___0___norm3_running_mean = b_getattr_l__self___ext3___0___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:98 in forward, code: add_7 = ext3_0_norm3 + ext3_0_residual_norm;  ext3_0_norm3 = ext3_0_residual_norm = None\\n        add_7: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_27, batch_norm_24);  batch_norm_27 = batch_norm_24 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:99 in forward, code: relu_24 = torch.nn.functional.relu(add_7, inplace = True);  add_7 = None\\n        relu__24: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_7);  add_7 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:101 in forward, code: ext3_1_conv1 = getattr(self.ext3, \"1\").conv1(relu_24);  relu_24 = None\\n        conv2d_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__24, p_getattr_l__self___ext3___1___conv1_weight);  p_getattr_l__self___ext3___1___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:102 in forward, code: ext3_1_norm1 = getattr(self.ext3, \"1\").norm1(ext3_1_conv1);  ext3_1_conv1 = None\\n        add__28: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm1_num_batches_tracked = add__28 = None\\n        batch_norm_28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_28, p_getattr_l__self___ext3___1___norm1_weight, p_getattr_l__self___ext3___1___norm1_bias, b_getattr_l__self___ext3___1___norm1_running_mean, b_getattr_l__self___ext3___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_28 = p_getattr_l__self___ext3___1___norm1_weight = p_getattr_l__self___ext3___1___norm1_bias = b_getattr_l__self___ext3___1___norm1_running_mean = b_getattr_l__self___ext3___1___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:103 in forward, code: relu_25 = torch.nn.functional.relu(ext3_1_norm1, inplace = True);  ext3_1_norm1 = None\\n        relu__25: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_28);  batch_norm_28 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:104 in forward, code: ext3_1_conv2 = getattr(self.ext3, \"1\").conv2(relu_25);  relu_25 = None\\n        conv2d_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__25, p_getattr_l__self___ext3___1___conv2_weight, None, [1, 1], [1, 1]);  relu__25 = p_getattr_l__self___ext3___1___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:105 in forward, code: ext3_1_norm2 = getattr(self.ext3, \"1\").norm2(ext3_1_conv2);  ext3_1_conv2 = None\\n        add__29: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm2_num_batches_tracked = add__29 = None\\n        batch_norm_29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_29, p_getattr_l__self___ext3___1___norm2_weight, p_getattr_l__self___ext3___1___norm2_bias, b_getattr_l__self___ext3___1___norm2_running_mean, b_getattr_l__self___ext3___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_29 = p_getattr_l__self___ext3___1___norm2_weight = p_getattr_l__self___ext3___1___norm2_bias = b_getattr_l__self___ext3___1___norm2_running_mean = b_getattr_l__self___ext3___1___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:106 in forward, code: relu_26 = torch.nn.functional.relu(ext3_1_norm2, inplace = True);  ext3_1_norm2 = None\\n        relu__26: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_29);  batch_norm_29 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:107 in forward, code: ext3_1_conv3 = getattr(self.ext3, \"1\").conv3(relu_26);  relu_26 = None\\n        conv2d_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__26, p_getattr_l__self___ext3___1___conv3_weight);  relu__26 = p_getattr_l__self___ext3___1___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:108 in forward, code: ext3_1_norm3 = getattr(self.ext3, \"1\").norm3(ext3_1_conv3);  ext3_1_conv3 = None\\n        add__30: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___1___norm3_num_batches_tracked = add__30 = None\\n        batch_norm_30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_30, p_getattr_l__self___ext3___1___norm3_weight, p_getattr_l__self___ext3___1___norm3_bias, b_getattr_l__self___ext3___1___norm3_running_mean, b_getattr_l__self___ext3___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_30 = p_getattr_l__self___ext3___1___norm3_weight = p_getattr_l__self___ext3___1___norm3_bias = b_getattr_l__self___ext3___1___norm3_running_mean = b_getattr_l__self___ext3___1___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:109 in forward, code: add_8 = ext3_1_norm3 + ext3_1_residual;  ext3_1_norm3 = ext3_1_residual = None\\n        add_8: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_30, relu__24);  batch_norm_30 = relu__24 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:110 in forward, code: relu_27 = torch.nn.functional.relu(add_8, inplace = True);  add_8 = None\\n        relu__27: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_8);  add_8 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:112 in forward, code: ext3_2_conv1 = getattr(self.ext3, \"2\").conv1(relu_27);  relu_27 = None\\n        conv2d_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__27, p_getattr_l__self___ext3___2___conv1_weight);  p_getattr_l__self___ext3___2___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:113 in forward, code: ext3_2_norm1 = getattr(self.ext3, \"2\").norm1(ext3_2_conv1);  ext3_2_conv1 = None\\n        add__31: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm1_num_batches_tracked = add__31 = None\\n        batch_norm_31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_31, p_getattr_l__self___ext3___2___norm1_weight, p_getattr_l__self___ext3___2___norm1_bias, b_getattr_l__self___ext3___2___norm1_running_mean, b_getattr_l__self___ext3___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_31 = p_getattr_l__self___ext3___2___norm1_weight = p_getattr_l__self___ext3___2___norm1_bias = b_getattr_l__self___ext3___2___norm1_running_mean = b_getattr_l__self___ext3___2___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:114 in forward, code: relu_28 = torch.nn.functional.relu(ext3_2_norm1, inplace = True);  ext3_2_norm1 = None\\n        relu__28: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_31);  batch_norm_31 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:115 in forward, code: ext3_2_conv2 = getattr(self.ext3, \"2\").conv2(relu_28);  relu_28 = None\\n        conv2d_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__28, p_getattr_l__self___ext3___2___conv2_weight, None, [1, 1], [1, 1]);  relu__28 = p_getattr_l__self___ext3___2___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:116 in forward, code: ext3_2_norm2 = getattr(self.ext3, \"2\").norm2(ext3_2_conv2);  ext3_2_conv2 = None\\n        add__32: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm2_num_batches_tracked = add__32 = None\\n        batch_norm_32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_32, p_getattr_l__self___ext3___2___norm2_weight, p_getattr_l__self___ext3___2___norm2_bias, b_getattr_l__self___ext3___2___norm2_running_mean, b_getattr_l__self___ext3___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_32 = p_getattr_l__self___ext3___2___norm2_weight = p_getattr_l__self___ext3___2___norm2_bias = b_getattr_l__self___ext3___2___norm2_running_mean = b_getattr_l__self___ext3___2___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:117 in forward, code: relu_29 = torch.nn.functional.relu(ext3_2_norm2, inplace = True);  ext3_2_norm2 = None\\n        relu__29: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_32);  batch_norm_32 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:118 in forward, code: ext3_2_conv3 = getattr(self.ext3, \"2\").conv3(relu_29);  relu_29 = None\\n        conv2d_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__29, p_getattr_l__self___ext3___2___conv3_weight);  relu__29 = p_getattr_l__self___ext3___2___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:119 in forward, code: ext3_2_norm3 = getattr(self.ext3, \"2\").norm3(ext3_2_conv3);  ext3_2_conv3 = None\\n        add__33: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___2___norm3_num_batches_tracked = add__33 = None\\n        batch_norm_33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_33, p_getattr_l__self___ext3___2___norm3_weight, p_getattr_l__self___ext3___2___norm3_bias, b_getattr_l__self___ext3___2___norm3_running_mean, b_getattr_l__self___ext3___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_33 = p_getattr_l__self___ext3___2___norm3_weight = p_getattr_l__self___ext3___2___norm3_bias = b_getattr_l__self___ext3___2___norm3_running_mean = b_getattr_l__self___ext3___2___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:120 in forward, code: add_9 = ext3_2_norm3 + ext3_2_residual;  ext3_2_norm3 = ext3_2_residual = None\\n        add_9: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_33, relu__27);  batch_norm_33 = relu__27 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:121 in forward, code: relu_30 = torch.nn.functional.relu(add_9, inplace = True);  add_9 = None\\n        relu__30: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_9);  add_9 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:123 in forward, code: ext3_3_conv1 = getattr(self.ext3, \"3\").conv1(relu_30);  relu_30 = None\\n        conv2d_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__30, p_getattr_l__self___ext3___3___conv1_weight);  p_getattr_l__self___ext3___3___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:124 in forward, code: ext3_3_norm1 = getattr(self.ext3, \"3\").norm1(ext3_3_conv1);  ext3_3_conv1 = None\\n        add__34: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm1_num_batches_tracked = add__34 = None\\n        batch_norm_34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_34, p_getattr_l__self___ext3___3___norm1_weight, p_getattr_l__self___ext3___3___norm1_bias, b_getattr_l__self___ext3___3___norm1_running_mean, b_getattr_l__self___ext3___3___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_34 = p_getattr_l__self___ext3___3___norm1_weight = p_getattr_l__self___ext3___3___norm1_bias = b_getattr_l__self___ext3___3___norm1_running_mean = b_getattr_l__self___ext3___3___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:125 in forward, code: relu_31 = torch.nn.functional.relu(ext3_3_norm1, inplace = True);  ext3_3_norm1 = None\\n        relu__31: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_34);  batch_norm_34 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:126 in forward, code: ext3_3_conv2 = getattr(self.ext3, \"3\").conv2(relu_31);  relu_31 = None\\n        conv2d_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__31, p_getattr_l__self___ext3___3___conv2_weight, None, [1, 1], [1, 1]);  relu__31 = p_getattr_l__self___ext3___3___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:127 in forward, code: ext3_3_norm2 = getattr(self.ext3, \"3\").norm2(ext3_3_conv2);  ext3_3_conv2 = None\\n        add__35: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm2_num_batches_tracked = add__35 = None\\n        batch_norm_35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_35, p_getattr_l__self___ext3___3___norm2_weight, p_getattr_l__self___ext3___3___norm2_bias, b_getattr_l__self___ext3___3___norm2_running_mean, b_getattr_l__self___ext3___3___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_35 = p_getattr_l__self___ext3___3___norm2_weight = p_getattr_l__self___ext3___3___norm2_bias = b_getattr_l__self___ext3___3___norm2_running_mean = b_getattr_l__self___ext3___3___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:128 in forward, code: relu_32 = torch.nn.functional.relu(ext3_3_norm2, inplace = True);  ext3_3_norm2 = None\\n        relu__32: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_35);  batch_norm_35 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:129 in forward, code: ext3_3_conv3 = getattr(self.ext3, \"3\").conv3(relu_32);  relu_32 = None\\n        conv2d_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__32, p_getattr_l__self___ext3___3___conv3_weight);  relu__32 = p_getattr_l__self___ext3___3___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:130 in forward, code: ext3_3_norm3 = getattr(self.ext3, \"3\").norm3(ext3_3_conv3);  ext3_3_conv3 = None\\n        add__36: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___3___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___3___norm3_num_batches_tracked = add__36 = None\\n        batch_norm_36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_36, p_getattr_l__self___ext3___3___norm3_weight, p_getattr_l__self___ext3___3___norm3_bias, b_getattr_l__self___ext3___3___norm3_running_mean, b_getattr_l__self___ext3___3___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_36 = p_getattr_l__self___ext3___3___norm3_weight = p_getattr_l__self___ext3___3___norm3_bias = b_getattr_l__self___ext3___3___norm3_running_mean = b_getattr_l__self___ext3___3___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:131 in forward, code: add_10 = ext3_3_norm3 + ext3_3_residual;  ext3_3_norm3 = ext3_3_residual = None\\n        add_10: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_36, relu__30);  batch_norm_36 = relu__30 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:132 in forward, code: relu_33 = torch.nn.functional.relu(add_10, inplace = True);  add_10 = None\\n        relu__33: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_10);  add_10 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:134 in forward, code: ext3_4_conv1 = getattr(self.ext3, \"4\").conv1(relu_33);  relu_33 = None\\n        conv2d_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__33, p_getattr_l__self___ext3___4___conv1_weight);  p_getattr_l__self___ext3___4___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:135 in forward, code: ext3_4_norm1 = getattr(self.ext3, \"4\").norm1(ext3_4_conv1);  ext3_4_conv1 = None\\n        add__37: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm1_num_batches_tracked = add__37 = None\\n        batch_norm_37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_37, p_getattr_l__self___ext3___4___norm1_weight, p_getattr_l__self___ext3___4___norm1_bias, b_getattr_l__self___ext3___4___norm1_running_mean, b_getattr_l__self___ext3___4___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_37 = p_getattr_l__self___ext3___4___norm1_weight = p_getattr_l__self___ext3___4___norm1_bias = b_getattr_l__self___ext3___4___norm1_running_mean = b_getattr_l__self___ext3___4___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:136 in forward, code: relu_34 = torch.nn.functional.relu(ext3_4_norm1, inplace = True);  ext3_4_norm1 = None\\n        relu__34: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_37);  batch_norm_37 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:137 in forward, code: ext3_4_conv2 = getattr(self.ext3, \"4\").conv2(relu_34);  relu_34 = None\\n        conv2d_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__34, p_getattr_l__self___ext3___4___conv2_weight, None, [1, 1], [1, 1]);  relu__34 = p_getattr_l__self___ext3___4___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:138 in forward, code: ext3_4_norm2 = getattr(self.ext3, \"4\").norm2(ext3_4_conv2);  ext3_4_conv2 = None\\n        add__38: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm2_num_batches_tracked = add__38 = None\\n        batch_norm_38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_38, p_getattr_l__self___ext3___4___norm2_weight, p_getattr_l__self___ext3___4___norm2_bias, b_getattr_l__self___ext3___4___norm2_running_mean, b_getattr_l__self___ext3___4___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_38 = p_getattr_l__self___ext3___4___norm2_weight = p_getattr_l__self___ext3___4___norm2_bias = b_getattr_l__self___ext3___4___norm2_running_mean = b_getattr_l__self___ext3___4___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:139 in forward, code: relu_35 = torch.nn.functional.relu(ext3_4_norm2, inplace = True);  ext3_4_norm2 = None\\n        relu__35: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_38);  batch_norm_38 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:140 in forward, code: ext3_4_conv3 = getattr(self.ext3, \"4\").conv3(relu_35);  relu_35 = None\\n        conv2d_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__35, p_getattr_l__self___ext3___4___conv3_weight);  relu__35 = p_getattr_l__self___ext3___4___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:141 in forward, code: ext3_4_norm3 = getattr(self.ext3, \"4\").norm3(ext3_4_conv3);  ext3_4_conv3 = None\\n        add__39: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___4___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___4___norm3_num_batches_tracked = add__39 = None\\n        batch_norm_39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_39, p_getattr_l__self___ext3___4___norm3_weight, p_getattr_l__self___ext3___4___norm3_bias, b_getattr_l__self___ext3___4___norm3_running_mean, b_getattr_l__self___ext3___4___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_39 = p_getattr_l__self___ext3___4___norm3_weight = p_getattr_l__self___ext3___4___norm3_bias = b_getattr_l__self___ext3___4___norm3_running_mean = b_getattr_l__self___ext3___4___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:142 in forward, code: add_11 = ext3_4_norm3 + ext3_4_residual;  ext3_4_norm3 = ext3_4_residual = None\\n        add_11: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_39, relu__33);  batch_norm_39 = relu__33 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:143 in forward, code: relu_36 = torch.nn.functional.relu(add_11, inplace = True);  add_11 = None\\n        relu__36: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_11);  add_11 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:145 in forward, code: ext3_5_conv1 = getattr(self.ext3, \"5\").conv1(relu_36);  relu_36 = None\\n        conv2d_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__36, p_getattr_l__self___ext3___5___conv1_weight);  p_getattr_l__self___ext3___5___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:146 in forward, code: ext3_5_norm1 = getattr(self.ext3, \"5\").norm1(ext3_5_conv1);  ext3_5_conv1 = None\\n        add__40: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm1_num_batches_tracked = add__40 = None\\n        batch_norm_40: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_40, p_getattr_l__self___ext3___5___norm1_weight, p_getattr_l__self___ext3___5___norm1_bias, b_getattr_l__self___ext3___5___norm1_running_mean, b_getattr_l__self___ext3___5___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_40 = p_getattr_l__self___ext3___5___norm1_weight = p_getattr_l__self___ext3___5___norm1_bias = b_getattr_l__self___ext3___5___norm1_running_mean = b_getattr_l__self___ext3___5___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:147 in forward, code: relu_37 = torch.nn.functional.relu(ext3_5_norm1, inplace = True);  ext3_5_norm1 = None\\n        relu__37: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_40);  batch_norm_40 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:148 in forward, code: ext3_5_conv2 = getattr(self.ext3, \"5\").conv2(relu_37);  relu_37 = None\\n        conv2d_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__37, p_getattr_l__self___ext3___5___conv2_weight, None, [1, 1], [1, 1]);  relu__37 = p_getattr_l__self___ext3___5___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:149 in forward, code: ext3_5_norm2 = getattr(self.ext3, \"5\").norm2(ext3_5_conv2);  ext3_5_conv2 = None\\n        add__41: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm2_num_batches_tracked = add__41 = None\\n        batch_norm_41: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_41, p_getattr_l__self___ext3___5___norm2_weight, p_getattr_l__self___ext3___5___norm2_bias, b_getattr_l__self___ext3___5___norm2_running_mean, b_getattr_l__self___ext3___5___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_41 = p_getattr_l__self___ext3___5___norm2_weight = p_getattr_l__self___ext3___5___norm2_bias = b_getattr_l__self___ext3___5___norm2_running_mean = b_getattr_l__self___ext3___5___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:150 in forward, code: relu_38 = torch.nn.functional.relu(ext3_5_norm2, inplace = True);  ext3_5_norm2 = None\\n        relu__38: \"f32[s0, 256, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_41);  batch_norm_41 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:151 in forward, code: ext3_5_conv3 = getattr(self.ext3, \"5\").conv3(relu_38);  relu_38 = None\\n        conv2d_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__38, p_getattr_l__self___ext3___5___conv3_weight);  relu__38 = p_getattr_l__self___ext3___5___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:152 in forward, code: ext3_5_norm3 = getattr(self.ext3, \"5\").norm3(ext3_5_conv3);  ext3_5_conv3 = None\\n        add__42: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext3___5___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext3___5___norm3_num_batches_tracked = add__42 = None\\n        batch_norm_42: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_42, p_getattr_l__self___ext3___5___norm3_weight, p_getattr_l__self___ext3___5___norm3_bias, b_getattr_l__self___ext3___5___norm3_running_mean, b_getattr_l__self___ext3___5___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_42 = p_getattr_l__self___ext3___5___norm3_weight = p_getattr_l__self___ext3___5___norm3_bias = b_getattr_l__self___ext3___5___norm3_running_mean = b_getattr_l__self___ext3___5___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:153 in forward, code: add_12 = ext3_5_norm3 + ext3_5_residual;  ext3_5_norm3 = ext3_5_residual = None\\n        add_12: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_42, relu__36);  batch_norm_42 = relu__36 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:154 in forward, code: relu_39 = torch.nn.functional.relu(add_12, inplace = True);  add_12 = None\\n        relu__39: \"f32[s0, 1024, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(add_12);  add_12 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:155 in forward, code: ext4_0_residual_conv = getattr(self.ext4, \"0\").residual.conv(relu_39)\\n        conv2d_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___residual_conv_weight, None, [2, 2]);  p_getattr_l__self___ext4___0___residual_conv_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:156 in forward, code: ext4_0_residual_norm = getattr(self.ext4, \"0\").residual.norm(ext4_0_residual_conv);  ext4_0_residual_conv = None\\n        add__43: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___residual_norm_num_batches_tracked = add__43 = None\\n        batch_norm_43: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_43, p_getattr_l__self___ext4___0___residual_norm_weight, p_getattr_l__self___ext4___0___residual_norm_bias, b_getattr_l__self___ext4___0___residual_norm_running_mean, b_getattr_l__self___ext4___0___residual_norm_running_var, True, 0.1, 1e-05, True);  conv2d_43 = p_getattr_l__self___ext4___0___residual_norm_weight = p_getattr_l__self___ext4___0___residual_norm_bias = b_getattr_l__self___ext4___0___residual_norm_running_mean = b_getattr_l__self___ext4___0___residual_norm_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:157 in forward, code: ext4_0_conv1 = getattr(self.ext4, \"0\").conv1(relu_39)\\n        conv2d_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.conv2d.default(relu__39, p_getattr_l__self___ext4___0___conv1_weight);  p_getattr_l__self___ext4___0___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:158 in forward, code: ext4_0_norm1 = getattr(self.ext4, \"0\").norm1(ext4_0_conv1);  ext4_0_conv1 = None\\n        add__44: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm1_num_batches_tracked = add__44 = None\\n        batch_norm_44: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_44, p_getattr_l__self___ext4___0___norm1_weight, p_getattr_l__self___ext4___0___norm1_bias, b_getattr_l__self___ext4___0___norm1_running_mean, b_getattr_l__self___ext4___0___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_44 = p_getattr_l__self___ext4___0___norm1_weight = p_getattr_l__self___ext4___0___norm1_bias = b_getattr_l__self___ext4___0___norm1_running_mean = b_getattr_l__self___ext4___0___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:159 in forward, code: relu_40 = torch.nn.functional.relu(ext4_0_norm1, inplace = True);  ext4_0_norm1 = None\\n        relu__40: \"f32[s0, 512, (((s3 - 1)//8)) + 1, (((s4 - 1)//8)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_44);  batch_norm_44 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:160 in forward, code: ext4_0_conv2 = getattr(self.ext4, \"0\").conv2(relu_40);  relu_40 = None\\n        conv2d_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__40, p_getattr_l__self___ext4___0___conv2_weight, None, [2, 2], [1, 1]);  relu__40 = p_getattr_l__self___ext4___0___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:161 in forward, code: ext4_0_norm2 = getattr(self.ext4, \"0\").norm2(ext4_0_conv2);  ext4_0_conv2 = None\\n        add__45: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm2_num_batches_tracked = add__45 = None\\n        batch_norm_45: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_45, p_getattr_l__self___ext4___0___norm2_weight, p_getattr_l__self___ext4___0___norm2_bias, b_getattr_l__self___ext4___0___norm2_running_mean, b_getattr_l__self___ext4___0___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_45 = p_getattr_l__self___ext4___0___norm2_weight = p_getattr_l__self___ext4___0___norm2_bias = b_getattr_l__self___ext4___0___norm2_running_mean = b_getattr_l__self___ext4___0___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:162 in forward, code: relu_41 = torch.nn.functional.relu(ext4_0_norm2, inplace = True);  ext4_0_norm2 = None\\n        relu__41: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_45);  batch_norm_45 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:163 in forward, code: ext4_0_conv3 = getattr(self.ext4, \"0\").conv3(relu_41);  relu_41 = None\\n        conv2d_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__41, p_getattr_l__self___ext4___0___conv3_weight);  relu__41 = p_getattr_l__self___ext4___0___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:164 in forward, code: ext4_0_norm3 = getattr(self.ext4, \"0\").norm3(ext4_0_conv3);  ext4_0_conv3 = None\\n        add__46: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___0___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___0___norm3_num_batches_tracked = add__46 = None\\n        batch_norm_46: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_46, p_getattr_l__self___ext4___0___norm3_weight, p_getattr_l__self___ext4___0___norm3_bias, b_getattr_l__self___ext4___0___norm3_running_mean, b_getattr_l__self___ext4___0___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_46 = p_getattr_l__self___ext4___0___norm3_weight = p_getattr_l__self___ext4___0___norm3_bias = b_getattr_l__self___ext4___0___norm3_running_mean = b_getattr_l__self___ext4___0___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:165 in forward, code: add_13 = ext4_0_norm3 + ext4_0_residual_norm;  ext4_0_norm3 = ext4_0_residual_norm = None\\n        add_13: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_46, batch_norm_43);  batch_norm_46 = batch_norm_43 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:166 in forward, code: relu_42 = torch.nn.functional.relu(add_13, inplace = True);  add_13 = None\\n        relu__42: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_13);  add_13 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:168 in forward, code: ext4_1_conv1 = getattr(self.ext4, \"1\").conv1(relu_42);  relu_42 = None\\n        conv2d_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__42, p_getattr_l__self___ext4___1___conv1_weight);  p_getattr_l__self___ext4___1___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:169 in forward, code: ext4_1_norm1 = getattr(self.ext4, \"1\").norm1(ext4_1_conv1);  ext4_1_conv1 = None\\n        add__47: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm1_num_batches_tracked = add__47 = None\\n        batch_norm_47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_47, p_getattr_l__self___ext4___1___norm1_weight, p_getattr_l__self___ext4___1___norm1_bias, b_getattr_l__self___ext4___1___norm1_running_mean, b_getattr_l__self___ext4___1___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_47 = p_getattr_l__self___ext4___1___norm1_weight = p_getattr_l__self___ext4___1___norm1_bias = b_getattr_l__self___ext4___1___norm1_running_mean = b_getattr_l__self___ext4___1___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:170 in forward, code: relu_43 = torch.nn.functional.relu(ext4_1_norm1, inplace = True);  ext4_1_norm1 = None\\n        relu__43: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_47);  batch_norm_47 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:171 in forward, code: ext4_1_conv2 = getattr(self.ext4, \"1\").conv2(relu_43);  relu_43 = None\\n        conv2d_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__43, p_getattr_l__self___ext4___1___conv2_weight, None, [1, 1], [1, 1]);  relu__43 = p_getattr_l__self___ext4___1___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:172 in forward, code: ext4_1_norm2 = getattr(self.ext4, \"1\").norm2(ext4_1_conv2);  ext4_1_conv2 = None\\n        add__48: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm2_num_batches_tracked = add__48 = None\\n        batch_norm_48: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_48, p_getattr_l__self___ext4___1___norm2_weight, p_getattr_l__self___ext4___1___norm2_bias, b_getattr_l__self___ext4___1___norm2_running_mean, b_getattr_l__self___ext4___1___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_48 = p_getattr_l__self___ext4___1___norm2_weight = p_getattr_l__self___ext4___1___norm2_bias = b_getattr_l__self___ext4___1___norm2_running_mean = b_getattr_l__self___ext4___1___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:173 in forward, code: relu_44 = torch.nn.functional.relu(ext4_1_norm2, inplace = True);  ext4_1_norm2 = None\\n        relu__44: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_48);  batch_norm_48 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:174 in forward, code: ext4_1_conv3 = getattr(self.ext4, \"1\").conv3(relu_44);  relu_44 = None\\n        conv2d_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__44, p_getattr_l__self___ext4___1___conv3_weight);  relu__44 = p_getattr_l__self___ext4___1___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:175 in forward, code: ext4_1_norm3 = getattr(self.ext4, \"1\").norm3(ext4_1_conv3);  ext4_1_conv3 = None\\n        add__49: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___1___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___1___norm3_num_batches_tracked = add__49 = None\\n        batch_norm_49: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_49, p_getattr_l__self___ext4___1___norm3_weight, p_getattr_l__self___ext4___1___norm3_bias, b_getattr_l__self___ext4___1___norm3_running_mean, b_getattr_l__self___ext4___1___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_49 = p_getattr_l__self___ext4___1___norm3_weight = p_getattr_l__self___ext4___1___norm3_bias = b_getattr_l__self___ext4___1___norm3_running_mean = b_getattr_l__self___ext4___1___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:176 in forward, code: add_14 = ext4_1_norm3 + ext4_1_residual;  ext4_1_norm3 = ext4_1_residual = None\\n        add_14: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_49, relu__42);  batch_norm_49 = relu__42 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:177 in forward, code: relu_45 = torch.nn.functional.relu(add_14, inplace = True);  add_14 = None\\n        relu__45: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_14);  add_14 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:179 in forward, code: ext4_2_conv1 = getattr(self.ext4, \"2\").conv1(relu_45);  relu_45 = None\\n        conv2d_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__45, p_getattr_l__self___ext4___2___conv1_weight);  p_getattr_l__self___ext4___2___conv1_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:180 in forward, code: ext4_2_norm1 = getattr(self.ext4, \"2\").norm1(ext4_2_conv1);  ext4_2_conv1 = None\\n        add__50: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm1_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm1_num_batches_tracked = add__50 = None\\n        batch_norm_50: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_50, p_getattr_l__self___ext4___2___norm1_weight, p_getattr_l__self___ext4___2___norm1_bias, b_getattr_l__self___ext4___2___norm1_running_mean, b_getattr_l__self___ext4___2___norm1_running_var, True, 0.1, 1e-05, True);  conv2d_50 = p_getattr_l__self___ext4___2___norm1_weight = p_getattr_l__self___ext4___2___norm1_bias = b_getattr_l__self___ext4___2___norm1_running_mean = b_getattr_l__self___ext4___2___norm1_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:181 in forward, code: relu_46 = torch.nn.functional.relu(ext4_2_norm1, inplace = True);  ext4_2_norm1 = None\\n        relu__46: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_50);  batch_norm_50 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:182 in forward, code: ext4_2_conv2 = getattr(self.ext4, \"2\").conv2(relu_46);  relu_46 = None\\n        conv2d_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__46, p_getattr_l__self___ext4___2___conv2_weight, None, [1, 1], [1, 1]);  relu__46 = p_getattr_l__self___ext4___2___conv2_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:183 in forward, code: ext4_2_norm2 = getattr(self.ext4, \"2\").norm2(ext4_2_conv2);  ext4_2_conv2 = None\\n        add__51: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm2_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm2_num_batches_tracked = add__51 = None\\n        batch_norm_51: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_51, p_getattr_l__self___ext4___2___norm2_weight, p_getattr_l__self___ext4___2___norm2_bias, b_getattr_l__self___ext4___2___norm2_running_mean, b_getattr_l__self___ext4___2___norm2_running_var, True, 0.1, 1e-05, True);  conv2d_51 = p_getattr_l__self___ext4___2___norm2_weight = p_getattr_l__self___ext4___2___norm2_bias = b_getattr_l__self___ext4___2___norm2_running_mean = b_getattr_l__self___ext4___2___norm2_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:184 in forward, code: relu_47 = torch.nn.functional.relu(ext4_2_norm2, inplace = True);  ext4_2_norm2 = None\\n        relu__47: \"f32[s0, 512, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(batch_norm_51);  batch_norm_51 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:185 in forward, code: ext4_2_conv3 = getattr(self.ext4, \"2\").conv3(relu_47);  relu_47 = None\\n        conv2d_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.conv2d.default(relu__47, p_getattr_l__self___ext4___2___conv3_weight);  relu__47 = p_getattr_l__self___ext4___2___conv3_weight = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:186 in forward, code: ext4_2_norm3 = getattr(self.ext4, \"2\").norm3(ext4_2_conv3);  ext4_2_conv3 = None\\n        add__52: \"i64[]\" = torch.ops.aten.add_.Tensor(b_getattr_l__self___ext4___2___norm3_num_batches_tracked, 1);  b_getattr_l__self___ext4___2___norm3_num_batches_tracked = add__52 = None\\n        batch_norm_52: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.batch_norm.default(conv2d_52, p_getattr_l__self___ext4___2___norm3_weight, p_getattr_l__self___ext4___2___norm3_bias, b_getattr_l__self___ext4___2___norm3_running_mean, b_getattr_l__self___ext4___2___norm3_running_var, True, 0.1, 1e-05, True);  conv2d_52 = p_getattr_l__self___ext4___2___norm3_weight = p_getattr_l__self___ext4___2___norm3_bias = b_getattr_l__self___ext4___2___norm3_running_mean = b_getattr_l__self___ext4___2___norm3_running_var = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:187 in forward, code: add_15 = ext4_2_norm3 + ext4_2_residual;  ext4_2_norm3 = ext4_2_residual = None\\n        add_15: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.add.Tensor(batch_norm_52, relu__45);  batch_norm_52 = relu__45 = None\\n        \\n         # File: <eval_with_key>.213 from /home/khwstolle/Projects/backbones/sources/backbones/resnet/_modules.py:288 in forward:188 in forward, code: relu_48 = torch.nn.functional.relu(add_15, inplace = True);  add_15 = None\\n        relu__48: \"f32[s0, 2048, (((s3 - 1)//16)) + 1, (((s4 - 1)//16)) + 1]\" = torch.ops.aten.relu_.default(add_15);  add_15 = None\\n        return (relu__9, relu__21, relu__39, relu__48)\\n        '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn50_ft_train = torch.export.export_for_training(\n",
    "    rn50_ft, inputs, dynamic_shapes=[(sb, Dim.STATIC, 2 * sh, 2 * sw)]\n",
    ")\n",
    "\n",
    "rn50_ft_train.graph_module.print_readable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ext1': tensor([[[[2.1229e+00, 2.1989e-01, 3.5561e+00,  ..., 3.0651e+00,\n",
       "            6.5761e-01, 3.5836e+00],\n",
       "           [1.7811e+00, 1.9223e+00, 4.0303e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [4.1568e+00, 1.5858e+00, 4.2046e-02,  ..., 1.5455e-01,\n",
       "            8.4549e-02, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 7.3195e-01,  ..., 4.0034e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.2993e-01,\n",
       "            1.4144e+00, 3.2125e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 5.5326e+00,  ..., 5.9888e+00,\n",
       "            4.1769e+00, 3.9481e+00]],\n",
       " \n",
       "          [[6.6075e-01, 8.0942e-01, 3.6434e-01,  ..., 4.5403e+00,\n",
       "            1.3335e+00, 0.0000e+00],\n",
       "           [1.9473e+00, 1.7458e+00, 9.9051e-01,  ..., 4.4006e+00,\n",
       "            1.0807e+00, 2.4453e+00],\n",
       "           [1.2348e+00, 5.2678e-01, 1.0074e+00,  ..., 1.6955e+00,\n",
       "            2.2640e+00, 2.9317e+00],\n",
       "           ...,\n",
       "           [2.0802e+00, 7.9480e-01, 1.2046e+00,  ..., 9.0305e-01,\n",
       "            8.9425e-01, 7.6747e-01],\n",
       "           [7.8921e+00, 8.2773e+00, 6.7583e+00,  ..., 4.3488e-01,\n",
       "            1.2776e+00, 1.4204e+00],\n",
       "           [2.1637e+00, 6.6493e-01, 9.3695e-01,  ..., 7.5121e-01,\n",
       "            5.2842e+00, 2.2782e+00]],\n",
       " \n",
       "          [[0.0000e+00, 4.6086e+00, 1.2273e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 2.4674e+00],\n",
       "           [0.0000e+00, 5.2571e+00, 0.0000e+00,  ..., 7.4172e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 1.9392e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 4.4909e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 2.9147e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.6081e+00, 3.2797e+00],\n",
       "           [3.4655e+00, 4.7336e+00, 0.0000e+00,  ..., 5.2053e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 3.2809e+00, 0.0000e+00,  ..., 6.0750e+00,\n",
       "            5.7133e-01, 0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[4.5290e+00, 7.2832e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.6561e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6540e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.2993e-01, 9.9443e-02, 0.0000e+00,  ..., 1.8011e+00,\n",
       "            6.9588e-01, 3.2242e+00],\n",
       "           ...,\n",
       "           [3.6033e+00, 4.5007e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.9398e+00, 1.0573e+00],\n",
       "           [1.2748e+00, 1.6307e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 3.0715e-01],\n",
       "           [5.6837e-01, 1.4186e+00, 5.8212e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.8468e-01]],\n",
       " \n",
       "          [[6.7360e+00, 6.2261e+00, 2.7626e+00,  ..., 1.5462e-01,\n",
       "            1.5696e-01, 6.0299e+00],\n",
       "           [5.8419e+00, 7.4212e-01, 1.0754e+00,  ..., 1.3734e+00,\n",
       "            2.6670e+00, 6.1842e+00],\n",
       "           [2.2554e+00, 3.0870e+00, 2.9160e+00,  ..., 8.9384e-01,\n",
       "            1.6511e+00, 1.4294e+00],\n",
       "           ...,\n",
       "           [9.1748e-02, 8.9336e-02, 3.9120e+00,  ..., 8.1585e-01,\n",
       "            3.5369e-01, 1.2647e+00],\n",
       "           [2.2787e-01, 1.2852e-01, 5.3690e+00,  ..., 2.7515e+00,\n",
       "            7.6020e-01, 1.0994e+00],\n",
       "           [3.1530e-01, 8.6261e-01, 4.5865e+00,  ..., 2.8328e+00,\n",
       "            4.5485e-01, 3.2078e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2612e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 4.2138e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.7892e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[5.3585e+00, 4.2802e+00, 2.1591e+00,  ..., 0.0000e+00,\n",
       "            1.9252e+00, 3.2503e+00],\n",
       "           [1.4340e+00, 2.1370e+00, 7.6775e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [4.2164e+00, 0.0000e+00, 1.5285e+00,  ..., 3.3581e-01,\n",
       "            2.6011e-01, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            3.4916e-01, 1.8669e+00],\n",
       "           [1.6539e+00, 0.0000e+00, 3.2410e-01,  ..., 1.7497e-01,\n",
       "            1.2628e-01, 3.9328e+00],\n",
       "           [3.4837e+00, 5.8964e-01, 1.3544e+00,  ..., 3.2091e-01,\n",
       "            1.7630e-01, 2.3561e+00]],\n",
       " \n",
       "          [[1.5201e+00, 4.9702e-01, 9.6877e-01,  ..., 1.2440e+00,\n",
       "            7.4337e-01, 9.1028e-01],\n",
       "           [1.2321e+00, 2.6451e+00, 9.5492e-01,  ..., 9.4505e-01,\n",
       "            5.5479e+00, 8.1274e+00],\n",
       "           [1.3615e+00, 1.8222e+00, 1.0339e+00,  ..., 1.5526e+00,\n",
       "            1.9610e+00, 6.0136e-02],\n",
       "           ...,\n",
       "           [7.2813e+00, 4.9004e+00, 1.4693e+00,  ..., 3.0366e+00,\n",
       "            1.3134e+00, 1.3791e+00],\n",
       "           [5.4403e+00, 4.9291e+00, 6.1188e+00,  ..., 8.3851e+00,\n",
       "            8.1808e+00, 4.9631e+00],\n",
       "           [5.9995e-01, 1.2326e+00, 1.5103e+00,  ..., 3.7508e+00,\n",
       "            2.0493e+00, 4.8135e+00]],\n",
       " \n",
       "          [[3.3559e-01, 2.3933e-01, 0.0000e+00,  ..., 2.2269e+00,\n",
       "            2.6688e+00, 0.0000e+00],\n",
       "           [6.8569e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            4.0909e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 5.0492e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 3.9974e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 5.0644e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 4.3734e-01],\n",
       "           [7.0022e-01, 4.1103e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            7.8492e-01, 0.0000e+00],\n",
       "           [1.9258e+00, 8.8219e-01, 0.0000e+00,  ..., 9.8854e-01,\n",
       "            0.0000e+00, 3.2098e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.5102e+01, 3.0466e+00, 1.4654e+01,  ..., 4.4105e+00,\n",
       "            0.0000e+00, 5.2033e-01],\n",
       "           [2.6546e+00, 6.2849e-01, 3.9188e+00,  ..., 4.0149e+00,\n",
       "            1.5427e+00, 8.3630e-02],\n",
       "           [5.4879e+00, 7.4748e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            6.5865e-01, 3.3531e+00],\n",
       "           ...,\n",
       "           [6.8727e+00, 1.9178e+00, 2.1367e+00,  ..., 2.7418e+00,\n",
       "            0.0000e+00, 1.0070e+00],\n",
       "           [1.9354e+00, 9.0647e-01, 1.0594e+01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 9.2399e-01],\n",
       "           [1.0043e+00, 5.9973e-01, 4.2991e+00,  ..., 5.7392e+00,\n",
       "            0.0000e+00, 1.3847e+00]],\n",
       " \n",
       "          [[4.4984e+00, 3.6616e+00, 9.0690e+00,  ..., 1.5555e+00,\n",
       "            1.5788e-01, 1.6918e-01],\n",
       "           [8.5715e-01, 6.4530e+00, 9.1606e+00,  ..., 4.3982e+00,\n",
       "            1.9490e-01, 5.2381e+00],\n",
       "           [2.7921e+00, 3.3564e+00, 2.0998e+00,  ..., 5.3147e+00,\n",
       "            3.3182e+00, 7.4366e+00],\n",
       "           ...,\n",
       "           [4.0362e+00, 4.4308e+00, 4.0789e+00,  ..., 3.7175e-01,\n",
       "            2.1113e+00, 2.0559e+00],\n",
       "           [4.3709e+00, 2.1265e+00, 4.5305e+00,  ..., 9.2239e-01,\n",
       "            6.7826e-01, 2.8520e+00],\n",
       "           [1.6725e+00, 7.0057e-01, 1.1479e+00,  ..., 1.1440e+00,\n",
       "            2.1172e+00, 5.5271e+00]],\n",
       " \n",
       "          [[0.0000e+00, 7.4438e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 2.5896e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.1029e+00, 7.9349e-01],\n",
       "           [0.0000e+00, 5.4613e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.8797e-01],\n",
       "           ...,\n",
       "           [0.0000e+00, 3.0748e-01, 0.0000e+00,  ..., 1.4674e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 1.2717e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]]], grad_fn=<ReluBackward0>),\n",
       " 'ext2': tensor([[[[5.1142e+00, 1.1438e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 8.8523e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 3.6473e+00,  ..., 0.0000e+00,\n",
       "            2.8902e+00, 4.0692e+00],\n",
       "           [0.0000e+00, 1.9929e+00, 6.9245e-01,  ..., 3.9371e-01,\n",
       "            2.2610e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [1.6235e+00, 7.4576e+00, 3.4909e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 3.9498e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 8.5035e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 6.3570e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[2.6862e-03, 1.4481e-01, 2.9452e+00,  ..., 4.9040e-01,\n",
       "            2.4246e-03, 2.7837e-03],\n",
       "           [2.5213e-03, 2.3313e-03, 2.3359e-03,  ..., 2.1743e-03,\n",
       "            1.9531e-03, 6.4156e-01],\n",
       "           [2.7366e-03, 2.3232e-03, 2.2904e-03,  ..., 2.0985e-03,\n",
       "            1.2470e+00, 1.2092e+00],\n",
       "           ...,\n",
       "           [3.8131e+00, 2.7057e+00, 4.6796e-01,  ..., 2.4514e-03,\n",
       "            7.4547e-04, 0.0000e+00],\n",
       "           [1.3560e+00, 2.0143e-01, 1.3770e-03,  ..., 2.1504e-03,\n",
       "            2.0123e-03, 2.6802e-03],\n",
       "           [3.7532e-03, 2.2991e-03, 1.6655e-03,  ..., 2.2743e+00,\n",
       "            1.8303e+00, 1.2211e-03]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 4.3378e+00,  ..., 2.9821e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 3.7886e+00,  ..., 3.7493e+00,\n",
       "            8.5855e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0405e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9934e+00,\n",
       "            1.3507e+01, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.7666e+00,  ..., 1.1172e+00,\n",
       "            5.0239e+00, 2.3148e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 3.4522e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[3.2148e+00, 4.8982e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            3.5370e-02, 3.3274e+00],\n",
       "           [1.9327e+00, 3.4444e+00, 2.2087e+00,  ..., 4.5714e+00,\n",
       "            0.0000e+00, 4.9452e+00],\n",
       "           [6.1384e-01, 1.5712e+00, 2.2017e+00,  ..., 0.0000e+00,\n",
       "            5.2432e-01, 3.3916e+00],\n",
       "           ...,\n",
       "           [1.2096e-01, 1.1274e+00, 1.8838e+00,  ..., 3.0938e+00,\n",
       "            1.6726e+00, 8.6195e+00],\n",
       "           [0.0000e+00, 2.5898e+00, 1.7284e-02,  ..., 5.5217e-02,\n",
       "            3.1613e-01, 4.7721e+00],\n",
       "           [4.6283e-01, 4.7354e+00, 3.0438e+00,  ..., 2.7347e+00,\n",
       "            4.1541e+00, 1.6912e+00]],\n",
       " \n",
       "          [[1.1871e+00, 5.9285e+00, 2.9749e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 4.1294e+00],\n",
       "           [4.5138e+00, 2.2948e+00, 2.0808e+00,  ..., 2.9312e+00,\n",
       "            0.0000e+00, 1.9500e+00],\n",
       "           [1.4094e-01, 8.1385e-01, 3.4907e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 7.8031e-01, 5.5892e-01,  ..., 0.0000e+00,\n",
       "            5.3401e-01, 2.4697e-01],\n",
       "           [7.4214e-01, 2.0615e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            2.2515e-02, 4.2133e-01],\n",
       "           [3.2940e+00, 0.0000e+00, 3.6273e-01,  ..., 4.4040e-02,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[1.4490e+00, 1.3585e+00, 2.4888e+00,  ..., 9.1000e-01,\n",
       "            0.0000e+00, 7.7797e-02],\n",
       "           [5.8382e-01, 0.0000e+00, 3.7740e-01,  ..., 0.0000e+00,\n",
       "            4.8261e-01, 0.0000e+00],\n",
       "           [2.2493e+00, 0.0000e+00, 9.7852e-02,  ..., 1.3492e+00,\n",
       "            3.7094e+00, 1.9870e+00],\n",
       "           ...,\n",
       "           [7.8769e-01, 0.0000e+00, 0.0000e+00,  ..., 1.1358e+00,\n",
       "            1.7358e+00, 0.0000e+00],\n",
       "           [9.3904e-02, 0.0000e+00, 0.0000e+00,  ..., 3.0789e-01,\n",
       "            4.4263e+00, 2.4253e+00],\n",
       "           [9.1562e-01, 0.0000e+00, 0.0000e+00,  ..., 1.3885e+00,\n",
       "            0.0000e+00, 3.8004e-01]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 6.6826e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            3.9466e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.1888e-01,\n",
       "            2.2397e+00, 4.1502e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 3.2326e+00,  ..., 1.7412e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 1.7009e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 6.7678e+00],\n",
       "           [5.9898e-01, 3.2165e-01, 1.6392e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 5.6613e+00],\n",
       "           [1.6930e+00, 6.5229e+00, 1.7495e+00,  ..., 0.0000e+00,\n",
       "            1.4347e+00, 3.8643e+00]],\n",
       " \n",
       "          [[1.0419e+00, 2.5645e-03, 2.1247e-03,  ..., 1.7967e-03,\n",
       "            1.6596e-03, 2.2178e-03],\n",
       "           [1.9641e-03, 2.5071e-03, 1.2650e-03,  ..., 1.5844e-03,\n",
       "            6.8160e-05, 1.7155e-03],\n",
       "           [2.2486e-03, 3.1132e-03, 4.0522e+00,  ..., 2.4559e-03,\n",
       "            1.0450e+00, 2.4404e-03],\n",
       "           ...,\n",
       "           [5.5979e-01, 1.9992e-03, 2.3491e-03,  ..., 3.5944e+00,\n",
       "            1.3393e+00, 2.4635e-03],\n",
       "           [3.4847e-03, 1.2022e-03, 2.0525e-03,  ..., 4.5528e-01,\n",
       "            1.9601e-03, 2.4885e-03],\n",
       "           [3.5841e-03, 2.2100e-03, 3.4716e-03,  ..., 3.2446e-03,\n",
       "            2.7134e-03, 3.1953e-03]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 6.2029e-01,  ..., 1.5359e+00,\n",
       "            3.7224e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 6.2624e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.4755e+00,\n",
       "            6.6139e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.1981e+00, 6.0553e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000e+00, 5.5942e+00, 2.3254e-02,  ..., 4.5414e-01,\n",
       "            1.1242e+00, 3.1631e-01],\n",
       "           [0.0000e+00, 2.7534e+00, 9.8018e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.3529e+00],\n",
       "           [6.9658e-01, 1.6583e+00, 2.7989e+00,  ..., 9.5559e-02,\n",
       "            0.0000e+00, 1.2613e+00],\n",
       "           ...,\n",
       "           [1.1701e+00, 1.4106e+00, 1.2415e-01,  ..., 2.5375e+00,\n",
       "            2.4397e+00, 1.2177e+00],\n",
       "           [1.9164e+00, 0.0000e+00, 6.5004e+00,  ..., 1.7199e+00,\n",
       "            0.0000e+00, 4.6010e+00],\n",
       "           [3.5870e+00, 2.1060e+00, 1.9858e+00,  ..., 0.0000e+00,\n",
       "            3.6916e+00, 3.6651e+00]],\n",
       " \n",
       "          [[0.0000e+00, 1.7567e+00, 0.0000e+00,  ..., 1.4827e+00,\n",
       "            2.6268e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 1.3006e-01, 5.6770e+00,  ..., 0.0000e+00,\n",
       "            1.6430e+00, 2.3174e+00],\n",
       "           [2.3683e-01, 0.0000e+00, 4.0355e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.9518e+00],\n",
       "           ...,\n",
       "           [2.3537e-01, 1.6105e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            9.2238e-01, 1.1610e-01],\n",
       "           [3.1224e+00, 1.6860e+00, 7.5921e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.6646e+00, 2.8084e+00, 2.0047e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 2.3077e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 2.9525e-01,  ..., 2.6180e+00,\n",
       "            1.0861e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.0688e+00,  ..., 6.3384e-01,\n",
       "            2.9787e+00, 2.3365e+00],\n",
       "           [2.5962e+00, 0.0000e+00, 4.1208e-01,  ..., 1.2974e+00,\n",
       "            1.3700e+00, 9.0099e-01],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 7.9530e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 1.3118e+00,  ..., 0.0000e+00,\n",
       "            1.2965e+00, 5.1367e+00],\n",
       "           [3.6744e-01, 4.4656e-01, 1.2689e+00,  ..., 4.7814e-01,\n",
       "            1.4336e+00, 1.5268e+00]]]], grad_fn=<ReluBackward0>),\n",
       " 'ext3': tensor([[[[2.7959e+00, 1.3636e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 3.2682e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 1.1688e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.4895e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 2.0642e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.4606e+00, 7.4503e-01, 1.5882e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.2245e+00]],\n",
       " \n",
       "          [[1.1580e+00, 5.8734e-01, 9.8998e-01,  ..., 8.8110e-01,\n",
       "            5.6313e-01, 1.2058e+00],\n",
       "           [8.9361e-01, 8.5129e-01, 6.5241e-01,  ..., 9.2897e-01,\n",
       "            8.5217e-01, 1.1005e+00],\n",
       "           [8.9047e-01, 5.4687e-01, 7.1033e-01,  ..., 8.2190e-01,\n",
       "            6.4837e-01, 8.7387e-01],\n",
       "           ...,\n",
       "           [4.8517e-01, 5.4476e-01, 5.8822e-01,  ..., 1.5044e-01,\n",
       "            4.0765e-01, 1.7266e+00],\n",
       "           [1.1693e+00, 6.8794e-01, 4.9211e-01,  ..., 3.4647e-01,\n",
       "            6.3908e-01, 2.9652e+00],\n",
       "           [1.1577e+00, 7.8085e-01, 5.2550e-01,  ..., 4.8407e-01,\n",
       "            4.1816e-01, 6.3402e-01]],\n",
       " \n",
       "          [[9.4642e-03, 1.0923e+00, 0.0000e+00,  ..., 4.3934e-01,\n",
       "            1.9000e+00, 0.0000e+00],\n",
       "           [1.9694e+00, 1.1096e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            9.1336e-02, 4.8506e-01],\n",
       "           [1.7246e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [3.0081e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 6.9985e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            8.1990e-01, 0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            8.2194e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 2.6661e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 7.8608e-02],\n",
       "           [1.6151e-01, 5.9369e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            8.1741e-01, 1.0337e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 4.6750e-02, 1.0254e-01,  ..., 0.0000e+00,\n",
       "            2.8449e-02, 0.0000e+00],\n",
       "           [1.3928e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.2588e-01, 2.1204e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.9563e-01,\n",
       "            1.2298e+00, 0.0000e+00]],\n",
       " \n",
       "          [[2.0855e+00, 1.3893e+00, 1.1973e-02,  ..., 1.4625e+00,\n",
       "            0.0000e+00, 1.4219e+00],\n",
       "           [4.0201e-01, 1.3119e+00, 1.4661e-01,  ..., 6.9176e-01,\n",
       "            1.2832e+00, 1.2273e+00],\n",
       "           [7.2701e-01, 0.0000e+00, 0.0000e+00,  ..., 1.4507e+00,\n",
       "            6.2277e-01, 1.8821e+00],\n",
       "           ...,\n",
       "           [1.0375e+00, 2.4929e+00, 2.6751e+00,  ..., 4.1232e+00,\n",
       "            7.1907e-01, 1.5763e+00],\n",
       "           [0.0000e+00, 3.7349e+00, 3.6605e+00,  ..., 4.5582e-01,\n",
       "            1.1157e+00, 5.4111e-01],\n",
       "           [1.1647e+00, 4.0901e-01, 1.0238e+00,  ..., 0.0000e+00,\n",
       "            2.0585e-01, 9.6643e-01]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 1.0225e-01, 0.0000e+00,  ..., 1.7972e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7006e+00,\n",
       "            0.0000e+00, 0.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.5857e+00],\n",
       "           [0.0000e+00, 8.2102e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.2925e+00, 1.1842e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9475e+00,\n",
       "            2.7156e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 4.9373e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.4372e-01]],\n",
       " \n",
       "          [[1.2716e+00, 7.4529e-01, 6.1626e-01,  ..., 9.2271e-01,\n",
       "            4.8816e-01, 1.3132e+00],\n",
       "           [9.5842e-01, 8.4188e-01, 4.8850e-01,  ..., 7.7124e-01,\n",
       "            6.4410e-01, 8.5538e-01],\n",
       "           [8.4944e-01, 6.4104e-01, 3.3482e-01,  ..., 5.5153e-01,\n",
       "            8.1909e-01, 1.3106e+00],\n",
       "           ...,\n",
       "           [6.6222e-01, 6.7183e-01, 4.7128e-01,  ..., 4.4230e-01,\n",
       "            3.6598e-01, 1.8300e-01],\n",
       "           [7.8900e-01, 7.2034e-01, 5.2239e-01,  ..., 6.3993e-01,\n",
       "            7.4532e-01, 5.7139e-01],\n",
       "           [7.9444e-01, 7.2011e-01, 5.9852e-01,  ..., 8.1500e-01,\n",
       "            3.3100e-01, 5.6479e-01]],\n",
       " \n",
       "          [[0.0000e+00, 1.3842e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.4760e+00, 0.0000e+00],\n",
       "           [1.2879e+00, 1.8756e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 6.8559e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.2728e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 1.1279e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.2011e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 2.8283e-02, 1.2439e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000e+00, 3.0839e-03, 0.0000e+00,  ..., 2.0085e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.4308e-02,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 8.7964e-02,  ..., 1.0523e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 2.0591e-01, 1.0873e+00,  ..., 1.0912e+00,\n",
       "            4.5330e-01, 0.0000e+00],\n",
       "           [7.8457e-02, 5.4024e-01, 1.7409e+00,  ..., 4.1067e-01,\n",
       "            0.0000e+00, 2.6927e-01],\n",
       "           [0.0000e+00, 6.3235e-01, 1.2069e+00,  ..., 1.3878e-01,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[1.9815e+00, 0.0000e+00, 3.1685e-01,  ..., 6.0931e-01,\n",
       "            1.2758e+00, 1.2256e+00],\n",
       "           [1.1014e+00, 1.1913e+00, 2.1735e+00,  ..., 6.7485e-01,\n",
       "            1.4448e+00, 2.2399e-01],\n",
       "           [2.1201e+00, 1.3815e+00, 3.9511e+00,  ..., 1.1648e+00,\n",
       "            1.2230e+00, 9.6101e-02],\n",
       "           ...,\n",
       "           [1.6017e+00, 1.9373e+00, 1.3713e+00,  ..., 3.9829e-01,\n",
       "            8.3449e-01, 9.6912e-01],\n",
       "           [1.4567e+00, 1.6372e+00, 1.9364e+00,  ..., 8.1515e-01,\n",
       "            1.1765e+00, 8.7045e-01],\n",
       "           [1.6736e+00, 4.3031e-01, 2.8335e-01,  ..., 1.5975e+00,\n",
       "            9.0979e-01, 9.5928e-01]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0361e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.6668e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 2.5961e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 7.6731e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]]]], grad_fn=<ReluBackward0>),\n",
       " 'ext4': tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 1.1710,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4450, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [1.8265, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [2.1610, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.3376, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 3.8252, 0.0000, 0.0000],\n",
       "           [0.0000, 0.4463, 0.0000,  ..., 0.6802, 0.0000, 0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "        grad_fn=<ReluBackward0>)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn50_ft_train.module()(*inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multictx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
